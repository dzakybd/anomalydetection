{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn import preprocessing \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, accuracy_score, recall_score, precision_score\n",
    "from pickle import dump\n",
    "from numpy.random import seed\n",
    "import tensorflow\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from numpy import quantile\n",
    "\n",
    "rseed = 1\n",
    "seed(rseed)\n",
    "tensorflow.random.set_seed(rseed)\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>0.090794</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>-0.166974</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>0.207643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>-0.054952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>0.753074</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.425966</td>\n",
       "      <td>0.960523</td>\n",
       "      <td>1.141109</td>\n",
       "      <td>-0.168252</td>\n",
       "      <td>0.420987</td>\n",
       "      <td>-0.029728</td>\n",
       "      <td>0.476201</td>\n",
       "      <td>0.260314</td>\n",
       "      <td>-0.568671</td>\n",
       "      <td>-0.371407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208254</td>\n",
       "      <td>-0.559825</td>\n",
       "      <td>-0.026398</td>\n",
       "      <td>-0.371427</td>\n",
       "      <td>-0.232794</td>\n",
       "      <td>0.105915</td>\n",
       "      <td>0.253844</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.229658</td>\n",
       "      <td>0.141004</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>1.202613</td>\n",
       "      <td>0.191881</td>\n",
       "      <td>0.272708</td>\n",
       "      <td>-0.005159</td>\n",
       "      <td>0.081213</td>\n",
       "      <td>0.464960</td>\n",
       "      <td>-0.099254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.167716</td>\n",
       "      <td>-0.270710</td>\n",
       "      <td>-0.154104</td>\n",
       "      <td>-0.780055</td>\n",
       "      <td>0.750137</td>\n",
       "      <td>-0.257237</td>\n",
       "      <td>0.034507</td>\n",
       "      <td>0.005168</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.644269</td>\n",
       "      <td>1.417964</td>\n",
       "      <td>1.074380</td>\n",
       "      <td>-0.492199</td>\n",
       "      <td>0.948934</td>\n",
       "      <td>0.428118</td>\n",
       "      <td>1.120631</td>\n",
       "      <td>-3.807864</td>\n",
       "      <td>0.615375</td>\n",
       "      <td>1.249376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.943465</td>\n",
       "      <td>-1.015455</td>\n",
       "      <td>0.057504</td>\n",
       "      <td>-0.649709</td>\n",
       "      <td>-0.415267</td>\n",
       "      <td>-0.051634</td>\n",
       "      <td>-1.206921</td>\n",
       "      <td>-1.085339</td>\n",
       "      <td>40.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.894286</td>\n",
       "      <td>0.286157</td>\n",
       "      <td>-0.113192</td>\n",
       "      <td>-0.271526</td>\n",
       "      <td>2.669599</td>\n",
       "      <td>3.721818</td>\n",
       "      <td>0.370145</td>\n",
       "      <td>0.851084</td>\n",
       "      <td>-0.392048</td>\n",
       "      <td>-0.410430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.268092</td>\n",
       "      <td>-0.204233</td>\n",
       "      <td>1.011592</td>\n",
       "      <td>0.373205</td>\n",
       "      <td>-0.384157</td>\n",
       "      <td>0.011747</td>\n",
       "      <td>0.142404</td>\n",
       "      <td>93.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.338262</td>\n",
       "      <td>1.119593</td>\n",
       "      <td>1.044367</td>\n",
       "      <td>-0.222187</td>\n",
       "      <td>0.499361</td>\n",
       "      <td>-0.246761</td>\n",
       "      <td>0.651583</td>\n",
       "      <td>0.069539</td>\n",
       "      <td>-0.736727</td>\n",
       "      <td>-0.366846</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.246914</td>\n",
       "      <td>-0.633753</td>\n",
       "      <td>-0.120794</td>\n",
       "      <td>-0.385050</td>\n",
       "      <td>-0.069733</td>\n",
       "      <td>0.094199</td>\n",
       "      <td>0.246219</td>\n",
       "      <td>0.083076</td>\n",
       "      <td>3.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.449044</td>\n",
       "      <td>-1.176339</td>\n",
       "      <td>0.913860</td>\n",
       "      <td>-1.375667</td>\n",
       "      <td>-1.971383</td>\n",
       "      <td>-0.629152</td>\n",
       "      <td>-1.423236</td>\n",
       "      <td>0.048456</td>\n",
       "      <td>-1.720408</td>\n",
       "      <td>1.626659</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.313894</td>\n",
       "      <td>0.027740</td>\n",
       "      <td>0.500512</td>\n",
       "      <td>0.251367</td>\n",
       "      <td>-0.129478</td>\n",
       "      <td>0.042850</td>\n",
       "      <td>0.016253</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.384978</td>\n",
       "      <td>0.616109</td>\n",
       "      <td>-0.874300</td>\n",
       "      <td>-0.094019</td>\n",
       "      <td>2.924584</td>\n",
       "      <td>3.317027</td>\n",
       "      <td>0.470455</td>\n",
       "      <td>0.538247</td>\n",
       "      <td>-0.558895</td>\n",
       "      <td>0.309755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049924</td>\n",
       "      <td>0.238422</td>\n",
       "      <td>0.009130</td>\n",
       "      <td>0.996710</td>\n",
       "      <td>-0.767315</td>\n",
       "      <td>-0.492208</td>\n",
       "      <td>0.042472</td>\n",
       "      <td>-0.054337</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.249999</td>\n",
       "      <td>-1.221637</td>\n",
       "      <td>0.383930</td>\n",
       "      <td>-1.234899</td>\n",
       "      <td>-1.485419</td>\n",
       "      <td>-0.753230</td>\n",
       "      <td>-0.689405</td>\n",
       "      <td>-0.227487</td>\n",
       "      <td>-2.094011</td>\n",
       "      <td>1.323729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.231809</td>\n",
       "      <td>-0.483285</td>\n",
       "      <td>0.084668</td>\n",
       "      <td>0.392831</td>\n",
       "      <td>0.161135</td>\n",
       "      <td>-0.354990</td>\n",
       "      <td>0.026416</td>\n",
       "      <td>0.042422</td>\n",
       "      <td>121.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.069374</td>\n",
       "      <td>0.287722</td>\n",
       "      <td>0.828613</td>\n",
       "      <td>2.712520</td>\n",
       "      <td>-0.178398</td>\n",
       "      <td>0.337544</td>\n",
       "      <td>-0.096717</td>\n",
       "      <td>0.115982</td>\n",
       "      <td>-0.221083</td>\n",
       "      <td>0.460230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.036876</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.071407</td>\n",
       "      <td>0.104744</td>\n",
       "      <td>0.548265</td>\n",
       "      <td>0.104094</td>\n",
       "      <td>0.021491</td>\n",
       "      <td>0.021293</td>\n",
       "      <td>27.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-2.791855</td>\n",
       "      <td>-0.327771</td>\n",
       "      <td>1.641750</td>\n",
       "      <td>1.767473</td>\n",
       "      <td>-0.136588</td>\n",
       "      <td>0.807596</td>\n",
       "      <td>-0.422911</td>\n",
       "      <td>-1.907107</td>\n",
       "      <td>0.755713</td>\n",
       "      <td>1.151087</td>\n",
       "      <td>...</td>\n",
       "      <td>1.151663</td>\n",
       "      <td>0.222182</td>\n",
       "      <td>1.020586</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>-0.232746</td>\n",
       "      <td>-0.235557</td>\n",
       "      <td>-0.164778</td>\n",
       "      <td>-0.030154</td>\n",
       "      <td>58.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.752417</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>2.057323</td>\n",
       "      <td>-1.468643</td>\n",
       "      <td>-1.158394</td>\n",
       "      <td>-0.077850</td>\n",
       "      <td>-0.608581</td>\n",
       "      <td>0.003603</td>\n",
       "      <td>-0.436167</td>\n",
       "      <td>0.747731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.499625</td>\n",
       "      <td>1.353650</td>\n",
       "      <td>-0.256573</td>\n",
       "      <td>-0.065084</td>\n",
       "      <td>-0.039124</td>\n",
       "      <td>-0.087086</td>\n",
       "      <td>-0.180998</td>\n",
       "      <td>0.129394</td>\n",
       "      <td>15.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.103215</td>\n",
       "      <td>-0.040296</td>\n",
       "      <td>1.267332</td>\n",
       "      <td>1.289091</td>\n",
       "      <td>-0.735997</td>\n",
       "      <td>0.288069</td>\n",
       "      <td>-0.586057</td>\n",
       "      <td>0.189380</td>\n",
       "      <td>0.782333</td>\n",
       "      <td>-0.267975</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024612</td>\n",
       "      <td>0.196002</td>\n",
       "      <td>0.013802</td>\n",
       "      <td>0.103758</td>\n",
       "      <td>0.364298</td>\n",
       "      <td>-0.382261</td>\n",
       "      <td>0.092809</td>\n",
       "      <td>0.037051</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.436905</td>\n",
       "      <td>0.918966</td>\n",
       "      <td>0.924591</td>\n",
       "      <td>-0.727219</td>\n",
       "      <td>0.915679</td>\n",
       "      <td>-0.127867</td>\n",
       "      <td>0.707642</td>\n",
       "      <td>0.087962</td>\n",
       "      <td>-0.665271</td>\n",
       "      <td>-0.737980</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194796</td>\n",
       "      <td>-0.672638</td>\n",
       "      <td>-0.156858</td>\n",
       "      <td>-0.888386</td>\n",
       "      <td>-0.342413</td>\n",
       "      <td>-0.049027</td>\n",
       "      <td>0.079692</td>\n",
       "      <td>0.131024</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-5.401258</td>\n",
       "      <td>-5.450148</td>\n",
       "      <td>1.186305</td>\n",
       "      <td>1.736239</td>\n",
       "      <td>3.049106</td>\n",
       "      <td>-1.763406</td>\n",
       "      <td>-1.559738</td>\n",
       "      <td>0.160842</td>\n",
       "      <td>1.233090</td>\n",
       "      <td>0.345173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.503600</td>\n",
       "      <td>0.984460</td>\n",
       "      <td>2.458589</td>\n",
       "      <td>0.042119</td>\n",
       "      <td>-0.481631</td>\n",
       "      <td>-0.621272</td>\n",
       "      <td>0.392053</td>\n",
       "      <td>0.949594</td>\n",
       "      <td>46.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.492936</td>\n",
       "      <td>-1.029346</td>\n",
       "      <td>0.454795</td>\n",
       "      <td>-1.438026</td>\n",
       "      <td>-1.555434</td>\n",
       "      <td>-0.720961</td>\n",
       "      <td>-1.080664</td>\n",
       "      <td>-0.053127</td>\n",
       "      <td>-1.978682</td>\n",
       "      <td>1.638076</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.177650</td>\n",
       "      <td>-0.175074</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.295814</td>\n",
       "      <td>0.332931</td>\n",
       "      <td>-0.220385</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.007602</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.694885</td>\n",
       "      <td>-1.361819</td>\n",
       "      <td>1.029221</td>\n",
       "      <td>0.834159</td>\n",
       "      <td>-1.191209</td>\n",
       "      <td>1.309109</td>\n",
       "      <td>-0.878586</td>\n",
       "      <td>0.445290</td>\n",
       "      <td>-0.446196</td>\n",
       "      <td>0.568521</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.295583</td>\n",
       "      <td>-0.571955</td>\n",
       "      <td>-0.050881</td>\n",
       "      <td>-0.304215</td>\n",
       "      <td>0.072001</td>\n",
       "      <td>-0.422234</td>\n",
       "      <td>0.086553</td>\n",
       "      <td>0.063499</td>\n",
       "      <td>231.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.962496</td>\n",
       "      <td>0.328461</td>\n",
       "      <td>-0.171479</td>\n",
       "      <td>2.109204</td>\n",
       "      <td>1.129566</td>\n",
       "      <td>1.696038</td>\n",
       "      <td>0.107712</td>\n",
       "      <td>0.521502</td>\n",
       "      <td>-1.191311</td>\n",
       "      <td>0.724396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143997</td>\n",
       "      <td>0.402492</td>\n",
       "      <td>-0.048508</td>\n",
       "      <td>-1.371866</td>\n",
       "      <td>0.390814</td>\n",
       "      <td>0.199964</td>\n",
       "      <td>0.016371</td>\n",
       "      <td>-0.014605</td>\n",
       "      <td>34.09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.166616</td>\n",
       "      <td>0.502120</td>\n",
       "      <td>-0.067300</td>\n",
       "      <td>2.261569</td>\n",
       "      <td>0.428804</td>\n",
       "      <td>0.089474</td>\n",
       "      <td>0.241147</td>\n",
       "      <td>0.138082</td>\n",
       "      <td>-0.989162</td>\n",
       "      <td>0.922175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018702</td>\n",
       "      <td>-0.061972</td>\n",
       "      <td>-0.103855</td>\n",
       "      <td>-0.370415</td>\n",
       "      <td>0.603200</td>\n",
       "      <td>0.108556</td>\n",
       "      <td>-0.040521</td>\n",
       "      <td>-0.011418</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.247491</td>\n",
       "      <td>0.277666</td>\n",
       "      <td>1.185471</td>\n",
       "      <td>-0.092603</td>\n",
       "      <td>-1.314394</td>\n",
       "      <td>-0.150116</td>\n",
       "      <td>-0.946365</td>\n",
       "      <td>-1.617935</td>\n",
       "      <td>1.544071</td>\n",
       "      <td>-0.829881</td>\n",
       "      <td>...</td>\n",
       "      <td>1.650180</td>\n",
       "      <td>0.200454</td>\n",
       "      <td>-0.185353</td>\n",
       "      <td>0.423073</td>\n",
       "      <td>0.820591</td>\n",
       "      <td>-0.227632</td>\n",
       "      <td>0.336634</td>\n",
       "      <td>0.250475</td>\n",
       "      <td>22.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-1.946525</td>\n",
       "      <td>-0.044901</td>\n",
       "      <td>-0.405570</td>\n",
       "      <td>-1.013057</td>\n",
       "      <td>2.941968</td>\n",
       "      <td>2.955053</td>\n",
       "      <td>-0.063063</td>\n",
       "      <td>0.855546</td>\n",
       "      <td>0.049967</td>\n",
       "      <td>0.573743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.579526</td>\n",
       "      <td>-0.799229</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.983421</td>\n",
       "      <td>0.321201</td>\n",
       "      <td>0.149650</td>\n",
       "      <td>0.707519</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-2.074295</td>\n",
       "      <td>-0.121482</td>\n",
       "      <td>1.322021</td>\n",
       "      <td>0.410008</td>\n",
       "      <td>0.295198</td>\n",
       "      <td>-0.959537</td>\n",
       "      <td>0.543985</td>\n",
       "      <td>-0.104627</td>\n",
       "      <td>0.475664</td>\n",
       "      <td>0.149451</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.403639</td>\n",
       "      <td>-0.227404</td>\n",
       "      <td>0.742435</td>\n",
       "      <td>0.398535</td>\n",
       "      <td>0.249212</td>\n",
       "      <td>0.274404</td>\n",
       "      <td>0.359969</td>\n",
       "      <td>0.243232</td>\n",
       "      <td>26.43</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.173285</td>\n",
       "      <td>0.353498</td>\n",
       "      <td>0.283905</td>\n",
       "      <td>1.133563</td>\n",
       "      <td>-0.172577</td>\n",
       "      <td>-0.916054</td>\n",
       "      <td>0.369025</td>\n",
       "      <td>-0.327260</td>\n",
       "      <td>-0.246651</td>\n",
       "      <td>-0.046139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067003</td>\n",
       "      <td>0.227812</td>\n",
       "      <td>-0.150487</td>\n",
       "      <td>0.435045</td>\n",
       "      <td>0.724825</td>\n",
       "      <td>-0.337082</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>41.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.322707</td>\n",
       "      <td>-0.174041</td>\n",
       "      <td>0.434555</td>\n",
       "      <td>0.576038</td>\n",
       "      <td>-0.836758</td>\n",
       "      <td>-0.831083</td>\n",
       "      <td>-0.264905</td>\n",
       "      <td>-0.220982</td>\n",
       "      <td>-1.071425</td>\n",
       "      <td>0.868559</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284376</td>\n",
       "      <td>-0.323357</td>\n",
       "      <td>-0.037710</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.559639</td>\n",
       "      <td>-0.280158</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.028822</td>\n",
       "      <td>16.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.414289</td>\n",
       "      <td>0.905437</td>\n",
       "      <td>1.727453</td>\n",
       "      <td>1.473471</td>\n",
       "      <td>0.007443</td>\n",
       "      <td>-0.200331</td>\n",
       "      <td>0.740228</td>\n",
       "      <td>-0.029247</td>\n",
       "      <td>-0.593392</td>\n",
       "      <td>-0.346188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077237</td>\n",
       "      <td>0.457331</td>\n",
       "      <td>-0.038500</td>\n",
       "      <td>0.642522</td>\n",
       "      <td>-0.183891</td>\n",
       "      <td>-0.277464</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.152665</td>\n",
       "      <td>33.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.059387</td>\n",
       "      <td>-0.175319</td>\n",
       "      <td>1.266130</td>\n",
       "      <td>1.186110</td>\n",
       "      <td>-0.786002</td>\n",
       "      <td>0.578435</td>\n",
       "      <td>-0.767084</td>\n",
       "      <td>0.401046</td>\n",
       "      <td>0.699500</td>\n",
       "      <td>-0.064738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013676</td>\n",
       "      <td>0.213734</td>\n",
       "      <td>0.014462</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.294638</td>\n",
       "      <td>-0.395070</td>\n",
       "      <td>0.081461</td>\n",
       "      <td>0.024220</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284777</th>\n",
       "      <td>2.079137</td>\n",
       "      <td>-0.028723</td>\n",
       "      <td>-1.343392</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>-0.045791</td>\n",
       "      <td>-1.345452</td>\n",
       "      <td>0.227476</td>\n",
       "      <td>-0.378355</td>\n",
       "      <td>0.665911</td>\n",
       "      <td>0.028351</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235758</td>\n",
       "      <td>0.829758</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>0.262183</td>\n",
       "      <td>-0.105327</td>\n",
       "      <td>-0.022363</td>\n",
       "      <td>-0.060283</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284778</th>\n",
       "      <td>-0.764523</td>\n",
       "      <td>0.588379</td>\n",
       "      <td>-0.907599</td>\n",
       "      <td>-0.418847</td>\n",
       "      <td>0.901528</td>\n",
       "      <td>-0.760802</td>\n",
       "      <td>0.758545</td>\n",
       "      <td>0.414698</td>\n",
       "      <td>-0.730854</td>\n",
       "      <td>-1.245088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>-0.431876</td>\n",
       "      <td>0.141759</td>\n",
       "      <td>0.587119</td>\n",
       "      <td>-0.200998</td>\n",
       "      <td>0.267337</td>\n",
       "      <td>-0.152951</td>\n",
       "      <td>-0.065285</td>\n",
       "      <td>80.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284779</th>\n",
       "      <td>1.975178</td>\n",
       "      <td>-0.616244</td>\n",
       "      <td>-2.628295</td>\n",
       "      <td>-0.406246</td>\n",
       "      <td>2.327804</td>\n",
       "      <td>3.664740</td>\n",
       "      <td>-0.533297</td>\n",
       "      <td>0.842937</td>\n",
       "      <td>1.128798</td>\n",
       "      <td>-0.220744</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086043</td>\n",
       "      <td>0.543613</td>\n",
       "      <td>-0.032129</td>\n",
       "      <td>0.768379</td>\n",
       "      <td>0.477688</td>\n",
       "      <td>-0.031833</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>-0.066542</td>\n",
       "      <td>25.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284780</th>\n",
       "      <td>-1.727503</td>\n",
       "      <td>1.108356</td>\n",
       "      <td>2.219561</td>\n",
       "      <td>1.148583</td>\n",
       "      <td>-0.884199</td>\n",
       "      <td>0.793083</td>\n",
       "      <td>-0.527298</td>\n",
       "      <td>0.866429</td>\n",
       "      <td>0.853819</td>\n",
       "      <td>-0.195152</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094708</td>\n",
       "      <td>0.236818</td>\n",
       "      <td>-0.204280</td>\n",
       "      <td>1.158185</td>\n",
       "      <td>0.627801</td>\n",
       "      <td>-0.399981</td>\n",
       "      <td>0.510818</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>30.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284781</th>\n",
       "      <td>-1.139015</td>\n",
       "      <td>-0.155510</td>\n",
       "      <td>1.894478</td>\n",
       "      <td>-1.138957</td>\n",
       "      <td>1.451777</td>\n",
       "      <td>0.093598</td>\n",
       "      <td>0.191353</td>\n",
       "      <td>0.092211</td>\n",
       "      <td>-0.062621</td>\n",
       "      <td>-0.792066</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.191027</td>\n",
       "      <td>-0.631658</td>\n",
       "      <td>-0.147249</td>\n",
       "      <td>0.212931</td>\n",
       "      <td>0.354257</td>\n",
       "      <td>-0.241068</td>\n",
       "      <td>-0.161717</td>\n",
       "      <td>-0.149188</td>\n",
       "      <td>13.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284782</th>\n",
       "      <td>-0.268061</td>\n",
       "      <td>2.540315</td>\n",
       "      <td>-1.400915</td>\n",
       "      <td>4.846661</td>\n",
       "      <td>0.639105</td>\n",
       "      <td>0.186479</td>\n",
       "      <td>-0.045911</td>\n",
       "      <td>0.936448</td>\n",
       "      <td>-2.419986</td>\n",
       "      <td>0.525012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263889</td>\n",
       "      <td>-0.857904</td>\n",
       "      <td>0.235172</td>\n",
       "      <td>-0.681794</td>\n",
       "      <td>-0.668894</td>\n",
       "      <td>0.044657</td>\n",
       "      <td>-0.066751</td>\n",
       "      <td>-0.072447</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284783</th>\n",
       "      <td>-1.796092</td>\n",
       "      <td>1.929178</td>\n",
       "      <td>-2.828417</td>\n",
       "      <td>-1.689844</td>\n",
       "      <td>2.199572</td>\n",
       "      <td>3.123732</td>\n",
       "      <td>-0.270714</td>\n",
       "      <td>1.657495</td>\n",
       "      <td>0.465804</td>\n",
       "      <td>0.832931</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271170</td>\n",
       "      <td>1.145750</td>\n",
       "      <td>0.084783</td>\n",
       "      <td>0.721269</td>\n",
       "      <td>-0.529906</td>\n",
       "      <td>-0.240117</td>\n",
       "      <td>0.129126</td>\n",
       "      <td>-0.080620</td>\n",
       "      <td>11.46</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284784</th>\n",
       "      <td>-0.669662</td>\n",
       "      <td>0.923769</td>\n",
       "      <td>-1.543167</td>\n",
       "      <td>-1.560729</td>\n",
       "      <td>2.833960</td>\n",
       "      <td>3.240843</td>\n",
       "      <td>0.181576</td>\n",
       "      <td>1.282746</td>\n",
       "      <td>-0.893890</td>\n",
       "      <td>-1.453432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.183856</td>\n",
       "      <td>0.202670</td>\n",
       "      <td>-0.373023</td>\n",
       "      <td>0.651122</td>\n",
       "      <td>1.073823</td>\n",
       "      <td>0.844590</td>\n",
       "      <td>-0.286676</td>\n",
       "      <td>-0.187719</td>\n",
       "      <td>40.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284785</th>\n",
       "      <td>0.032887</td>\n",
       "      <td>0.545338</td>\n",
       "      <td>-1.185844</td>\n",
       "      <td>-1.729828</td>\n",
       "      <td>2.932315</td>\n",
       "      <td>3.401529</td>\n",
       "      <td>0.337434</td>\n",
       "      <td>0.925377</td>\n",
       "      <td>-0.165663</td>\n",
       "      <td>-0.386953</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.266113</td>\n",
       "      <td>-0.716336</td>\n",
       "      <td>0.108519</td>\n",
       "      <td>0.688519</td>\n",
       "      <td>-0.460220</td>\n",
       "      <td>0.161939</td>\n",
       "      <td>0.265368</td>\n",
       "      <td>0.090245</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284786</th>\n",
       "      <td>-2.076175</td>\n",
       "      <td>2.142238</td>\n",
       "      <td>-2.522704</td>\n",
       "      <td>-1.888063</td>\n",
       "      <td>1.982785</td>\n",
       "      <td>3.732950</td>\n",
       "      <td>-1.217430</td>\n",
       "      <td>-0.536644</td>\n",
       "      <td>0.272867</td>\n",
       "      <td>0.300342</td>\n",
       "      <td>...</td>\n",
       "      <td>2.016666</td>\n",
       "      <td>-1.588269</td>\n",
       "      <td>0.588482</td>\n",
       "      <td>0.632444</td>\n",
       "      <td>-0.201064</td>\n",
       "      <td>0.199251</td>\n",
       "      <td>0.438657</td>\n",
       "      <td>0.172923</td>\n",
       "      <td>8.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284787</th>\n",
       "      <td>-1.029719</td>\n",
       "      <td>-1.110670</td>\n",
       "      <td>-0.636179</td>\n",
       "      <td>-0.840816</td>\n",
       "      <td>2.424360</td>\n",
       "      <td>-2.956733</td>\n",
       "      <td>0.283610</td>\n",
       "      <td>-0.332656</td>\n",
       "      <td>-0.247488</td>\n",
       "      <td>-0.328271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.353722</td>\n",
       "      <td>0.488487</td>\n",
       "      <td>0.293632</td>\n",
       "      <td>0.107812</td>\n",
       "      <td>-0.935586</td>\n",
       "      <td>1.138216</td>\n",
       "      <td>0.025271</td>\n",
       "      <td>0.255347</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284788</th>\n",
       "      <td>2.007418</td>\n",
       "      <td>-0.280235</td>\n",
       "      <td>-0.208113</td>\n",
       "      <td>0.335261</td>\n",
       "      <td>-0.715798</td>\n",
       "      <td>-0.751373</td>\n",
       "      <td>-0.458972</td>\n",
       "      <td>-0.140140</td>\n",
       "      <td>0.959971</td>\n",
       "      <td>-0.028284</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208260</td>\n",
       "      <td>-0.430347</td>\n",
       "      <td>0.416765</td>\n",
       "      <td>0.064819</td>\n",
       "      <td>-0.608337</td>\n",
       "      <td>0.268436</td>\n",
       "      <td>-0.028069</td>\n",
       "      <td>-0.041367</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284789</th>\n",
       "      <td>-0.446951</td>\n",
       "      <td>1.302212</td>\n",
       "      <td>-0.168583</td>\n",
       "      <td>0.981577</td>\n",
       "      <td>0.578957</td>\n",
       "      <td>-0.605641</td>\n",
       "      <td>1.253430</td>\n",
       "      <td>-1.042610</td>\n",
       "      <td>-0.417116</td>\n",
       "      <td>0.076605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851800</td>\n",
       "      <td>0.305268</td>\n",
       "      <td>-0.148093</td>\n",
       "      <td>-0.038712</td>\n",
       "      <td>0.010209</td>\n",
       "      <td>-0.362666</td>\n",
       "      <td>0.503092</td>\n",
       "      <td>0.229921</td>\n",
       "      <td>60.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284790</th>\n",
       "      <td>-0.515513</td>\n",
       "      <td>0.971950</td>\n",
       "      <td>-1.014580</td>\n",
       "      <td>-0.677037</td>\n",
       "      <td>0.912430</td>\n",
       "      <td>-0.316187</td>\n",
       "      <td>0.396137</td>\n",
       "      <td>0.532364</td>\n",
       "      <td>-0.224606</td>\n",
       "      <td>-0.753365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.280302</td>\n",
       "      <td>-0.849919</td>\n",
       "      <td>0.300245</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>-0.376379</td>\n",
       "      <td>0.128660</td>\n",
       "      <td>-0.015205</td>\n",
       "      <td>-0.021486</td>\n",
       "      <td>9.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284791</th>\n",
       "      <td>-0.863506</td>\n",
       "      <td>0.874701</td>\n",
       "      <td>0.420358</td>\n",
       "      <td>-0.530365</td>\n",
       "      <td>0.356561</td>\n",
       "      <td>-1.046238</td>\n",
       "      <td>0.757051</td>\n",
       "      <td>0.230473</td>\n",
       "      <td>-0.506856</td>\n",
       "      <td>-1.032990</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108846</td>\n",
       "      <td>-0.480820</td>\n",
       "      <td>-0.074513</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>-0.113149</td>\n",
       "      <td>0.280378</td>\n",
       "      <td>-0.077310</td>\n",
       "      <td>0.023079</td>\n",
       "      <td>20.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284792</th>\n",
       "      <td>-0.724123</td>\n",
       "      <td>1.485216</td>\n",
       "      <td>-1.132218</td>\n",
       "      <td>-0.607190</td>\n",
       "      <td>0.709499</td>\n",
       "      <td>-0.482638</td>\n",
       "      <td>0.548393</td>\n",
       "      <td>0.343003</td>\n",
       "      <td>-0.226323</td>\n",
       "      <td>-0.348134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.414621</td>\n",
       "      <td>1.307511</td>\n",
       "      <td>-0.059545</td>\n",
       "      <td>0.242669</td>\n",
       "      <td>-0.665424</td>\n",
       "      <td>-0.269869</td>\n",
       "      <td>-0.170579</td>\n",
       "      <td>-0.030692</td>\n",
       "      <td>3.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284793</th>\n",
       "      <td>1.971002</td>\n",
       "      <td>-0.699067</td>\n",
       "      <td>-1.697541</td>\n",
       "      <td>-0.617643</td>\n",
       "      <td>1.718797</td>\n",
       "      <td>3.911336</td>\n",
       "      <td>-1.259306</td>\n",
       "      <td>1.056209</td>\n",
       "      <td>1.315006</td>\n",
       "      <td>-0.146827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188758</td>\n",
       "      <td>0.694418</td>\n",
       "      <td>0.163002</td>\n",
       "      <td>0.726365</td>\n",
       "      <td>-0.058282</td>\n",
       "      <td>-0.191813</td>\n",
       "      <td>0.061858</td>\n",
       "      <td>-0.043716</td>\n",
       "      <td>4.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284794</th>\n",
       "      <td>-1.266580</td>\n",
       "      <td>-0.400461</td>\n",
       "      <td>0.956221</td>\n",
       "      <td>-0.723919</td>\n",
       "      <td>1.531993</td>\n",
       "      <td>-1.788600</td>\n",
       "      <td>0.314741</td>\n",
       "      <td>0.004704</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>-0.815911</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.157831</td>\n",
       "      <td>-0.883365</td>\n",
       "      <td>0.088485</td>\n",
       "      <td>-0.076790</td>\n",
       "      <td>-0.095833</td>\n",
       "      <td>0.132720</td>\n",
       "      <td>-0.028468</td>\n",
       "      <td>0.126494</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284795</th>\n",
       "      <td>-12.516732</td>\n",
       "      <td>10.187818</td>\n",
       "      <td>-8.476671</td>\n",
       "      <td>-2.510473</td>\n",
       "      <td>-4.586669</td>\n",
       "      <td>-1.394465</td>\n",
       "      <td>-3.632516</td>\n",
       "      <td>5.498583</td>\n",
       "      <td>4.893089</td>\n",
       "      <td>8.655320</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.944759</td>\n",
       "      <td>-1.565026</td>\n",
       "      <td>0.890675</td>\n",
       "      <td>-1.253276</td>\n",
       "      <td>1.786717</td>\n",
       "      <td>0.320763</td>\n",
       "      <td>2.090712</td>\n",
       "      <td>1.232864</td>\n",
       "      <td>9.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284796</th>\n",
       "      <td>1.884849</td>\n",
       "      <td>-0.143540</td>\n",
       "      <td>-0.999943</td>\n",
       "      <td>1.506772</td>\n",
       "      <td>-0.035300</td>\n",
       "      <td>-0.613638</td>\n",
       "      <td>0.190241</td>\n",
       "      <td>-0.249058</td>\n",
       "      <td>0.666458</td>\n",
       "      <td>0.120908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.144008</td>\n",
       "      <td>0.634646</td>\n",
       "      <td>-0.042114</td>\n",
       "      <td>-0.053206</td>\n",
       "      <td>0.316403</td>\n",
       "      <td>-0.461441</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>-0.041068</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284797</th>\n",
       "      <td>-0.241923</td>\n",
       "      <td>0.712247</td>\n",
       "      <td>0.399806</td>\n",
       "      <td>-0.463406</td>\n",
       "      <td>0.244531</td>\n",
       "      <td>-1.343668</td>\n",
       "      <td>0.929369</td>\n",
       "      <td>-0.206210</td>\n",
       "      <td>0.106234</td>\n",
       "      <td>-0.284708</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228876</td>\n",
       "      <td>-0.514376</td>\n",
       "      <td>0.279598</td>\n",
       "      <td>0.371441</td>\n",
       "      <td>-0.559238</td>\n",
       "      <td>0.113144</td>\n",
       "      <td>0.131507</td>\n",
       "      <td>0.081265</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284798</th>\n",
       "      <td>0.219529</td>\n",
       "      <td>0.881246</td>\n",
       "      <td>-0.635891</td>\n",
       "      <td>0.960928</td>\n",
       "      <td>-0.152971</td>\n",
       "      <td>-1.014307</td>\n",
       "      <td>0.427126</td>\n",
       "      <td>0.121340</td>\n",
       "      <td>-0.285670</td>\n",
       "      <td>-0.111640</td>\n",
       "      <td>...</td>\n",
       "      <td>0.099936</td>\n",
       "      <td>0.337120</td>\n",
       "      <td>0.251791</td>\n",
       "      <td>0.057688</td>\n",
       "      <td>-1.508368</td>\n",
       "      <td>0.144023</td>\n",
       "      <td>0.181205</td>\n",
       "      <td>0.215243</td>\n",
       "      <td>24.05</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284799</th>\n",
       "      <td>-1.775135</td>\n",
       "      <td>-0.004235</td>\n",
       "      <td>1.189786</td>\n",
       "      <td>0.331096</td>\n",
       "      <td>1.196063</td>\n",
       "      <td>5.519980</td>\n",
       "      <td>-1.518185</td>\n",
       "      <td>2.080825</td>\n",
       "      <td>1.159498</td>\n",
       "      <td>-0.594242</td>\n",
       "      <td>...</td>\n",
       "      <td>0.103302</td>\n",
       "      <td>0.654850</td>\n",
       "      <td>-0.348929</td>\n",
       "      <td>0.745323</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>-0.127579</td>\n",
       "      <td>0.454379</td>\n",
       "      <td>0.130308</td>\n",
       "      <td>79.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284800</th>\n",
       "      <td>2.039560</td>\n",
       "      <td>-0.175233</td>\n",
       "      <td>-1.196825</td>\n",
       "      <td>0.234580</td>\n",
       "      <td>-0.008713</td>\n",
       "      <td>-0.726571</td>\n",
       "      <td>0.017050</td>\n",
       "      <td>-0.118228</td>\n",
       "      <td>0.435402</td>\n",
       "      <td>0.267772</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268048</td>\n",
       "      <td>-0.717211</td>\n",
       "      <td>0.297930</td>\n",
       "      <td>-0.359769</td>\n",
       "      <td>-0.315610</td>\n",
       "      <td>0.201114</td>\n",
       "      <td>-0.080826</td>\n",
       "      <td>-0.075071</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284801</th>\n",
       "      <td>0.120316</td>\n",
       "      <td>0.931005</td>\n",
       "      <td>-0.546012</td>\n",
       "      <td>-0.745097</td>\n",
       "      <td>1.130314</td>\n",
       "      <td>-0.235973</td>\n",
       "      <td>0.812722</td>\n",
       "      <td>0.115093</td>\n",
       "      <td>-0.204064</td>\n",
       "      <td>-0.657422</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314205</td>\n",
       "      <td>-0.808520</td>\n",
       "      <td>0.050343</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>-0.435870</td>\n",
       "      <td>0.124079</td>\n",
       "      <td>0.217940</td>\n",
       "      <td>0.068803</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-11.881118</td>\n",
       "      <td>10.071785</td>\n",
       "      <td>-9.834783</td>\n",
       "      <td>-2.066656</td>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>1.914428</td>\n",
       "      <td>4.356170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213454</td>\n",
       "      <td>0.111864</td>\n",
       "      <td>1.014480</td>\n",
       "      <td>-0.509348</td>\n",
       "      <td>1.436807</td>\n",
       "      <td>0.250034</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>-0.732789</td>\n",
       "      <td>-0.055080</td>\n",
       "      <td>2.035030</td>\n",
       "      <td>-0.738589</td>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.584800</td>\n",
       "      <td>-0.975926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214205</td>\n",
       "      <td>0.924384</td>\n",
       "      <td>0.012463</td>\n",
       "      <td>-1.016226</td>\n",
       "      <td>-0.606624</td>\n",
       "      <td>-0.395255</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>24.79</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>1.919565</td>\n",
       "      <td>-0.301254</td>\n",
       "      <td>-3.249640</td>\n",
       "      <td>-0.557828</td>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.432454</td>\n",
       "      <td>-0.484782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.232045</td>\n",
       "      <td>0.578229</td>\n",
       "      <td>-0.037501</td>\n",
       "      <td>0.640134</td>\n",
       "      <td>0.265745</td>\n",
       "      <td>-0.087371</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>67.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.240440</td>\n",
       "      <td>0.530483</td>\n",
       "      <td>0.702510</td>\n",
       "      <td>0.689799</td>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.392087</td>\n",
       "      <td>-0.399126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.265245</td>\n",
       "      <td>0.800049</td>\n",
       "      <td>-0.163298</td>\n",
       "      <td>0.123205</td>\n",
       "      <td>-0.569159</td>\n",
       "      <td>0.546668</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.533413</td>\n",
       "      <td>-0.189733</td>\n",
       "      <td>0.703337</td>\n",
       "      <td>-0.506271</td>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>0.486180</td>\n",
       "      <td>-0.915427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261057</td>\n",
       "      <td>0.643078</td>\n",
       "      <td>0.376777</td>\n",
       "      <td>0.008797</td>\n",
       "      <td>-0.473649</td>\n",
       "      <td>-0.818267</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>217.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               V1         V2        V3        V4        V5        V6  \\\n",
       "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "5       -0.425966   0.960523  1.141109 -0.168252  0.420987 -0.029728   \n",
       "6        1.229658   0.141004  0.045371  1.202613  0.191881  0.272708   \n",
       "7       -0.644269   1.417964  1.074380 -0.492199  0.948934  0.428118   \n",
       "8       -0.894286   0.286157 -0.113192 -0.271526  2.669599  3.721818   \n",
       "9       -0.338262   1.119593  1.044367 -0.222187  0.499361 -0.246761   \n",
       "10       1.449044  -1.176339  0.913860 -1.375667 -1.971383 -0.629152   \n",
       "11       0.384978   0.616109 -0.874300 -0.094019  2.924584  3.317027   \n",
       "12       1.249999  -1.221637  0.383930 -1.234899 -1.485419 -0.753230   \n",
       "13       1.069374   0.287722  0.828613  2.712520 -0.178398  0.337544   \n",
       "14      -2.791855  -0.327771  1.641750  1.767473 -0.136588  0.807596   \n",
       "15      -0.752417   0.345485  2.057323 -1.468643 -1.158394 -0.077850   \n",
       "16       1.103215  -0.040296  1.267332  1.289091 -0.735997  0.288069   \n",
       "17      -0.436905   0.918966  0.924591 -0.727219  0.915679 -0.127867   \n",
       "18      -5.401258  -5.450148  1.186305  1.736239  3.049106 -1.763406   \n",
       "19       1.492936  -1.029346  0.454795 -1.438026 -1.555434 -0.720961   \n",
       "20       0.694885  -1.361819  1.029221  0.834159 -1.191209  1.309109   \n",
       "21       0.962496   0.328461 -0.171479  2.109204  1.129566  1.696038   \n",
       "22       1.166616   0.502120 -0.067300  2.261569  0.428804  0.089474   \n",
       "23       0.247491   0.277666  1.185471 -0.092603 -1.314394 -0.150116   \n",
       "24      -1.946525  -0.044901 -0.405570 -1.013057  2.941968  2.955053   \n",
       "25      -2.074295  -0.121482  1.322021  0.410008  0.295198 -0.959537   \n",
       "26       1.173285   0.353498  0.283905  1.133563 -0.172577 -0.916054   \n",
       "27       1.322707  -0.174041  0.434555  0.576038 -0.836758 -0.831083   \n",
       "28      -0.414289   0.905437  1.727453  1.473471  0.007443 -0.200331   \n",
       "29       1.059387  -0.175319  1.266130  1.186110 -0.786002  0.578435   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "284777   2.079137  -0.028723 -1.343392  0.358000 -0.045791 -1.345452   \n",
       "284778  -0.764523   0.588379 -0.907599 -0.418847  0.901528 -0.760802   \n",
       "284779   1.975178  -0.616244 -2.628295 -0.406246  2.327804  3.664740   \n",
       "284780  -1.727503   1.108356  2.219561  1.148583 -0.884199  0.793083   \n",
       "284781  -1.139015  -0.155510  1.894478 -1.138957  1.451777  0.093598   \n",
       "284782  -0.268061   2.540315 -1.400915  4.846661  0.639105  0.186479   \n",
       "284783  -1.796092   1.929178 -2.828417 -1.689844  2.199572  3.123732   \n",
       "284784  -0.669662   0.923769 -1.543167 -1.560729  2.833960  3.240843   \n",
       "284785   0.032887   0.545338 -1.185844 -1.729828  2.932315  3.401529   \n",
       "284786  -2.076175   2.142238 -2.522704 -1.888063  1.982785  3.732950   \n",
       "284787  -1.029719  -1.110670 -0.636179 -0.840816  2.424360 -2.956733   \n",
       "284788   2.007418  -0.280235 -0.208113  0.335261 -0.715798 -0.751373   \n",
       "284789  -0.446951   1.302212 -0.168583  0.981577  0.578957 -0.605641   \n",
       "284790  -0.515513   0.971950 -1.014580 -0.677037  0.912430 -0.316187   \n",
       "284791  -0.863506   0.874701  0.420358 -0.530365  0.356561 -1.046238   \n",
       "284792  -0.724123   1.485216 -1.132218 -0.607190  0.709499 -0.482638   \n",
       "284793   1.971002  -0.699067 -1.697541 -0.617643  1.718797  3.911336   \n",
       "284794  -1.266580  -0.400461  0.956221 -0.723919  1.531993 -1.788600   \n",
       "284795 -12.516732  10.187818 -8.476671 -2.510473 -4.586669 -1.394465   \n",
       "284796   1.884849  -0.143540 -0.999943  1.506772 -0.035300 -0.613638   \n",
       "284797  -0.241923   0.712247  0.399806 -0.463406  0.244531 -1.343668   \n",
       "284798   0.219529   0.881246 -0.635891  0.960928 -0.152971 -1.014307   \n",
       "284799  -1.775135  -0.004235  1.189786  0.331096  1.196063  5.519980   \n",
       "284800   2.039560  -0.175233 -1.196825  0.234580 -0.008713 -0.726571   \n",
       "284801   0.120316   0.931005 -0.546012 -0.745097  1.130314 -0.235973   \n",
       "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
       "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
       "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
       "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
       "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
       "\n",
       "              V7        V8        V9       V10  ...       V21       V22  \\\n",
       "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
       "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
       "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
       "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
       "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
       "5       0.476201  0.260314 -0.568671 -0.371407  ... -0.208254 -0.559825   \n",
       "6      -0.005159  0.081213  0.464960 -0.099254  ... -0.167716 -0.270710   \n",
       "7       1.120631 -3.807864  0.615375  1.249376  ...  1.943465 -1.015455   \n",
       "8       0.370145  0.851084 -0.392048 -0.410430  ... -0.073425 -0.268092   \n",
       "9       0.651583  0.069539 -0.736727 -0.366846  ... -0.246914 -0.633753   \n",
       "10     -1.423236  0.048456 -1.720408  1.626659  ... -0.009302  0.313894   \n",
       "11      0.470455  0.538247 -0.558895  0.309755  ...  0.049924  0.238422   \n",
       "12     -0.689405 -0.227487 -2.094011  1.323729  ... -0.231809 -0.483285   \n",
       "13     -0.096717  0.115982 -0.221083  0.460230  ... -0.036876  0.074412   \n",
       "14     -0.422911 -1.907107  0.755713  1.151087  ...  1.151663  0.222182   \n",
       "15     -0.608581  0.003603 -0.436167  0.747731  ...  0.499625  1.353650   \n",
       "16     -0.586057  0.189380  0.782333 -0.267975  ... -0.024612  0.196002   \n",
       "17      0.707642  0.087962 -0.665271 -0.737980  ... -0.194796 -0.672638   \n",
       "18     -1.559738  0.160842  1.233090  0.345173  ... -0.503600  0.984460   \n",
       "19     -1.080664 -0.053127 -1.978682  1.638076  ... -0.177650 -0.175074   \n",
       "20     -0.878586  0.445290 -0.446196  0.568521  ... -0.295583 -0.571955   \n",
       "21      0.107712  0.521502 -1.191311  0.724396  ...  0.143997  0.402492   \n",
       "22      0.241147  0.138082 -0.989162  0.922175  ...  0.018702 -0.061972   \n",
       "23     -0.946365 -1.617935  1.544071 -0.829881  ...  1.650180  0.200454   \n",
       "24     -0.063063  0.855546  0.049967  0.573743  ... -0.579526 -0.799229   \n",
       "25      0.543985 -0.104627  0.475664  0.149451  ... -0.403639 -0.227404   \n",
       "26      0.369025 -0.327260 -0.246651 -0.046139  ...  0.067003  0.227812   \n",
       "27     -0.264905 -0.220982 -1.071425  0.868559  ... -0.284376 -0.323357   \n",
       "28      0.740228 -0.029247 -0.593392 -0.346188  ...  0.077237  0.457331   \n",
       "29     -0.767084  0.401046  0.699500 -0.064738  ...  0.013676  0.213734   \n",
       "...          ...       ...       ...       ...  ...       ...       ...   \n",
       "284777  0.227476 -0.378355  0.665911  0.028351  ...  0.235758  0.829758   \n",
       "284778  0.758545  0.414698 -0.730854 -1.245088  ...  0.003530 -0.431876   \n",
       "284779 -0.533297  0.842937  1.128798 -0.220744  ...  0.086043  0.543613   \n",
       "284780 -0.527298  0.866429  0.853819 -0.195152  ... -0.094708  0.236818   \n",
       "284781  0.191353  0.092211 -0.062621 -0.792066  ... -0.191027 -0.631658   \n",
       "284782 -0.045911  0.936448 -2.419986  0.525012  ... -0.263889 -0.857904   \n",
       "284783 -0.270714  1.657495  0.465804  0.832931  ...  0.271170  1.145750   \n",
       "284784  0.181576  1.282746 -0.893890 -1.453432  ...  0.183856  0.202670   \n",
       "284785  0.337434  0.925377 -0.165663 -0.386953  ... -0.266113 -0.716336   \n",
       "284786 -1.217430 -0.536644  0.272867  0.300342  ...  2.016666 -1.588269   \n",
       "284787  0.283610 -0.332656 -0.247488 -0.328271  ...  0.353722  0.488487   \n",
       "284788 -0.458972 -0.140140  0.959971 -0.028284  ... -0.208260 -0.430347   \n",
       "284789  1.253430 -1.042610 -0.417116  0.076605  ...  0.851800  0.305268   \n",
       "284790  0.396137  0.532364 -0.224606 -0.753365  ... -0.280302 -0.849919   \n",
       "284791  0.757051  0.230473 -0.506856 -1.032990  ... -0.108846 -0.480820   \n",
       "284792  0.548393  0.343003 -0.226323 -0.348134  ...  0.414621  1.307511   \n",
       "284793 -1.259306  1.056209  1.315006 -0.146827  ...  0.188758  0.694418   \n",
       "284794  0.314741  0.004704  0.013857 -0.815911  ... -0.157831 -0.883365   \n",
       "284795 -3.632516  5.498583  4.893089  8.655320  ... -0.944759 -1.565026   \n",
       "284796  0.190241 -0.249058  0.666458  0.120908  ...  0.144008  0.634646   \n",
       "284797  0.929369 -0.206210  0.106234 -0.284708  ... -0.228876 -0.514376   \n",
       "284798  0.427126  0.121340 -0.285670 -0.111640  ...  0.099936  0.337120   \n",
       "284799 -1.518185  2.080825  1.159498 -0.594242  ...  0.103302  0.654850   \n",
       "284800  0.017050 -0.118228  0.435402  0.267772  ... -0.268048 -0.717211   \n",
       "284801  0.812722  0.115093 -0.204064 -0.657422  ... -0.314205 -0.808520   \n",
       "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
       "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
       "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
       "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
       "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "5      -0.026398 -0.371427 -0.232794  0.105915  0.253844  0.081080    3.67   \n",
       "6      -0.154104 -0.780055  0.750137 -0.257237  0.034507  0.005168    4.99   \n",
       "7       0.057504 -0.649709 -0.415267 -0.051634 -1.206921 -1.085339   40.80   \n",
       "8      -0.204233  1.011592  0.373205 -0.384157  0.011747  0.142404   93.20   \n",
       "9      -0.120794 -0.385050 -0.069733  0.094199  0.246219  0.083076    3.68   \n",
       "10      0.027740  0.500512  0.251367 -0.129478  0.042850  0.016253    7.80   \n",
       "11      0.009130  0.996710 -0.767315 -0.492208  0.042472 -0.054337    9.99   \n",
       "12      0.084668  0.392831  0.161135 -0.354990  0.026416  0.042422  121.50   \n",
       "13     -0.071407  0.104744  0.548265  0.104094  0.021491  0.021293   27.50   \n",
       "14      1.020586  0.028317 -0.232746 -0.235557 -0.164778 -0.030154   58.80   \n",
       "15     -0.256573 -0.065084 -0.039124 -0.087086 -0.180998  0.129394   15.99   \n",
       "16      0.013802  0.103758  0.364298 -0.382261  0.092809  0.037051   12.99   \n",
       "17     -0.156858 -0.888386 -0.342413 -0.049027  0.079692  0.131024    0.89   \n",
       "18      2.458589  0.042119 -0.481631 -0.621272  0.392053  0.949594   46.80   \n",
       "19      0.040002  0.295814  0.332931 -0.220385  0.022298  0.007602    5.00   \n",
       "20     -0.050881 -0.304215  0.072001 -0.422234  0.086553  0.063499  231.71   \n",
       "21     -0.048508 -1.371866  0.390814  0.199964  0.016371 -0.014605   34.09   \n",
       "22     -0.103855 -0.370415  0.603200  0.108556 -0.040521 -0.011418    2.28   \n",
       "23     -0.185353  0.423073  0.820591 -0.227632  0.336634  0.250475   22.75   \n",
       "24      0.870300  0.983421  0.321201  0.149650  0.707519  0.014600    0.89   \n",
       "25      0.742435  0.398535  0.249212  0.274404  0.359969  0.243232   26.43   \n",
       "26     -0.150487  0.435045  0.724825 -0.337082  0.016368  0.030041   41.88   \n",
       "27     -0.037710  0.347151  0.559639 -0.280158  0.042335  0.028822   16.00   \n",
       "28     -0.038500  0.642522 -0.183891 -0.277464  0.182687  0.152665   33.00   \n",
       "29      0.014462  0.002951  0.294638 -0.395070  0.081461  0.024220   12.99   \n",
       "...          ...       ...       ...       ...       ...       ...     ...   \n",
       "284777 -0.002063  0.001344  0.262183 -0.105327 -0.022363 -0.060283    1.00   \n",
       "284778  0.141759  0.587119 -0.200998  0.267337 -0.152951 -0.065285   80.00   \n",
       "284779 -0.032129  0.768379  0.477688 -0.031833  0.014151 -0.066542   25.00   \n",
       "284780 -0.204280  1.158185  0.627801 -0.399981  0.510818  0.233265   30.00   \n",
       "284781 -0.147249  0.212931  0.354257 -0.241068 -0.161717 -0.149188   13.00   \n",
       "284782  0.235172 -0.681794 -0.668894  0.044657 -0.066751 -0.072447   12.82   \n",
       "284783  0.084783  0.721269 -0.529906 -0.240117  0.129126 -0.080620   11.46   \n",
       "284784 -0.373023  0.651122  1.073823  0.844590 -0.286676 -0.187719   40.00   \n",
       "284785  0.108519  0.688519 -0.460220  0.161939  0.265368  0.090245    1.79   \n",
       "284786  0.588482  0.632444 -0.201064  0.199251  0.438657  0.172923    8.95   \n",
       "284787  0.293632  0.107812 -0.935586  1.138216  0.025271  0.255347    9.99   \n",
       "284788  0.416765  0.064819 -0.608337  0.268436 -0.028069 -0.041367    3.99   \n",
       "284789 -0.148093 -0.038712  0.010209 -0.362666  0.503092  0.229921   60.50   \n",
       "284790  0.300245  0.000607 -0.376379  0.128660 -0.015205 -0.021486    9.81   \n",
       "284791 -0.074513 -0.003988 -0.113149  0.280378 -0.077310  0.023079   20.32   \n",
       "284792 -0.059545  0.242669 -0.665424 -0.269869 -0.170579 -0.030692    3.99   \n",
       "284793  0.163002  0.726365 -0.058282 -0.191813  0.061858 -0.043716    4.99   \n",
       "284794  0.088485 -0.076790 -0.095833  0.132720 -0.028468  0.126494    0.89   \n",
       "284795  0.890675 -1.253276  1.786717  0.320763  2.090712  1.232864    9.87   \n",
       "284796 -0.042114 -0.053206  0.316403 -0.461441  0.018265 -0.041068   60.00   \n",
       "284797  0.279598  0.371441 -0.559238  0.113144  0.131507  0.081265    5.49   \n",
       "284798  0.251791  0.057688 -1.508368  0.144023  0.181205  0.215243   24.05   \n",
       "284799 -0.348929  0.745323  0.704545 -0.127579  0.454379  0.130308   79.99   \n",
       "284800  0.297930 -0.359769 -0.315610  0.201114 -0.080826 -0.075071    2.68   \n",
       "284801  0.050343  0.102800 -0.435870  0.124079  0.217940  0.068803    2.69   \n",
       "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
       "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
       "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
       "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
       "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
       "\n",
       "        Class  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  \n",
       "5           0  \n",
       "6           0  \n",
       "7           0  \n",
       "8           0  \n",
       "9           0  \n",
       "10          0  \n",
       "11          0  \n",
       "12          0  \n",
       "13          0  \n",
       "14          0  \n",
       "15          0  \n",
       "16          0  \n",
       "17          0  \n",
       "18          0  \n",
       "19          0  \n",
       "20          0  \n",
       "21          0  \n",
       "22          0  \n",
       "23          0  \n",
       "24          0  \n",
       "25          0  \n",
       "26          0  \n",
       "27          0  \n",
       "28          0  \n",
       "29          0  \n",
       "...       ...  \n",
       "284777      0  \n",
       "284778      0  \n",
       "284779      0  \n",
       "284780      0  \n",
       "284781      0  \n",
       "284782      0  \n",
       "284783      0  \n",
       "284784      0  \n",
       "284785      0  \n",
       "284786      0  \n",
       "284787      0  \n",
       "284788      0  \n",
       "284789      0  \n",
       "284790      0  \n",
       "284791      0  \n",
       "284792      0  \n",
       "284793      0  \n",
       "284794      0  \n",
       "284795      0  \n",
       "284796      0  \n",
       "284797      0  \n",
       "284798      0  \n",
       "284799      0  \n",
       "284800      0  \n",
       "284801      0  \n",
       "284802      0  \n",
       "284803      0  \n",
       "284804      0  \n",
       "284805      0  \n",
       "284806      0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('creditcard.csv') # Load data\n",
    "data = data.drop(columns=['Time']) # drop unused variable 'Time'\n",
    "print(data.isnull().values.any()) # Check if the data has missing value\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    284315\n",
      "1       492\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x13ccc1dbc18>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data[\"Class\"].value_counts()) #Class distribution\n",
    "data[\"Class\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.935192</td>\n",
       "      <td>0.766490</td>\n",
       "      <td>0.881365</td>\n",
       "      <td>0.313023</td>\n",
       "      <td>0.763439</td>\n",
       "      <td>0.267669</td>\n",
       "      <td>0.266815</td>\n",
       "      <td>0.786444</td>\n",
       "      <td>0.475312</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561184</td>\n",
       "      <td>0.522992</td>\n",
       "      <td>0.663793</td>\n",
       "      <td>0.391253</td>\n",
       "      <td>0.585122</td>\n",
       "      <td>0.394557</td>\n",
       "      <td>0.418976</td>\n",
       "      <td>0.312697</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.978542</td>\n",
       "      <td>0.770067</td>\n",
       "      <td>0.840298</td>\n",
       "      <td>0.271796</td>\n",
       "      <td>0.766120</td>\n",
       "      <td>0.262192</td>\n",
       "      <td>0.264875</td>\n",
       "      <td>0.786298</td>\n",
       "      <td>0.453981</td>\n",
       "      <td>0.505267</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557840</td>\n",
       "      <td>0.480237</td>\n",
       "      <td>0.666938</td>\n",
       "      <td>0.336440</td>\n",
       "      <td>0.587290</td>\n",
       "      <td>0.446013</td>\n",
       "      <td>0.416345</td>\n",
       "      <td>0.313423</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.935217</td>\n",
       "      <td>0.753118</td>\n",
       "      <td>0.868141</td>\n",
       "      <td>0.268766</td>\n",
       "      <td>0.762329</td>\n",
       "      <td>0.281122</td>\n",
       "      <td>0.270177</td>\n",
       "      <td>0.788042</td>\n",
       "      <td>0.410603</td>\n",
       "      <td>0.513018</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565477</td>\n",
       "      <td>0.546030</td>\n",
       "      <td>0.678939</td>\n",
       "      <td>0.289354</td>\n",
       "      <td>0.559515</td>\n",
       "      <td>0.402727</td>\n",
       "      <td>0.415489</td>\n",
       "      <td>0.311911</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.941878</td>\n",
       "      <td>0.765304</td>\n",
       "      <td>0.868484</td>\n",
       "      <td>0.213661</td>\n",
       "      <td>0.765647</td>\n",
       "      <td>0.275559</td>\n",
       "      <td>0.266803</td>\n",
       "      <td>0.789434</td>\n",
       "      <td>0.414999</td>\n",
       "      <td>0.507585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559734</td>\n",
       "      <td>0.510277</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>0.223826</td>\n",
       "      <td>0.614245</td>\n",
       "      <td>0.389197</td>\n",
       "      <td>0.417669</td>\n",
       "      <td>0.314371</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.938617</td>\n",
       "      <td>0.776520</td>\n",
       "      <td>0.864251</td>\n",
       "      <td>0.269796</td>\n",
       "      <td>0.762975</td>\n",
       "      <td>0.263984</td>\n",
       "      <td>0.268968</td>\n",
       "      <td>0.782484</td>\n",
       "      <td>0.490950</td>\n",
       "      <td>0.524303</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561327</td>\n",
       "      <td>0.547271</td>\n",
       "      <td>0.663392</td>\n",
       "      <td>0.401270</td>\n",
       "      <td>0.566343</td>\n",
       "      <td>0.507497</td>\n",
       "      <td>0.420561</td>\n",
       "      <td>0.317490</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.951057</td>\n",
       "      <td>0.777393</td>\n",
       "      <td>0.857187</td>\n",
       "      <td>0.244472</td>\n",
       "      <td>0.768550</td>\n",
       "      <td>0.262721</td>\n",
       "      <td>0.268257</td>\n",
       "      <td>0.788178</td>\n",
       "      <td>0.443190</td>\n",
       "      <td>0.501038</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558122</td>\n",
       "      <td>0.483915</td>\n",
       "      <td>0.665042</td>\n",
       "      <td>0.332185</td>\n",
       "      <td>0.564839</td>\n",
       "      <td>0.442749</td>\n",
       "      <td>0.421196</td>\n",
       "      <td>0.314769</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.979184</td>\n",
       "      <td>0.768746</td>\n",
       "      <td>0.838200</td>\n",
       "      <td>0.305241</td>\n",
       "      <td>0.767008</td>\n",
       "      <td>0.265762</td>\n",
       "      <td>0.265324</td>\n",
       "      <td>0.786257</td>\n",
       "      <td>0.478797</td>\n",
       "      <td>0.506668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558776</td>\n",
       "      <td>0.497402</td>\n",
       "      <td>0.663145</td>\n",
       "      <td>0.277122</td>\n",
       "      <td>0.620014</td>\n",
       "      <td>0.383429</td>\n",
       "      <td>0.417148</td>\n",
       "      <td>0.313229</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.947348</td>\n",
       "      <td>0.782220</td>\n",
       "      <td>0.856031</td>\n",
       "      <td>0.230111</td>\n",
       "      <td>0.772104</td>\n",
       "      <td>0.267324</td>\n",
       "      <td>0.272183</td>\n",
       "      <td>0.744539</td>\n",
       "      <td>0.483978</td>\n",
       "      <td>0.534571</td>\n",
       "      <td>...</td>\n",
       "      <td>0.592809</td>\n",
       "      <td>0.462660</td>\n",
       "      <td>0.666288</td>\n",
       "      <td>0.294686</td>\n",
       "      <td>0.554597</td>\n",
       "      <td>0.417014</td>\n",
       "      <td>0.394234</td>\n",
       "      <td>0.291099</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.943101</td>\n",
       "      <td>0.770278</td>\n",
       "      <td>0.835452</td>\n",
       "      <td>0.239894</td>\n",
       "      <td>0.783688</td>\n",
       "      <td>0.300439</td>\n",
       "      <td>0.267610</td>\n",
       "      <td>0.794515</td>\n",
       "      <td>0.449275</td>\n",
       "      <td>0.500230</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560296</td>\n",
       "      <td>0.497525</td>\n",
       "      <td>0.662401</td>\n",
       "      <td>0.518546</td>\n",
       "      <td>0.598855</td>\n",
       "      <td>0.362697</td>\n",
       "      <td>0.416728</td>\n",
       "      <td>0.316014</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.952547</td>\n",
       "      <td>0.779072</td>\n",
       "      <td>0.855511</td>\n",
       "      <td>0.242081</td>\n",
       "      <td>0.769078</td>\n",
       "      <td>0.260539</td>\n",
       "      <td>0.269325</td>\n",
       "      <td>0.786131</td>\n",
       "      <td>0.437401</td>\n",
       "      <td>0.501132</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557499</td>\n",
       "      <td>0.480466</td>\n",
       "      <td>0.663640</td>\n",
       "      <td>0.330349</td>\n",
       "      <td>0.573992</td>\n",
       "      <td>0.440836</td>\n",
       "      <td>0.421056</td>\n",
       "      <td>0.314810</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.982911</td>\n",
       "      <td>0.754846</td>\n",
       "      <td>0.853250</td>\n",
       "      <td>0.190948</td>\n",
       "      <td>0.752445</td>\n",
       "      <td>0.256694</td>\n",
       "      <td>0.256685</td>\n",
       "      <td>0.785905</td>\n",
       "      <td>0.403515</td>\n",
       "      <td>0.542377</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561330</td>\n",
       "      <td>0.524674</td>\n",
       "      <td>0.665846</td>\n",
       "      <td>0.449678</td>\n",
       "      <td>0.592016</td>\n",
       "      <td>0.404298</td>\n",
       "      <td>0.417302</td>\n",
       "      <td>0.313454</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.964834</td>\n",
       "      <td>0.773759</td>\n",
       "      <td>0.822263</td>\n",
       "      <td>0.247762</td>\n",
       "      <td>0.785405</td>\n",
       "      <td>0.296369</td>\n",
       "      <td>0.268222</td>\n",
       "      <td>0.791159</td>\n",
       "      <td>0.443527</td>\n",
       "      <td>0.515131</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562284</td>\n",
       "      <td>0.521153</td>\n",
       "      <td>0.665569</td>\n",
       "      <td>0.516540</td>\n",
       "      <td>0.534835</td>\n",
       "      <td>0.345047</td>\n",
       "      <td>0.417295</td>\n",
       "      <td>0.312021</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.979530</td>\n",
       "      <td>0.754368</td>\n",
       "      <td>0.844067</td>\n",
       "      <td>0.197188</td>\n",
       "      <td>0.755717</td>\n",
       "      <td>0.255447</td>\n",
       "      <td>0.261156</td>\n",
       "      <td>0.782945</td>\n",
       "      <td>0.390645</td>\n",
       "      <td>0.536109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557743</td>\n",
       "      <td>0.487486</td>\n",
       "      <td>0.666691</td>\n",
       "      <td>0.435168</td>\n",
       "      <td>0.586951</td>\n",
       "      <td>0.367461</td>\n",
       "      <td>0.416999</td>\n",
       "      <td>0.313985</td>\n",
       "      <td>0.004729</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.976461</td>\n",
       "      <td>0.770294</td>\n",
       "      <td>0.851772</td>\n",
       "      <td>0.372174</td>\n",
       "      <td>0.764515</td>\n",
       "      <td>0.266413</td>\n",
       "      <td>0.264766</td>\n",
       "      <td>0.786630</td>\n",
       "      <td>0.455164</td>\n",
       "      <td>0.518244</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560885</td>\n",
       "      <td>0.513502</td>\n",
       "      <td>0.664373</td>\n",
       "      <td>0.396348</td>\n",
       "      <td>0.608682</td>\n",
       "      <td>0.442452</td>\n",
       "      <td>0.416908</td>\n",
       "      <td>0.313556</td>\n",
       "      <td>0.001070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.910864</td>\n",
       "      <td>0.763800</td>\n",
       "      <td>0.865863</td>\n",
       "      <td>0.330281</td>\n",
       "      <td>0.764797</td>\n",
       "      <td>0.271139</td>\n",
       "      <td>0.262779</td>\n",
       "      <td>0.764928</td>\n",
       "      <td>0.488813</td>\n",
       "      <td>0.532538</td>\n",
       "      <td>...</td>\n",
       "      <td>0.580045</td>\n",
       "      <td>0.520396</td>\n",
       "      <td>0.680590</td>\n",
       "      <td>0.386050</td>\n",
       "      <td>0.564842</td>\n",
       "      <td>0.386971</td>\n",
       "      <td>0.413470</td>\n",
       "      <td>0.312512</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.945511</td>\n",
       "      <td>0.770904</td>\n",
       "      <td>0.873064</td>\n",
       "      <td>0.186826</td>\n",
       "      <td>0.757918</td>\n",
       "      <td>0.262237</td>\n",
       "      <td>0.261648</td>\n",
       "      <td>0.785424</td>\n",
       "      <td>0.447755</td>\n",
       "      <td>0.524192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.569534</td>\n",
       "      <td>0.573179</td>\n",
       "      <td>0.661623</td>\n",
       "      <td>0.373464</td>\n",
       "      <td>0.575710</td>\n",
       "      <td>0.411223</td>\n",
       "      <td>0.413170</td>\n",
       "      <td>0.315750</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.977036</td>\n",
       "      <td>0.766833</td>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.309075</td>\n",
       "      <td>0.760762</td>\n",
       "      <td>0.265916</td>\n",
       "      <td>0.261785</td>\n",
       "      <td>0.787417</td>\n",
       "      <td>0.489730</td>\n",
       "      <td>0.503178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561083</td>\n",
       "      <td>0.519174</td>\n",
       "      <td>0.665639</td>\n",
       "      <td>0.396216</td>\n",
       "      <td>0.598355</td>\n",
       "      <td>0.363007</td>\n",
       "      <td>0.418224</td>\n",
       "      <td>0.313876</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.950871</td>\n",
       "      <td>0.776955</td>\n",
       "      <td>0.853435</td>\n",
       "      <td>0.219693</td>\n",
       "      <td>0.771881</td>\n",
       "      <td>0.261734</td>\n",
       "      <td>0.269667</td>\n",
       "      <td>0.786329</td>\n",
       "      <td>0.439862</td>\n",
       "      <td>0.493453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558339</td>\n",
       "      <td>0.478652</td>\n",
       "      <td>0.663104</td>\n",
       "      <td>0.262525</td>\n",
       "      <td>0.558686</td>\n",
       "      <td>0.417440</td>\n",
       "      <td>0.417982</td>\n",
       "      <td>0.315783</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.866533</td>\n",
       "      <td>0.709751</td>\n",
       "      <td>0.857971</td>\n",
       "      <td>0.328896</td>\n",
       "      <td>0.786243</td>\n",
       "      <td>0.245290</td>\n",
       "      <td>0.255853</td>\n",
       "      <td>0.787111</td>\n",
       "      <td>0.505258</td>\n",
       "      <td>0.515863</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553361</td>\n",
       "      <td>0.555956</td>\n",
       "      <td>0.701946</td>\n",
       "      <td>0.387910</td>\n",
       "      <td>0.550871</td>\n",
       "      <td>0.323965</td>\n",
       "      <td>0.423747</td>\n",
       "      <td>0.332394</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.983657</td>\n",
       "      <td>0.756397</td>\n",
       "      <td>0.845295</td>\n",
       "      <td>0.188184</td>\n",
       "      <td>0.755245</td>\n",
       "      <td>0.255771</td>\n",
       "      <td>0.258772</td>\n",
       "      <td>0.784816</td>\n",
       "      <td>0.394618</td>\n",
       "      <td>0.542613</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558616</td>\n",
       "      <td>0.501864</td>\n",
       "      <td>0.666028</td>\n",
       "      <td>0.422095</td>\n",
       "      <td>0.596595</td>\n",
       "      <td>0.389449</td>\n",
       "      <td>0.416923</td>\n",
       "      <td>0.313278</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.970099</td>\n",
       "      <td>0.752889</td>\n",
       "      <td>0.855249</td>\n",
       "      <td>0.288908</td>\n",
       "      <td>0.757697</td>\n",
       "      <td>0.276182</td>\n",
       "      <td>0.260003</td>\n",
       "      <td>0.790162</td>\n",
       "      <td>0.447409</td>\n",
       "      <td>0.520484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556715</td>\n",
       "      <td>0.483349</td>\n",
       "      <td>0.664678</td>\n",
       "      <td>0.341241</td>\n",
       "      <td>0.581948</td>\n",
       "      <td>0.356477</td>\n",
       "      <td>0.418109</td>\n",
       "      <td>0.314412</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.974645</td>\n",
       "      <td>0.770724</td>\n",
       "      <td>0.834442</td>\n",
       "      <td>0.345429</td>\n",
       "      <td>0.773320</td>\n",
       "      <td>0.280072</td>\n",
       "      <td>0.266012</td>\n",
       "      <td>0.790980</td>\n",
       "      <td>0.421741</td>\n",
       "      <td>0.523709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563801</td>\n",
       "      <td>0.528807</td>\n",
       "      <td>0.664713</td>\n",
       "      <td>0.197376</td>\n",
       "      <td>0.599844</td>\n",
       "      <td>0.458112</td>\n",
       "      <td>0.416813</td>\n",
       "      <td>0.312827</td>\n",
       "      <td>0.001327</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.978113</td>\n",
       "      <td>0.772556</td>\n",
       "      <td>0.836247</td>\n",
       "      <td>0.352184</td>\n",
       "      <td>0.768603</td>\n",
       "      <td>0.263919</td>\n",
       "      <td>0.266825</td>\n",
       "      <td>0.786867</td>\n",
       "      <td>0.428705</td>\n",
       "      <td>0.527801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561781</td>\n",
       "      <td>0.507140</td>\n",
       "      <td>0.663891</td>\n",
       "      <td>0.332321</td>\n",
       "      <td>0.611766</td>\n",
       "      <td>0.443181</td>\n",
       "      <td>0.415763</td>\n",
       "      <td>0.312892</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.962498</td>\n",
       "      <td>0.770188</td>\n",
       "      <td>0.857956</td>\n",
       "      <td>0.247825</td>\n",
       "      <td>0.756868</td>\n",
       "      <td>0.261510</td>\n",
       "      <td>0.259590</td>\n",
       "      <td>0.768030</td>\n",
       "      <td>0.515970</td>\n",
       "      <td>0.491552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588081</td>\n",
       "      <td>0.519382</td>\n",
       "      <td>0.662681</td>\n",
       "      <td>0.439243</td>\n",
       "      <td>0.623968</td>\n",
       "      <td>0.388265</td>\n",
       "      <td>0.422724</td>\n",
       "      <td>0.318207</td>\n",
       "      <td>0.000886</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.925225</td>\n",
       "      <td>0.766785</td>\n",
       "      <td>0.830386</td>\n",
       "      <td>0.207022</td>\n",
       "      <td>0.785522</td>\n",
       "      <td>0.292730</td>\n",
       "      <td>0.264971</td>\n",
       "      <td>0.794563</td>\n",
       "      <td>0.464501</td>\n",
       "      <td>0.520593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.552137</td>\n",
       "      <td>0.472747</td>\n",
       "      <td>0.678358</td>\n",
       "      <td>0.514750</td>\n",
       "      <td>0.595936</td>\n",
       "      <td>0.449893</td>\n",
       "      <td>0.429570</td>\n",
       "      <td>0.313420</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.923054</td>\n",
       "      <td>0.765977</td>\n",
       "      <td>0.860322</td>\n",
       "      <td>0.270105</td>\n",
       "      <td>0.767704</td>\n",
       "      <td>0.253372</td>\n",
       "      <td>0.268670</td>\n",
       "      <td>0.784263</td>\n",
       "      <td>0.479166</td>\n",
       "      <td>0.511814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554973</td>\n",
       "      <td>0.499423</td>\n",
       "      <td>0.676459</td>\n",
       "      <td>0.435937</td>\n",
       "      <td>0.591895</td>\n",
       "      <td>0.470272</td>\n",
       "      <td>0.423155</td>\n",
       "      <td>0.318060</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.978226</td>\n",
       "      <td>0.770988</td>\n",
       "      <td>0.842333</td>\n",
       "      <td>0.302180</td>\n",
       "      <td>0.764555</td>\n",
       "      <td>0.253810</td>\n",
       "      <td>0.267604</td>\n",
       "      <td>0.781875</td>\n",
       "      <td>0.454283</td>\n",
       "      <td>0.507767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562560</td>\n",
       "      <td>0.520658</td>\n",
       "      <td>0.663199</td>\n",
       "      <td>0.440856</td>\n",
       "      <td>0.618593</td>\n",
       "      <td>0.370387</td>\n",
       "      <td>0.416813</td>\n",
       "      <td>0.313733</td>\n",
       "      <td>0.001630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.980765</td>\n",
       "      <td>0.765422</td>\n",
       "      <td>0.844944</td>\n",
       "      <td>0.277465</td>\n",
       "      <td>0.760083</td>\n",
       "      <td>0.254664</td>\n",
       "      <td>0.263742</td>\n",
       "      <td>0.783015</td>\n",
       "      <td>0.425871</td>\n",
       "      <td>0.526692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556895</td>\n",
       "      <td>0.494946</td>\n",
       "      <td>0.664874</td>\n",
       "      <td>0.429013</td>\n",
       "      <td>0.609321</td>\n",
       "      <td>0.379685</td>\n",
       "      <td>0.417292</td>\n",
       "      <td>0.313709</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.951256</td>\n",
       "      <td>0.776812</td>\n",
       "      <td>0.867348</td>\n",
       "      <td>0.317248</td>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.261006</td>\n",
       "      <td>0.269865</td>\n",
       "      <td>0.785072</td>\n",
       "      <td>0.442339</td>\n",
       "      <td>0.501559</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562725</td>\n",
       "      <td>0.531365</td>\n",
       "      <td>0.664862</td>\n",
       "      <td>0.468814</td>\n",
       "      <td>0.567584</td>\n",
       "      <td>0.380125</td>\n",
       "      <td>0.419883</td>\n",
       "      <td>0.316222</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.976291</td>\n",
       "      <td>0.765408</td>\n",
       "      <td>0.859354</td>\n",
       "      <td>0.304509</td>\n",
       "      <td>0.760425</td>\n",
       "      <td>0.268835</td>\n",
       "      <td>0.260682</td>\n",
       "      <td>0.789687</td>\n",
       "      <td>0.486876</td>\n",
       "      <td>0.507383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561700</td>\n",
       "      <td>0.520002</td>\n",
       "      <td>0.665648</td>\n",
       "      <td>0.382632</td>\n",
       "      <td>0.594445</td>\n",
       "      <td>0.360914</td>\n",
       "      <td>0.418015</td>\n",
       "      <td>0.313615</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284777</th>\n",
       "      <td>0.993616</td>\n",
       "      <td>0.766955</td>\n",
       "      <td>0.814135</td>\n",
       "      <td>0.267800</td>\n",
       "      <td>0.765408</td>\n",
       "      <td>0.249492</td>\n",
       "      <td>0.266741</td>\n",
       "      <td>0.781327</td>\n",
       "      <td>0.485719</td>\n",
       "      <td>0.509309</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565280</td>\n",
       "      <td>0.548739</td>\n",
       "      <td>0.665403</td>\n",
       "      <td>0.382415</td>\n",
       "      <td>0.592624</td>\n",
       "      <td>0.408243</td>\n",
       "      <td>0.416098</td>\n",
       "      <td>0.311901</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284778</th>\n",
       "      <td>0.945305</td>\n",
       "      <td>0.773467</td>\n",
       "      <td>0.821686</td>\n",
       "      <td>0.233363</td>\n",
       "      <td>0.771785</td>\n",
       "      <td>0.255371</td>\n",
       "      <td>0.269977</td>\n",
       "      <td>0.789834</td>\n",
       "      <td>0.437603</td>\n",
       "      <td>0.482962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561536</td>\n",
       "      <td>0.489884</td>\n",
       "      <td>0.667539</td>\n",
       "      <td>0.461348</td>\n",
       "      <td>0.566624</td>\n",
       "      <td>0.469117</td>\n",
       "      <td>0.413688</td>\n",
       "      <td>0.311799</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284779</th>\n",
       "      <td>0.991850</td>\n",
       "      <td>0.760756</td>\n",
       "      <td>0.791869</td>\n",
       "      <td>0.233922</td>\n",
       "      <td>0.781387</td>\n",
       "      <td>0.299865</td>\n",
       "      <td>0.262107</td>\n",
       "      <td>0.794428</td>\n",
       "      <td>0.501665</td>\n",
       "      <td>0.504155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.562867</td>\n",
       "      <td>0.535391</td>\n",
       "      <td>0.664956</td>\n",
       "      <td>0.485773</td>\n",
       "      <td>0.604720</td>\n",
       "      <td>0.420249</td>\n",
       "      <td>0.416772</td>\n",
       "      <td>0.311774</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284780</th>\n",
       "      <td>0.928946</td>\n",
       "      <td>0.778953</td>\n",
       "      <td>0.875875</td>\n",
       "      <td>0.302846</td>\n",
       "      <td>0.759764</td>\n",
       "      <td>0.270993</td>\n",
       "      <td>0.262143</td>\n",
       "      <td>0.794680</td>\n",
       "      <td>0.492192</td>\n",
       "      <td>0.504684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559953</td>\n",
       "      <td>0.521079</td>\n",
       "      <td>0.662400</td>\n",
       "      <td>0.538299</td>\n",
       "      <td>0.613147</td>\n",
       "      <td>0.360112</td>\n",
       "      <td>0.425939</td>\n",
       "      <td>0.317858</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284781</th>\n",
       "      <td>0.938943</td>\n",
       "      <td>0.765618</td>\n",
       "      <td>0.870242</td>\n",
       "      <td>0.201441</td>\n",
       "      <td>0.775490</td>\n",
       "      <td>0.263961</td>\n",
       "      <td>0.266521</td>\n",
       "      <td>0.786375</td>\n",
       "      <td>0.460623</td>\n",
       "      <td>0.492334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.480564</td>\n",
       "      <td>0.663247</td>\n",
       "      <td>0.410926</td>\n",
       "      <td>0.597792</td>\n",
       "      <td>0.386070</td>\n",
       "      <td>0.413526</td>\n",
       "      <td>0.310096</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284782</th>\n",
       "      <td>0.953740</td>\n",
       "      <td>0.794062</td>\n",
       "      <td>0.813138</td>\n",
       "      <td>0.466779</td>\n",
       "      <td>0.770019</td>\n",
       "      <td>0.264895</td>\n",
       "      <td>0.265076</td>\n",
       "      <td>0.795431</td>\n",
       "      <td>0.379416</td>\n",
       "      <td>0.519584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557226</td>\n",
       "      <td>0.470010</td>\n",
       "      <td>0.668926</td>\n",
       "      <td>0.290363</td>\n",
       "      <td>0.540360</td>\n",
       "      <td>0.432743</td>\n",
       "      <td>0.415279</td>\n",
       "      <td>0.311654</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284783</th>\n",
       "      <td>0.927780</td>\n",
       "      <td>0.787614</td>\n",
       "      <td>0.788401</td>\n",
       "      <td>0.177021</td>\n",
       "      <td>0.780524</td>\n",
       "      <td>0.294426</td>\n",
       "      <td>0.263706</td>\n",
       "      <td>0.803165</td>\n",
       "      <td>0.478826</td>\n",
       "      <td>0.525955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565851</td>\n",
       "      <td>0.563480</td>\n",
       "      <td>0.666693</td>\n",
       "      <td>0.479425</td>\n",
       "      <td>0.548162</td>\n",
       "      <td>0.386226</td>\n",
       "      <td>0.418894</td>\n",
       "      <td>0.311488</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284784</th>\n",
       "      <td>0.946917</td>\n",
       "      <td>0.777005</td>\n",
       "      <td>0.810673</td>\n",
       "      <td>0.182744</td>\n",
       "      <td>0.784794</td>\n",
       "      <td>0.295603</td>\n",
       "      <td>0.266462</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.431987</td>\n",
       "      <td>0.478651</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564443</td>\n",
       "      <td>0.519486</td>\n",
       "      <td>0.659894</td>\n",
       "      <td>0.469972</td>\n",
       "      <td>0.638183</td>\n",
       "      <td>0.563411</td>\n",
       "      <td>0.411220</td>\n",
       "      <td>0.309314</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284785</th>\n",
       "      <td>0.958852</td>\n",
       "      <td>0.773012</td>\n",
       "      <td>0.816865</td>\n",
       "      <td>0.175248</td>\n",
       "      <td>0.785457</td>\n",
       "      <td>0.297219</td>\n",
       "      <td>0.267411</td>\n",
       "      <td>0.795312</td>\n",
       "      <td>0.457073</td>\n",
       "      <td>0.500716</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557190</td>\n",
       "      <td>0.476614</td>\n",
       "      <td>0.667045</td>\n",
       "      <td>0.475012</td>\n",
       "      <td>0.552073</td>\n",
       "      <td>0.451901</td>\n",
       "      <td>0.421409</td>\n",
       "      <td>0.314955</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284786</th>\n",
       "      <td>0.923022</td>\n",
       "      <td>0.789862</td>\n",
       "      <td>0.793699</td>\n",
       "      <td>0.168234</td>\n",
       "      <td>0.779064</td>\n",
       "      <td>0.300551</td>\n",
       "      <td>0.257939</td>\n",
       "      <td>0.779629</td>\n",
       "      <td>0.472180</td>\n",
       "      <td>0.514936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593989</td>\n",
       "      <td>0.435938</td>\n",
       "      <td>0.674173</td>\n",
       "      <td>0.467456</td>\n",
       "      <td>0.566620</td>\n",
       "      <td>0.457996</td>\n",
       "      <td>0.424608</td>\n",
       "      <td>0.316633</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284787</th>\n",
       "      <td>0.940800</td>\n",
       "      <td>0.755539</td>\n",
       "      <td>0.826390</td>\n",
       "      <td>0.214658</td>\n",
       "      <td>0.782037</td>\n",
       "      <td>0.233293</td>\n",
       "      <td>0.267083</td>\n",
       "      <td>0.781817</td>\n",
       "      <td>0.454254</td>\n",
       "      <td>0.501930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.567182</td>\n",
       "      <td>0.532819</td>\n",
       "      <td>0.669794</td>\n",
       "      <td>0.396762</td>\n",
       "      <td>0.525390</td>\n",
       "      <td>0.611374</td>\n",
       "      <td>0.416977</td>\n",
       "      <td>0.318306</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284788</th>\n",
       "      <td>0.992397</td>\n",
       "      <td>0.764301</td>\n",
       "      <td>0.833807</td>\n",
       "      <td>0.266792</td>\n",
       "      <td>0.760898</td>\n",
       "      <td>0.255465</td>\n",
       "      <td>0.262559</td>\n",
       "      <td>0.783882</td>\n",
       "      <td>0.495849</td>\n",
       "      <td>0.508137</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558122</td>\n",
       "      <td>0.489955</td>\n",
       "      <td>0.671623</td>\n",
       "      <td>0.390969</td>\n",
       "      <td>0.543759</td>\n",
       "      <td>0.469297</td>\n",
       "      <td>0.415993</td>\n",
       "      <td>0.312284</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284789</th>\n",
       "      <td>0.950701</td>\n",
       "      <td>0.780999</td>\n",
       "      <td>0.834492</td>\n",
       "      <td>0.295443</td>\n",
       "      <td>0.769614</td>\n",
       "      <td>0.256931</td>\n",
       "      <td>0.272992</td>\n",
       "      <td>0.774202</td>\n",
       "      <td>0.448411</td>\n",
       "      <td>0.510307</td>\n",
       "      <td>...</td>\n",
       "      <td>0.575211</td>\n",
       "      <td>0.524272</td>\n",
       "      <td>0.663234</td>\n",
       "      <td>0.377018</td>\n",
       "      <td>0.578480</td>\n",
       "      <td>0.366207</td>\n",
       "      <td>0.425797</td>\n",
       "      <td>0.317790</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284790</th>\n",
       "      <td>0.949536</td>\n",
       "      <td>0.777514</td>\n",
       "      <td>0.819832</td>\n",
       "      <td>0.221918</td>\n",
       "      <td>0.771859</td>\n",
       "      <td>0.259841</td>\n",
       "      <td>0.267769</td>\n",
       "      <td>0.791096</td>\n",
       "      <td>0.455043</td>\n",
       "      <td>0.493135</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556961</td>\n",
       "      <td>0.470382</td>\n",
       "      <td>0.669893</td>\n",
       "      <td>0.382316</td>\n",
       "      <td>0.556779</td>\n",
       "      <td>0.446465</td>\n",
       "      <td>0.416230</td>\n",
       "      <td>0.312688</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284791</th>\n",
       "      <td>0.943624</td>\n",
       "      <td>0.776488</td>\n",
       "      <td>0.844698</td>\n",
       "      <td>0.228420</td>\n",
       "      <td>0.768117</td>\n",
       "      <td>0.252501</td>\n",
       "      <td>0.269968</td>\n",
       "      <td>0.787858</td>\n",
       "      <td>0.445320</td>\n",
       "      <td>0.487350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559725</td>\n",
       "      <td>0.487601</td>\n",
       "      <td>0.664327</td>\n",
       "      <td>0.381697</td>\n",
       "      <td>0.571555</td>\n",
       "      <td>0.471248</td>\n",
       "      <td>0.415084</td>\n",
       "      <td>0.313592</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284792</th>\n",
       "      <td>0.945992</td>\n",
       "      <td>0.782930</td>\n",
       "      <td>0.817794</td>\n",
       "      <td>0.225014</td>\n",
       "      <td>0.770493</td>\n",
       "      <td>0.258167</td>\n",
       "      <td>0.268696</td>\n",
       "      <td>0.789065</td>\n",
       "      <td>0.454983</td>\n",
       "      <td>0.501519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.568163</td>\n",
       "      <td>0.571026</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>0.414934</td>\n",
       "      <td>0.540555</td>\n",
       "      <td>0.381366</td>\n",
       "      <td>0.413362</td>\n",
       "      <td>0.312501</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284793</th>\n",
       "      <td>0.991779</td>\n",
       "      <td>0.759882</td>\n",
       "      <td>0.807998</td>\n",
       "      <td>0.224551</td>\n",
       "      <td>0.777287</td>\n",
       "      <td>0.302345</td>\n",
       "      <td>0.257684</td>\n",
       "      <td>0.796715</td>\n",
       "      <td>0.508080</td>\n",
       "      <td>0.505684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564522</td>\n",
       "      <td>0.542426</td>\n",
       "      <td>0.667854</td>\n",
       "      <td>0.480111</td>\n",
       "      <td>0.574635</td>\n",
       "      <td>0.394116</td>\n",
       "      <td>0.417653</td>\n",
       "      <td>0.312237</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284794</th>\n",
       "      <td>0.936776</td>\n",
       "      <td>0.763033</td>\n",
       "      <td>0.853984</td>\n",
       "      <td>0.219839</td>\n",
       "      <td>0.776030</td>\n",
       "      <td>0.245037</td>\n",
       "      <td>0.267273</td>\n",
       "      <td>0.785436</td>\n",
       "      <td>0.463257</td>\n",
       "      <td>0.491841</td>\n",
       "      <td>...</td>\n",
       "      <td>0.558935</td>\n",
       "      <td>0.468822</td>\n",
       "      <td>0.666748</td>\n",
       "      <td>0.371887</td>\n",
       "      <td>0.572527</td>\n",
       "      <td>0.447128</td>\n",
       "      <td>0.415985</td>\n",
       "      <td>0.315691</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284795</th>\n",
       "      <td>0.745650</td>\n",
       "      <td>0.874755</td>\n",
       "      <td>0.690525</td>\n",
       "      <td>0.140643</td>\n",
       "      <td>0.734839</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.243226</td>\n",
       "      <td>0.844368</td>\n",
       "      <td>0.631338</td>\n",
       "      <td>0.687797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.546250</td>\n",
       "      <td>0.437023</td>\n",
       "      <td>0.678661</td>\n",
       "      <td>0.213356</td>\n",
       "      <td>0.678199</td>\n",
       "      <td>0.477844</td>\n",
       "      <td>0.455101</td>\n",
       "      <td>0.338142</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284796</th>\n",
       "      <td>0.990315</td>\n",
       "      <td>0.765744</td>\n",
       "      <td>0.820086</td>\n",
       "      <td>0.318724</td>\n",
       "      <td>0.765479</td>\n",
       "      <td>0.256850</td>\n",
       "      <td>0.266514</td>\n",
       "      <td>0.782714</td>\n",
       "      <td>0.485738</td>\n",
       "      <td>0.511224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563801</td>\n",
       "      <td>0.539637</td>\n",
       "      <td>0.664808</td>\n",
       "      <td>0.375065</td>\n",
       "      <td>0.595667</td>\n",
       "      <td>0.350073</td>\n",
       "      <td>0.416848</td>\n",
       "      <td>0.312290</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284797</th>\n",
       "      <td>0.954184</td>\n",
       "      <td>0.774774</td>\n",
       "      <td>0.844342</td>\n",
       "      <td>0.231388</td>\n",
       "      <td>0.767362</td>\n",
       "      <td>0.249510</td>\n",
       "      <td>0.271017</td>\n",
       "      <td>0.783173</td>\n",
       "      <td>0.466439</td>\n",
       "      <td>0.502831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557790</td>\n",
       "      <td>0.486035</td>\n",
       "      <td>0.669586</td>\n",
       "      <td>0.432286</td>\n",
       "      <td>0.546515</td>\n",
       "      <td>0.443930</td>\n",
       "      <td>0.418938</td>\n",
       "      <td>0.314773</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284798</th>\n",
       "      <td>0.962023</td>\n",
       "      <td>0.776557</td>\n",
       "      <td>0.826395</td>\n",
       "      <td>0.294527</td>\n",
       "      <td>0.764687</td>\n",
       "      <td>0.252822</td>\n",
       "      <td>0.267958</td>\n",
       "      <td>0.786687</td>\n",
       "      <td>0.452939</td>\n",
       "      <td>0.506412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563091</td>\n",
       "      <td>0.525758</td>\n",
       "      <td>0.669173</td>\n",
       "      <td>0.390008</td>\n",
       "      <td>0.493238</td>\n",
       "      <td>0.448974</td>\n",
       "      <td>0.419856</td>\n",
       "      <td>0.317492</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284799</th>\n",
       "      <td>0.928136</td>\n",
       "      <td>0.767214</td>\n",
       "      <td>0.858031</td>\n",
       "      <td>0.266607</td>\n",
       "      <td>0.773768</td>\n",
       "      <td>0.318518</td>\n",
       "      <td>0.256107</td>\n",
       "      <td>0.807706</td>\n",
       "      <td>0.502723</td>\n",
       "      <td>0.496427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.563145</td>\n",
       "      <td>0.540580</td>\n",
       "      <td>0.660252</td>\n",
       "      <td>0.482666</td>\n",
       "      <td>0.617454</td>\n",
       "      <td>0.404609</td>\n",
       "      <td>0.424898</td>\n",
       "      <td>0.315768</td>\n",
       "      <td>0.003114</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284800</th>\n",
       "      <td>0.992943</td>\n",
       "      <td>0.765409</td>\n",
       "      <td>0.816674</td>\n",
       "      <td>0.262329</td>\n",
       "      <td>0.765658</td>\n",
       "      <td>0.255715</td>\n",
       "      <td>0.265459</td>\n",
       "      <td>0.784117</td>\n",
       "      <td>0.477779</td>\n",
       "      <td>0.514262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.557158</td>\n",
       "      <td>0.476573</td>\n",
       "      <td>0.669858</td>\n",
       "      <td>0.333755</td>\n",
       "      <td>0.560191</td>\n",
       "      <td>0.458300</td>\n",
       "      <td>0.415019</td>\n",
       "      <td>0.311600</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284801</th>\n",
       "      <td>0.960338</td>\n",
       "      <td>0.777082</td>\n",
       "      <td>0.827952</td>\n",
       "      <td>0.218901</td>\n",
       "      <td>0.773326</td>\n",
       "      <td>0.260647</td>\n",
       "      <td>0.270307</td>\n",
       "      <td>0.786620</td>\n",
       "      <td>0.455750</td>\n",
       "      <td>0.495120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.556414</td>\n",
       "      <td>0.472314</td>\n",
       "      <td>0.666181</td>\n",
       "      <td>0.396086</td>\n",
       "      <td>0.553440</td>\n",
       "      <td>0.445716</td>\n",
       "      <td>0.420534</td>\n",
       "      <td>0.314520</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>0.756448</td>\n",
       "      <td>0.873531</td>\n",
       "      <td>0.666991</td>\n",
       "      <td>0.160317</td>\n",
       "      <td>0.729603</td>\n",
       "      <td>0.236810</td>\n",
       "      <td>0.235393</td>\n",
       "      <td>0.863749</td>\n",
       "      <td>0.528729</td>\n",
       "      <td>0.598850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564920</td>\n",
       "      <td>0.515249</td>\n",
       "      <td>0.680500</td>\n",
       "      <td>0.313600</td>\n",
       "      <td>0.658558</td>\n",
       "      <td>0.466291</td>\n",
       "      <td>0.433929</td>\n",
       "      <td>0.329840</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>0.945845</td>\n",
       "      <td>0.766677</td>\n",
       "      <td>0.872678</td>\n",
       "      <td>0.219189</td>\n",
       "      <td>0.771561</td>\n",
       "      <td>0.273661</td>\n",
       "      <td>0.265504</td>\n",
       "      <td>0.788548</td>\n",
       "      <td>0.482925</td>\n",
       "      <td>0.488530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.564933</td>\n",
       "      <td>0.553153</td>\n",
       "      <td>0.665619</td>\n",
       "      <td>0.245298</td>\n",
       "      <td>0.543855</td>\n",
       "      <td>0.360884</td>\n",
       "      <td>0.417775</td>\n",
       "      <td>0.312038</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>0.990905</td>\n",
       "      <td>0.764080</td>\n",
       "      <td>0.781102</td>\n",
       "      <td>0.227202</td>\n",
       "      <td>0.783425</td>\n",
       "      <td>0.293496</td>\n",
       "      <td>0.263547</td>\n",
       "      <td>0.792985</td>\n",
       "      <td>0.477677</td>\n",
       "      <td>0.498692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565220</td>\n",
       "      <td>0.537005</td>\n",
       "      <td>0.664877</td>\n",
       "      <td>0.468492</td>\n",
       "      <td>0.592824</td>\n",
       "      <td>0.411177</td>\n",
       "      <td>0.416593</td>\n",
       "      <td>0.312585</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>0.954209</td>\n",
       "      <td>0.772856</td>\n",
       "      <td>0.849587</td>\n",
       "      <td>0.282508</td>\n",
       "      <td>0.763172</td>\n",
       "      <td>0.269291</td>\n",
       "      <td>0.261175</td>\n",
       "      <td>0.792671</td>\n",
       "      <td>0.476287</td>\n",
       "      <td>0.500464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565755</td>\n",
       "      <td>0.547353</td>\n",
       "      <td>0.663008</td>\n",
       "      <td>0.398836</td>\n",
       "      <td>0.545958</td>\n",
       "      <td>0.514746</td>\n",
       "      <td>0.418520</td>\n",
       "      <td>0.315245</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>0.949232</td>\n",
       "      <td>0.765256</td>\n",
       "      <td>0.849601</td>\n",
       "      <td>0.229488</td>\n",
       "      <td>0.765632</td>\n",
       "      <td>0.256488</td>\n",
       "      <td>0.274963</td>\n",
       "      <td>0.780938</td>\n",
       "      <td>0.479528</td>\n",
       "      <td>0.489782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565688</td>\n",
       "      <td>0.540031</td>\n",
       "      <td>0.671029</td>\n",
       "      <td>0.383420</td>\n",
       "      <td>0.551319</td>\n",
       "      <td>0.291786</td>\n",
       "      <td>0.416466</td>\n",
       "      <td>0.313401</td>\n",
       "      <td>0.008446</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0       0.935192  0.766490  0.881365  0.313023  0.763439  0.267669  0.266815   \n",
       "1       0.978542  0.770067  0.840298  0.271796  0.766120  0.262192  0.264875   \n",
       "2       0.935217  0.753118  0.868141  0.268766  0.762329  0.281122  0.270177   \n",
       "3       0.941878  0.765304  0.868484  0.213661  0.765647  0.275559  0.266803   \n",
       "4       0.938617  0.776520  0.864251  0.269796  0.762975  0.263984  0.268968   \n",
       "5       0.951057  0.777393  0.857187  0.244472  0.768550  0.262721  0.268257   \n",
       "6       0.979184  0.768746  0.838200  0.305241  0.767008  0.265762  0.265324   \n",
       "7       0.947348  0.782220  0.856031  0.230111  0.772104  0.267324  0.272183   \n",
       "8       0.943101  0.770278  0.835452  0.239894  0.783688  0.300439  0.267610   \n",
       "9       0.952547  0.779072  0.855511  0.242081  0.769078  0.260539  0.269325   \n",
       "10      0.982911  0.754846  0.853250  0.190948  0.752445  0.256694  0.256685   \n",
       "11      0.964834  0.773759  0.822263  0.247762  0.785405  0.296369  0.268222   \n",
       "12      0.979530  0.754368  0.844067  0.197188  0.755717  0.255447  0.261156   \n",
       "13      0.976461  0.770294  0.851772  0.372174  0.764515  0.266413  0.264766   \n",
       "14      0.910864  0.763800  0.865863  0.330281  0.764797  0.271139  0.262779   \n",
       "15      0.945511  0.770904  0.873064  0.186826  0.757918  0.262237  0.261648   \n",
       "16      0.977036  0.766833  0.859375  0.309075  0.760762  0.265916  0.261785   \n",
       "17      0.950871  0.776955  0.853435  0.219693  0.771881  0.261734  0.269667   \n",
       "18      0.866533  0.709751  0.857971  0.328896  0.786243  0.245290  0.255853   \n",
       "19      0.983657  0.756397  0.845295  0.188184  0.755245  0.255771  0.258772   \n",
       "20      0.970099  0.752889  0.855249  0.288908  0.757697  0.276182  0.260003   \n",
       "21      0.974645  0.770724  0.834442  0.345429  0.773320  0.280072  0.266012   \n",
       "22      0.978113  0.772556  0.836247  0.352184  0.768603  0.263919  0.266825   \n",
       "23      0.962498  0.770188  0.857956  0.247825  0.756868  0.261510  0.259590   \n",
       "24      0.925225  0.766785  0.830386  0.207022  0.785522  0.292730  0.264971   \n",
       "25      0.923054  0.765977  0.860322  0.270105  0.767704  0.253372  0.268670   \n",
       "26      0.978226  0.770988  0.842333  0.302180  0.764555  0.253810  0.267604   \n",
       "27      0.980765  0.765422  0.844944  0.277465  0.760083  0.254664  0.263742   \n",
       "28      0.951256  0.776812  0.867348  0.317248  0.765766  0.261006  0.269865   \n",
       "29      0.976291  0.765408  0.859354  0.304509  0.760425  0.268835  0.260682   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "284777  0.993616  0.766955  0.814135  0.267800  0.765408  0.249492  0.266741   \n",
       "284778  0.945305  0.773467  0.821686  0.233363  0.771785  0.255371  0.269977   \n",
       "284779  0.991850  0.760756  0.791869  0.233922  0.781387  0.299865  0.262107   \n",
       "284780  0.928946  0.778953  0.875875  0.302846  0.759764  0.270993  0.262143   \n",
       "284781  0.938943  0.765618  0.870242  0.201441  0.775490  0.263961  0.266521   \n",
       "284782  0.953740  0.794062  0.813138  0.466779  0.770019  0.264895  0.265076   \n",
       "284783  0.927780  0.787614  0.788401  0.177021  0.780524  0.294426  0.263706   \n",
       "284784  0.946917  0.777005  0.810673  0.182744  0.784794  0.295603  0.266462   \n",
       "284785  0.958852  0.773012  0.816865  0.175248  0.785457  0.297219  0.267411   \n",
       "284786  0.923022  0.789862  0.793699  0.168234  0.779064  0.300551  0.257939   \n",
       "284787  0.940800  0.755539  0.826390  0.214658  0.782037  0.233293  0.267083   \n",
       "284788  0.992397  0.764301  0.833807  0.266792  0.760898  0.255465  0.262559   \n",
       "284789  0.950701  0.780999  0.834492  0.295443  0.769614  0.256931  0.272992   \n",
       "284790  0.949536  0.777514  0.819832  0.221918  0.771859  0.259841  0.267769   \n",
       "284791  0.943624  0.776488  0.844698  0.228420  0.768117  0.252501  0.269968   \n",
       "284792  0.945992  0.782930  0.817794  0.225014  0.770493  0.258167  0.268696   \n",
       "284793  0.991779  0.759882  0.807998  0.224551  0.777287  0.302345  0.257684   \n",
       "284794  0.936776  0.763033  0.853984  0.219839  0.776030  0.245037  0.267273   \n",
       "284795  0.745650  0.874755  0.690525  0.140643  0.734839  0.249000  0.243226   \n",
       "284796  0.990315  0.765744  0.820086  0.318724  0.765479  0.256850  0.266514   \n",
       "284797  0.954184  0.774774  0.844342  0.231388  0.767362  0.249510  0.271017   \n",
       "284798  0.962023  0.776557  0.826395  0.294527  0.764687  0.252822  0.267958   \n",
       "284799  0.928136  0.767214  0.858031  0.266607  0.773768  0.318518  0.256107   \n",
       "284800  0.992943  0.765409  0.816674  0.262329  0.765658  0.255715  0.265459   \n",
       "284801  0.960338  0.777082  0.827952  0.218901  0.773326  0.260647  0.270307   \n",
       "284802  0.756448  0.873531  0.666991  0.160317  0.729603  0.236810  0.235393   \n",
       "284803  0.945845  0.766677  0.872678  0.219189  0.771561  0.273661  0.265504   \n",
       "284804  0.990905  0.764080  0.781102  0.227202  0.783425  0.293496  0.263547   \n",
       "284805  0.954209  0.772856  0.849587  0.282508  0.763172  0.269291  0.261175   \n",
       "284806  0.949232  0.765256  0.849601  0.229488  0.765632  0.256488  0.274963   \n",
       "\n",
       "              V8        V9       V10  ...       V21       V22       V23  \\\n",
       "0       0.786444  0.475312  0.510600  ...  0.561184  0.522992  0.663793   \n",
       "1       0.786298  0.453981  0.505267  ...  0.557840  0.480237  0.666938   \n",
       "2       0.788042  0.410603  0.513018  ...  0.565477  0.546030  0.678939   \n",
       "3       0.789434  0.414999  0.507585  ...  0.559734  0.510277  0.662607   \n",
       "4       0.782484  0.490950  0.524303  ...  0.561327  0.547271  0.663392   \n",
       "5       0.788178  0.443190  0.501038  ...  0.558122  0.483915  0.665042   \n",
       "6       0.786257  0.478797  0.506668  ...  0.558776  0.497402  0.663145   \n",
       "7       0.744539  0.483978  0.534571  ...  0.592809  0.462660  0.666288   \n",
       "8       0.794515  0.449275  0.500230  ...  0.560296  0.497525  0.662401   \n",
       "9       0.786131  0.437401  0.501132  ...  0.557499  0.480466  0.663640   \n",
       "10      0.785905  0.403515  0.542377  ...  0.561330  0.524674  0.665846   \n",
       "11      0.791159  0.443527  0.515131  ...  0.562284  0.521153  0.665569   \n",
       "12      0.782945  0.390645  0.536109  ...  0.557743  0.487486  0.666691   \n",
       "13      0.786630  0.455164  0.518244  ...  0.560885  0.513502  0.664373   \n",
       "14      0.764928  0.488813  0.532538  ...  0.580045  0.520396  0.680590   \n",
       "15      0.785424  0.447755  0.524192  ...  0.569534  0.573179  0.661623   \n",
       "16      0.787417  0.489730  0.503178  ...  0.561083  0.519174  0.665639   \n",
       "17      0.786329  0.439862  0.493453  ...  0.558339  0.478652  0.663104   \n",
       "18      0.787111  0.505258  0.515863  ...  0.553361  0.555956  0.701946   \n",
       "19      0.784816  0.394618  0.542613  ...  0.558616  0.501864  0.666028   \n",
       "20      0.790162  0.447409  0.520484  ...  0.556715  0.483349  0.664678   \n",
       "21      0.790980  0.421741  0.523709  ...  0.563801  0.528807  0.664713   \n",
       "22      0.786867  0.428705  0.527801  ...  0.561781  0.507140  0.663891   \n",
       "23      0.768030  0.515970  0.491552  ...  0.588081  0.519382  0.662681   \n",
       "24      0.794563  0.464501  0.520593  ...  0.552137  0.472747  0.678358   \n",
       "25      0.784263  0.479166  0.511814  ...  0.554973  0.499423  0.676459   \n",
       "26      0.781875  0.454283  0.507767  ...  0.562560  0.520658  0.663199   \n",
       "27      0.783015  0.425871  0.526692  ...  0.556895  0.494946  0.664874   \n",
       "28      0.785072  0.442339  0.501559  ...  0.562725  0.531365  0.664862   \n",
       "29      0.789687  0.486876  0.507383  ...  0.561700  0.520002  0.665648   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "284777  0.781327  0.485719  0.509309  ...  0.565280  0.548739  0.665403   \n",
       "284778  0.789834  0.437603  0.482962  ...  0.561536  0.489884  0.667539   \n",
       "284779  0.794428  0.501665  0.504155  ...  0.562867  0.535391  0.664956   \n",
       "284780  0.794680  0.492192  0.504684  ...  0.559953  0.521079  0.662400   \n",
       "284781  0.786375  0.460623  0.492334  ...  0.558400  0.480564  0.663247   \n",
       "284782  0.795431  0.379416  0.519584  ...  0.557226  0.470010  0.668926   \n",
       "284783  0.803165  0.478826  0.525955  ...  0.565851  0.563480  0.666693   \n",
       "284784  0.799145  0.431987  0.478651  ...  0.564443  0.519486  0.659894   \n",
       "284785  0.795312  0.457073  0.500716  ...  0.557190  0.476614  0.667045   \n",
       "284786  0.779629  0.472180  0.514936  ...  0.593989  0.435938  0.674173   \n",
       "284787  0.781817  0.454254  0.501930  ...  0.567182  0.532819  0.669794   \n",
       "284788  0.783882  0.495849  0.508137  ...  0.558122  0.489955  0.671623   \n",
       "284789  0.774202  0.448411  0.510307  ...  0.575211  0.524272  0.663234   \n",
       "284790  0.791096  0.455043  0.493135  ...  0.556961  0.470382  0.669893   \n",
       "284791  0.787858  0.445320  0.487350  ...  0.559725  0.487601  0.664327   \n",
       "284792  0.789065  0.454983  0.501519  ...  0.568163  0.571026  0.664549   \n",
       "284793  0.796715  0.508080  0.505684  ...  0.564522  0.542426  0.667854   \n",
       "284794  0.785436  0.463257  0.491841  ...  0.558935  0.468822  0.666748   \n",
       "284795  0.844368  0.631338  0.687797  ...  0.546250  0.437023  0.678661   \n",
       "284796  0.782714  0.485738  0.511224  ...  0.563801  0.539637  0.664808   \n",
       "284797  0.783173  0.466439  0.502831  ...  0.557790  0.486035  0.669586   \n",
       "284798  0.786687  0.452939  0.506412  ...  0.563091  0.525758  0.669173   \n",
       "284799  0.807706  0.502723  0.496427  ...  0.563145  0.540580  0.660252   \n",
       "284800  0.784117  0.477779  0.514262  ...  0.557158  0.476573  0.669858   \n",
       "284801  0.786620  0.455750  0.495120  ...  0.556414  0.472314  0.666181   \n",
       "284802  0.863749  0.528729  0.598850  ...  0.564920  0.515249  0.680500   \n",
       "284803  0.788548  0.482925  0.488530  ...  0.564933  0.553153  0.665619   \n",
       "284804  0.792985  0.477677  0.498692  ...  0.565220  0.537005  0.664877   \n",
       "284805  0.792671  0.476287  0.500464  ...  0.565755  0.547353  0.663008   \n",
       "284806  0.780938  0.479528  0.489782  ...  0.565688  0.540031  0.671029   \n",
       "\n",
       "             V24       V25       V26       V27       V28    Amount  Class  \n",
       "0       0.391253  0.585122  0.394557  0.418976  0.312697  0.005824    0.0  \n",
       "1       0.336440  0.587290  0.446013  0.416345  0.313423  0.000105    0.0  \n",
       "2       0.289354  0.559515  0.402727  0.415489  0.311911  0.014739    0.0  \n",
       "3       0.223826  0.614245  0.389197  0.417669  0.314371  0.004807    0.0  \n",
       "4       0.401270  0.566343  0.507497  0.420561  0.317490  0.002724    0.0  \n",
       "5       0.332185  0.564839  0.442749  0.421196  0.314769  0.000143    0.0  \n",
       "6       0.277122  0.620014  0.383429  0.417148  0.313229  0.000194    0.0  \n",
       "7       0.294686  0.554597  0.417014  0.394234  0.291099  0.001588    0.0  \n",
       "8       0.518546  0.598855  0.362697  0.416728  0.316014  0.003628    0.0  \n",
       "9       0.330349  0.573992  0.440836  0.421056  0.314810  0.000143    0.0  \n",
       "10      0.449678  0.592016  0.404298  0.417302  0.313454  0.000304    0.0  \n",
       "11      0.516540  0.534835  0.345047  0.417295  0.312021  0.000389    0.0  \n",
       "12      0.435168  0.586951  0.367461  0.416999  0.313985  0.004729    0.0  \n",
       "13      0.396348  0.608682  0.442452  0.416908  0.313556  0.001070    0.0  \n",
       "14      0.386050  0.564842  0.386971  0.413470  0.312512  0.002289    0.0  \n",
       "15      0.373464  0.575710  0.411223  0.413170  0.315750  0.000622    0.0  \n",
       "16      0.396216  0.598355  0.363007  0.418224  0.313876  0.000506    0.0  \n",
       "17      0.262525  0.558686  0.417440  0.417982  0.315783  0.000035    0.0  \n",
       "18      0.387910  0.550871  0.323965  0.423747  0.332394  0.001822    0.0  \n",
       "19      0.422095  0.596595  0.389449  0.416923  0.313278  0.000195    0.0  \n",
       "20      0.341241  0.581948  0.356477  0.418109  0.314412  0.009019    0.0  \n",
       "21      0.197376  0.599844  0.458112  0.416813  0.312827  0.001327    0.0  \n",
       "22      0.332321  0.611766  0.443181  0.415763  0.312892  0.000089    0.0  \n",
       "23      0.439243  0.623968  0.388265  0.422724  0.318207  0.000886    0.0  \n",
       "24      0.514750  0.595936  0.449893  0.429570  0.313420  0.000035    0.0  \n",
       "25      0.435937  0.591895  0.470272  0.423155  0.318060  0.001029    0.0  \n",
       "26      0.440856  0.618593  0.370387  0.416813  0.313733  0.001630    0.0  \n",
       "27      0.429013  0.609321  0.379685  0.417292  0.313709  0.000623    0.0  \n",
       "28      0.468814  0.567584  0.380125  0.419883  0.316222  0.001284    0.0  \n",
       "29      0.382632  0.594445  0.360914  0.418015  0.313615  0.000506    0.0  \n",
       "...          ...       ...       ...       ...       ...       ...    ...  \n",
       "284777  0.382415  0.592624  0.408243  0.416098  0.311901  0.000039    0.0  \n",
       "284778  0.461348  0.566624  0.469117  0.413688  0.311799  0.003114    0.0  \n",
       "284779  0.485773  0.604720  0.420249  0.416772  0.311774  0.000973    0.0  \n",
       "284780  0.538299  0.613147  0.360112  0.425939  0.317858  0.001168    0.0  \n",
       "284781  0.410926  0.597792  0.386070  0.413526  0.310096  0.000506    0.0  \n",
       "284782  0.290363  0.540360  0.432743  0.415279  0.311654  0.000499    0.0  \n",
       "284783  0.479425  0.548162  0.386226  0.418894  0.311488  0.000446    0.0  \n",
       "284784  0.469972  0.638183  0.563411  0.411220  0.309314  0.001557    0.0  \n",
       "284785  0.475012  0.552073  0.451901  0.421409  0.314955  0.000070    0.0  \n",
       "284786  0.467456  0.566620  0.457996  0.424608  0.316633  0.000348    0.0  \n",
       "284787  0.396762  0.525390  0.611374  0.416977  0.318306  0.000389    0.0  \n",
       "284788  0.390969  0.543759  0.469297  0.415993  0.312284  0.000155    0.0  \n",
       "284789  0.377018  0.578480  0.366207  0.425797  0.317790  0.002355    0.0  \n",
       "284790  0.382316  0.556779  0.446465  0.416230  0.312688  0.000382    0.0  \n",
       "284791  0.381697  0.571555  0.471248  0.415084  0.313592  0.000791    0.0  \n",
       "284792  0.414934  0.540555  0.381366  0.413362  0.312501  0.000155    0.0  \n",
       "284793  0.480111  0.574635  0.394116  0.417653  0.312237  0.000194    0.0  \n",
       "284794  0.371887  0.572527  0.447128  0.415985  0.315691  0.000035    0.0  \n",
       "284795  0.213356  0.678199  0.477844  0.455101  0.338142  0.000384    0.0  \n",
       "284796  0.375065  0.595667  0.350073  0.416848  0.312290  0.002335    0.0  \n",
       "284797  0.432286  0.546515  0.443930  0.418938  0.314773  0.000214    0.0  \n",
       "284798  0.390008  0.493238  0.448974  0.419856  0.317492  0.000936    0.0  \n",
       "284799  0.482666  0.617454  0.404609  0.424898  0.315768  0.003114    0.0  \n",
       "284800  0.333755  0.560191  0.458300  0.415019  0.311600  0.000104    0.0  \n",
       "284801  0.396086  0.553440  0.445716  0.420534  0.314520  0.000105    0.0  \n",
       "284802  0.313600  0.658558  0.466291  0.433929  0.329840  0.000030    0.0  \n",
       "284803  0.245298  0.543855  0.360884  0.417775  0.312038  0.000965    0.0  \n",
       "284804  0.468492  0.592824  0.411177  0.416593  0.312585  0.002642    0.0  \n",
       "284805  0.398836  0.545958  0.514746  0.418520  0.315245  0.000389    0.0  \n",
       "284806  0.383420  0.551319  0.291786  0.416466  0.313401  0.008446    0.0  \n",
       "\n",
       "[284807 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = preprocessing.MinMaxScaler().fit_transform(data.values)\n",
    "data_scale = pd.DataFrame(scaled, columns=data.columns, index=data.index)\n",
    "data_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier fraction: 0.0017304750013189597\n",
      "Fraud Cases : 492\n",
      "Valid Cases : 284315\n"
     ]
    }
   ],
   "source": [
    "y = data_scale[\"Class\"].values\n",
    "X_normal, X_fraud = data_scale[y == 0].iloc[:,:-1], data_scale[y == 1].iloc[:,:-1]\n",
    "Y_normal, Y_fraud = np.zeros(X_normal.shape[0]), np.ones(X_fraud.shape[0])\n",
    "\n",
    "outlier_fraction = len(Y_fraud)/float(len(Y_normal))\n",
    "print(\"Outlier fraction:\", outlier_fraction)\n",
    "print(\"Fraud Cases : {}\".format(len(Y_fraud)))\n",
    "print(\"Valid Cases : {}\".format(len(Y_normal)))\n",
    "\n",
    "# Splitting Train & Test of Normal data\n",
    "X_train_normal, X_test_normal, Y_train_normal, Y_test_normal = train_test_split(X_normal, Y_normal, test_size=0.2)\n",
    "# Splitting Train & Test of Fraud data\n",
    "X_train_fraud, X_test_fraud, Y_train_fraud, Y_test_fraud = train_test_split(X_fraud, Y_fraud, test_size=0.2)\n",
    "\n",
    "# Combine Train Normal & Fraud data\n",
    "X_train_all = np.append(X_train_normal, X_train_fraud, axis = 0)\n",
    "Y_train_all = np.append(Y_train_normal, Y_train_fraud).astype(int)\n",
    "\n",
    "# Combine Test Normal & Fraud data\n",
    "X_test_all = np.append(X_test_normal, X_test_fraud, axis = 0)\n",
    "Y_test_all = np.append(Y_test_normal, Y_test_fraud).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearch setting\n",
    "cv = ShuffleSplit(test_size=0.2, n_splits=1, random_state=rseed)\n",
    "\n",
    "def evaluation_matrix(Y_test_all, y_pred):\n",
    "    print(classification_report(Y_test_all,y_pred))\n",
    "    print(\"accuracy_score\", accuracy_score(Y_test_all,y_pred))\n",
    "    print(\"f1_score\", f1_score(Y_test_all,y_pred,average=None))\n",
    "    print(\"recall_score\", recall_score(Y_test_all,y_pred,average=None))\n",
    "    print(\"precision_score\", precision_score(Y_test_all,y_pred,average=None))\n",
    "    \n",
    "    matrix = confusion_matrix(Y_test_all, y_pred)\n",
    "    labels = ['Normal', 'Fraud']\n",
    "    g=sns.heatmap(matrix,annot=True, cbar=False, fmt='g', xticklabels=labels, yticklabels=labels)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.title('Confusion matrix of IsolationForest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolation forest (unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 8 candidates, totalling 8 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] contamination=0.0017304750013189597, max_samples=auto, n_estimators=100 \n",
      "[CV]  contamination=0.0017304750013189597, max_samples=auto, n_estimators=100, score=0.277, total=  15.5s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   15.5s remaining:    0.0s\n",
      "[CV] contamination=0.0017304750013189597, max_samples=auto, n_estimators=200 \n",
      "[CV]  contamination=0.0017304750013189597, max_samples=auto, n_estimators=200, score=0.284, total=  28.2s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   43.7s remaining:    0.0s\n",
      "[CV] contamination=0.0017304750013189597, max_samples=100, n_estimators=100 \n",
      "[CV]  contamination=0.0017304750013189597, max_samples=100, n_estimators=100, score=0.259, total=  14.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   57.7s remaining:    0.0s\n",
      "[CV] contamination=0.0017304750013189597, max_samples=100, n_estimators=200 \n",
      "[CV]  contamination=0.0017304750013189597, max_samples=100, n_estimators=200, score=0.260, total=  29.4s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  1.5min remaining:    0.0s\n",
      "[CV] contamination=auto, max_samples=auto, n_estimators=100 ..........\n",
      "[CV]  contamination=auto, max_samples=auto, n_estimators=100, score=0.074, total=   7.8s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  1.6min remaining:    0.0s\n",
      "[CV] contamination=auto, max_samples=auto, n_estimators=200 ..........\n",
      "[CV]  contamination=auto, max_samples=auto, n_estimators=200, score=0.073, total=  15.5s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:  1.8min remaining:    0.0s\n",
      "[CV] contamination=auto, max_samples=100, n_estimators=100 ...........\n",
      "[CV]  contamination=auto, max_samples=100, n_estimators=100, score=0.045, total=   7.7s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  2.0min remaining:    0.0s\n",
      "[CV] contamination=auto, max_samples=100, n_estimators=200 ...........\n",
      "[CV]  contamination=auto, max_samples=100, n_estimators=200, score=0.044, total=  15.2s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=1, test_size=0.2, train_size=None),\n",
       "             estimator=IsolationForest(random_state=1),\n",
       "             param_grid={'contamination': [0.0017304750013189597, 'auto'],\n",
       "                         'max_samples': ['auto', 100],\n",
       "                         'n_estimators': [100, 200]},\n",
       "             scoring=make_scorer(f1_score, average=binary, pos_label=-1),\n",
       "             verbose=100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [100, 200],\n",
    "            'max_samples': ['auto', 100],\n",
    "            'contamination': [outlier_fraction, 'auto']}\n",
    "f1_ms = make_scorer(f1_score, average='binary', pos_label=-1)\n",
    "\n",
    "clf_if = IsolationForest(random_state=rseed)\n",
    "clf_if = GridSearchCV(clf_if, param_grid, cv=cv, scoring=f1_ms, verbose=100)\n",
    "\n",
    "# Provide class label with sklearn format\n",
    "Y_train_all_2 = Y_train_all.copy()\n",
    "Y_train_all_2[Y_train_all_2 == 1] = -1\n",
    "Y_train_all_2[Y_train_all_2 == 0] = 1\n",
    "\n",
    "clf_if.fit(X_train_all, Y_train_all_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contamination': 0.0017304750013189597, 'max_samples': 'auto', 'n_estimators': 200}\n",
      "0.2838709677419355\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch Parameter Tuning result\n",
    "print(clf_if.best_params_)\n",
    "print(clf_if.best_score_)\n",
    "dump(clf_if.best_estimator_, open('isolation_forest.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       0.28      0.27      0.28        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.64      0.64      0.64     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "accuracy_score 0.99750711000316\n",
      "f1_score [0.99875141 0.2755102 ]\n",
      "recall_score [0.99876897 0.27272727]\n",
      "precision_score [0.99873384 0.27835052]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = clf_if.best_estimator_.predict(X_test_all)\n",
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "\n",
    "evaluation_matrix(Y_test_all, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest (supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 8 candidates, totalling 8 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] criterion=gini, min_samples_split=2, n_estimators=100 ...........\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bbd3e965548e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mclf_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf_rf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_rf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf1_ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mclf_rf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train_all\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    713\u001b[0m                                \u001b[1;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    714\u001b[0m                                in product(candidate_params,\n\u001b[1;32m--> 715\u001b[1;33m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    717\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    390\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    391\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[1;32m--> 392\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    394\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 924\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    925\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    166\u001b[0m                                                         indices=indices)\n\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    895\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    373\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 375\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    376\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators': [100, 200],\n",
    "              'criterion': ['gini', 'entropy'],\n",
    "             'min_samples_split': [2, 5]}\n",
    "\n",
    "f1_ms = make_scorer(f1_score, average='binary', pos_label=1)\n",
    "\n",
    "clf_rf = RandomForestClassifier(random_state=rseed)\n",
    "clf_rf = GridSearchCV(clf_rf, param_grid, cv=cv, scoring=f1_ms, verbose=100)\n",
    "clf_rf.fit(X_train_all, Y_train_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'min_samples_split': 2, 'n_estimators': 100}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch Parameter Tuning result\n",
    "print(clf_rf.best_params_)\n",
    "print(clf_rf.best_score_)\n",
    "dump(clf_rf.best_estimator_, open('random_forest.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       1.00      1.00      1.00     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "accuracy_score 1.0\n",
      "f1_score [1. 1.]\n",
      "recall_score [1. 1.]\n",
      "precision_score [1. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = clf_rf.best_estimator_.predict(X_test_all)\n",
    "y_probs = clf_rf.best_estimator_.predict_proba(X_test_all)[:,1]\n",
    "\n",
    "evaluation_matrix(Y_test_all, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-class SVM (semi-supervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 9 candidates, totalling 9 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] gamma=scale, kernel=rbf, nu=0.1 .................................\n",
      "[CV] ..... gamma=scale, kernel=rbf, nu=0.1, score=0.942, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.7s remaining:    0.0s\n",
      "[CV] gamma=scale, kernel=rbf, nu=0.5 .................................\n",
      "[CV] ..... gamma=scale, kernel=rbf, nu=0.5, score=0.669, total=  12.8s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   15.5s remaining:    0.0s\n",
      "[CV] gamma=scale, kernel=rbf, nu=1 ...................................\n",
      "[CV] ....... gamma=scale, kernel=rbf, nu=1, score=0.000, total=  12.9s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   28.4s remaining:    0.0s\n",
      "[CV] gamma=0.1, kernel=rbf, nu=0.1 ...................................\n",
      "[CV] ....... gamma=0.1, kernel=rbf, nu=0.1, score=0.942, total=   2.8s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   31.2s remaining:    0.0s\n",
      "[CV] gamma=0.1, kernel=rbf, nu=0.5 ...................................\n",
      "[CV] ....... gamma=0.1, kernel=rbf, nu=0.5, score=0.670, total=  13.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   44.2s remaining:    0.0s\n",
      "[CV] gamma=0.1, kernel=rbf, nu=1 .....................................\n",
      "[CV] ......... gamma=0.1, kernel=rbf, nu=1, score=0.000, total=  13.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   57.2s remaining:    0.0s\n",
      "[CV] gamma=1, kernel=rbf, nu=0.1 .....................................\n",
      "[CV] ......... gamma=1, kernel=rbf, nu=0.1, score=0.942, total=   2.9s\n",
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:  1.0min remaining:    0.0s\n",
      "[CV] gamma=1, kernel=rbf, nu=0.5 .....................................\n",
      "[CV] ......... gamma=1, kernel=rbf, nu=0.5, score=0.669, total=  13.2s\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.2min remaining:    0.0s\n",
      "[CV] gamma=1, kernel=rbf, nu=1 .......................................\n",
      "[CV] ........... gamma=1, kernel=rbf, nu=1, score=0.000, total=  13.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=1, test_size=0.2, train_size=None),\n",
       "             estimator=OneClassSVM(),\n",
       "             param_grid={'gamma': ['scale', 0.1, 1], 'kernel': ['rbf'],\n",
       "                         'nu': [0.1, 0.5, 1]},\n",
       "             scoring=make_scorer(f1_score), verbose=100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = {'kernel': ['rbf'],\n",
    "             'gamma': ['scale', 0.1, 1],\n",
    "             'nu': [0.1, 0.5, 1]}\n",
    "f1_ms = make_scorer(f1_score)\n",
    "\n",
    "clf_svm = OneClassSVM()\n",
    "clf_svm = GridSearchCV(clf_svm, param_grid, cv=cv, scoring=f1_ms, verbose=100)\n",
    "\n",
    "Y_train_normal_2 = Y_train_normal[:len(Y_train_normal)//10].copy()\n",
    "Y_train_normal_2[Y_train_normal_2 == 1] = -1\n",
    "Y_train_normal_2[Y_train_normal_2 == 0] = 1\n",
    "\n",
    "clf_svm.fit(X_train_normal[:len(X_train_normal)//10], Y_train_normal_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.1, 'kernel': 'rbf', 'nu': 0.1}\n",
      "0.9424619318842263\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch Parameter Tuning result\n",
    "print(clf_svm.best_params_)\n",
    "print(clf_svm.best_score_)\n",
    "dump(clf_svm.best_estimator_, open('oneclass_svm.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95     56863\n",
      "           1       0.02      1.00      0.03        99\n",
      "\n",
      "    accuracy                           0.90     56962\n",
      "   macro avg       0.51      0.95      0.49     56962\n",
      "weighted avg       1.00      0.90      0.94     56962\n",
      "\n",
      "accuracy_score 0.8981601769600787\n",
      "f1_score [0.94624971 0.0330055 ]\n",
      "recall_score [0.89798287 1.        ]\n",
      "precision_score [1.         0.01677966]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = clf_svm.best_estimator_.predict(X_test_all)\n",
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "\n",
    "evaluation_matrix(Y_test_all, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-class Autoencoder\n",
    "1. Hybrid (semi-supervised & supervised): encoder + classifier\n",
    "1. Semi-supervised: using threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(optimizer='Adam', encoded_neuron=32):\n",
    "    input_layer = Input(shape=(X_train_normal.shape[1],))\n",
    "\n",
    "    ## encoding part\n",
    "    encoded = Dense(encoded_neuron*4, activation='relu')(input_layer)\n",
    "    encoded = Dense(encoded_neuron*2, activation='relu')(encoded)\n",
    "    encoded = Dense(encoded_neuron, activation='relu')(encoded)\n",
    "\n",
    "    ## decoding part\n",
    "    decoded = Dense(encoded_neuron, activation='relu')(encoded)\n",
    "    decoded = Dense(encoded_neuron*2, activation='relu')(decoded)\n",
    "    decoded = Dense(encoded_neuron*4, activation='relu')(decoded)\n",
    "\n",
    "    ## output layer\n",
    "    output_layer = Dense(X_train_normal.shape[1], activation='sigmoid')(decoded)\n",
    "\n",
    "    autoencoder = Model(input_layer, output_layer)\n",
    "    autoencoder.compile(optimizer=optimizer, loss=\"mse\")\n",
    "    \n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 6 candidates, totalling 6 fits\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[CV] encoded_neuron=8, optimizer=Adam ................................\n",
      "Epoch 1/100\n",
      "1820/1820 [==============================] - 1s 606us/step - loss: 0.0027\n",
      "Epoch 2/100\n",
      "1820/1820 [==============================] - 1s 604us/step - loss: 0.0013\n",
      "Epoch 3/100\n",
      "1820/1820 [==============================] - 1s 597us/step - loss: 0.0011\n",
      "Epoch 4/100\n",
      "1820/1820 [==============================] - 1s 604us/step - loss: 0.0010\n",
      "Epoch 5/100\n",
      "1820/1820 [==============================] - 1s 601us/step - loss: 0.0010\n",
      "Epoch 6/100\n",
      "1820/1820 [==============================] - 1s 593us/step - loss: 8.5295e-04\n",
      "Epoch 7/100\n",
      "1820/1820 [==============================] - 1s 590us/step - loss: 8.0007e-04\n",
      "Epoch 8/100\n",
      "1820/1820 [==============================] - 1s 595us/step - loss: 6.9026e-04\n",
      "Epoch 9/100\n",
      "1820/1820 [==============================] - 1s 583us/step - loss: 6.7244e-04\n",
      "Epoch 10/100\n",
      "1820/1820 [==============================] - 1s 589us/step - loss: 6.5205e-04\n",
      "Epoch 11/100\n",
      "1820/1820 [==============================] - 1s 590us/step - loss: 6.3929e-04\n",
      "Epoch 12/100\n",
      "1820/1820 [==============================] - 1s 587us/step - loss: 6.2786e-04\n",
      "Epoch 13/100\n",
      "1820/1820 [==============================] - 1s 597us/step - loss: 6.2077e-04\n",
      "Epoch 14/100\n",
      "1820/1820 [==============================] - 1s 598us/step - loss: 6.1488e-04\n",
      "Epoch 15/100\n",
      "1820/1820 [==============================] - 1s 595us/step - loss: 6.0981e-04\n",
      "Epoch 16/100\n",
      "1820/1820 [==============================] - 1s 595us/step - loss: 6.0396e-04\n",
      "Epoch 17/100\n",
      "1820/1820 [==============================] - 1s 594us/step - loss: 5.9982e-04\n",
      "Epoch 18/100\n",
      "1820/1820 [==============================] - 1s 596us/step - loss: 5.9640e-04\n",
      "Epoch 19/100\n",
      "1820/1820 [==============================] - 1s 608us/step - loss: 5.9202e-04\n",
      "Epoch 20/100\n",
      "1820/1820 [==============================] - 1s 597us/step - loss: 5.8856e-04\n",
      "Epoch 21/100\n",
      "1820/1820 [==============================] - 1s 591us/step - loss: 5.8556e-04\n",
      "Epoch 22/100\n",
      "1820/1820 [==============================] - 1s 591us/step - loss: 5.8164e-04\n",
      "Epoch 23/100\n",
      "1820/1820 [==============================] - 1s 590us/step - loss: 5.7797e-04\n",
      "Epoch 24/100\n",
      "1820/1820 [==============================] - 1s 624us/step - loss: 5.7524e-04\n",
      "Epoch 25/100\n",
      "1820/1820 [==============================] - 1s 590us/step - loss: 5.7260e-04\n",
      "Epoch 26/100\n",
      "1820/1820 [==============================] - 1s 589us/step - loss: 5.7017e-04\n",
      "Epoch 27/100\n",
      "1820/1820 [==============================] - 1s 587us/step - loss: 5.6819e-04\n",
      "Epoch 28/100\n",
      "1820/1820 [==============================] - 1s 593us/step - loss: 5.6675e-04\n",
      "Epoch 29/100\n",
      "1820/1820 [==============================] - 1s 589us/step - loss: 5.6506e-04\n",
      "Epoch 30/100\n",
      "1820/1820 [==============================] - 1s 587us/step - loss: 5.6380e-04\n",
      "Epoch 31/100\n",
      "1820/1820 [==============================] - 1s 592us/step - loss: 5.6307e-04\n",
      "Epoch 32/100\n",
      "1820/1820 [==============================] - 1s 590us/step - loss: 5.6165e-04\n",
      "Epoch 33/100\n",
      "1820/1820 [==============================] - 1s 597us/step - loss: 5.6092e-04\n",
      "Epoch 34/100\n",
      "1820/1820 [==============================] - 1s 618us/step - loss: 5.5978e-04\n",
      "Epoch 35/100\n",
      "1820/1820 [==============================] - 1s 592us/step - loss: 5.5925e-04\n",
      "Epoch 36/100\n",
      "1820/1820 [==============================] - 1s 589us/step - loss: 5.5829e-04\n",
      "Epoch 37/100\n",
      "1820/1820 [==============================] - 1s 595us/step - loss: 5.5800e-04\n",
      "Epoch 38/100\n",
      "1820/1820 [==============================] - 1s 594us/step - loss: 5.5717e-04\n",
      "Epoch 39/100\n",
      "1820/1820 [==============================] - 1s 594us/step - loss: 5.5579e-04\n",
      "Epoch 40/100\n",
      "1820/1820 [==============================] - 1s 596us/step - loss: 5.5513e-04\n",
      "Epoch 41/100\n",
      "1820/1820 [==============================] - 1s 601us/step - loss: 5.5438e-04\n",
      "Epoch 42/100\n",
      "1820/1820 [==============================] - 1s 660us/step - loss: 5.5321e-04\n",
      "Epoch 43/100\n",
      "1820/1820 [==============================] - 1s 602us/step - loss: 5.5319e-04\n",
      "Epoch 44/100\n",
      "1820/1820 [==============================] - 1s 637us/step - loss: 5.5159e-04\n",
      "Epoch 45/100\n",
      "1820/1820 [==============================] - 1s 654us/step - loss: 5.5124e-04\n",
      "Epoch 46/100\n",
      "1820/1820 [==============================] - 1s 647us/step - loss: 5.5028e-04\n",
      "Epoch 47/100\n",
      "1820/1820 [==============================] - 1s 603us/step - loss: 5.4996e-04\n",
      "Epoch 48/100\n",
      "1820/1820 [==============================] - 1s 607us/step - loss: 5.4811e-04\n",
      "Epoch 49/100\n",
      "1820/1820 [==============================] - 1s 591us/step - loss: 5.4726e-04\n",
      "Epoch 50/100\n",
      "1820/1820 [==============================] - 1s 621us/step - loss: 5.4616e-04\n",
      "Epoch 51/100\n",
      "1820/1820 [==============================] - 1s 590us/step - loss: 5.4439e-04\n",
      "Epoch 52/100\n",
      "1820/1820 [==============================] - 1s 590us/step - loss: 5.4290e-04\n",
      "Epoch 53/100\n",
      "1820/1820 [==============================] - 1s 601us/step - loss: 5.4013e-04\n",
      "Epoch 54/100\n",
      "1820/1820 [==============================] - 1s 598us/step - loss: 5.3766e-04\n",
      "Epoch 55/100\n",
      "1820/1820 [==============================] - 1s 635us/step - loss: 5.3492e-04\n",
      "Epoch 56/100\n",
      "1820/1820 [==============================] - 1s 634us/step - loss: 5.3383e-04\n",
      "Epoch 57/100\n",
      "1820/1820 [==============================] - 1s 651us/step - loss: 5.3158e-04\n",
      "Epoch 58/100\n",
      "1820/1820 [==============================] - 1s 602us/step - loss: 5.2993e-04\n",
      "Epoch 59/100\n",
      "1820/1820 [==============================] - 1s 621us/step - loss: 5.2771e-04\n",
      "Epoch 60/100\n",
      "1820/1820 [==============================] - 1s 618us/step - loss: 5.2781e-04\n",
      "Epoch 61/100\n",
      "1820/1820 [==============================] - 1s 591us/step - loss: 5.2625e-04\n",
      "Epoch 62/100\n",
      "1820/1820 [==============================] - 1s 617us/step - loss: 5.2498e-04\n",
      "Epoch 63/100\n",
      "1820/1820 [==============================] - 1s 690us/step - loss: 5.2406e-04\n",
      "Epoch 64/100\n",
      "1820/1820 [==============================] - 1s 639us/step - loss: 5.2271e-04\n",
      "Epoch 65/100\n",
      "1820/1820 [==============================] - 1s 626us/step - loss: 5.2206e-04\n",
      "Epoch 66/100\n",
      "1820/1820 [==============================] - 1s 627us/step - loss: 5.2092e-04\n",
      "Epoch 67/100\n",
      "1820/1820 [==============================] - 1s 628us/step - loss: 5.1983e-04\n",
      "Epoch 68/100\n",
      "1820/1820 [==============================] - 1s 611us/step - loss: 5.1870e-04\n",
      "Epoch 69/100\n",
      "1820/1820 [==============================] - 1s 613us/step - loss: 5.1788e-04\n",
      "Epoch 70/100\n",
      "1820/1820 [==============================] - 1s 604us/step - loss: 5.1694e-04\n",
      "Epoch 71/100\n",
      "1820/1820 [==============================] - 1s 597us/step - loss: 5.1589e-04\n",
      "Epoch 72/100\n",
      "1820/1820 [==============================] - 1s 600us/step - loss: 5.1505e-04\n",
      "Epoch 73/100\n",
      "1820/1820 [==============================] - 1s 613us/step - loss: 5.1440e-04\n",
      "Epoch 74/100\n",
      "1820/1820 [==============================] - 1s 599us/step - loss: 5.1384e-04\n",
      "Epoch 75/100\n",
      "1820/1820 [==============================] - 1s 598us/step - loss: 5.1295e-04\n",
      "Epoch 76/100\n",
      "1820/1820 [==============================] - 1s 598us/step - loss: 5.1256e-04\n",
      "Epoch 77/100\n",
      "1820/1820 [==============================] - 1s 629us/step - loss: 5.1218e-04\n",
      "Epoch 78/100\n",
      "1820/1820 [==============================] - 1s 600us/step - loss: 5.1158e-04\n",
      "Epoch 79/100\n",
      "1820/1820 [==============================] - 1s 603us/step - loss: 5.1129e-04\n",
      "Epoch 80/100\n",
      "1820/1820 [==============================] - 1s 606us/step - loss: 5.1011e-04\n",
      "Epoch 81/100\n",
      "1820/1820 [==============================] - 1s 600us/step - loss: 5.0975e-04\n",
      "Epoch 82/100\n",
      "1820/1820 [==============================] - 1s 612us/step - loss: 5.0958e-04\n",
      "Epoch 83/100\n",
      "1820/1820 [==============================] - 1s 625us/step - loss: 5.0870e-04\n",
      "Epoch 84/100\n",
      "1820/1820 [==============================] - 1s 606us/step - loss: 5.0827e-04\n",
      "Epoch 85/100\n",
      "1820/1820 [==============================] - 1s 598us/step - loss: 5.0781e-04\n",
      "Epoch 86/100\n",
      "1820/1820 [==============================] - 1s 590us/step - loss: 4.8477e-04\n",
      "Epoch 87/100\n",
      "1820/1820 [==============================] - 1s 602us/step - loss: 4.3255e-04\n",
      "Epoch 88/100\n",
      "1820/1820 [==============================] - 1s 596us/step - loss: 4.1097e-04\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1820/1820 [==============================] - 1s 596us/step - loss: 4.0556e-04\n",
      "Epoch 90/100\n",
      "1820/1820 [==============================] - 1s 590us/step - loss: 4.0250e-04\n",
      "Epoch 91/100\n",
      "1820/1820 [==============================] - 1s 610us/step - loss: 3.9868e-04\n",
      "Epoch 92/100\n",
      "1820/1820 [==============================] - 1s 594us/step - loss: 3.9554e-04\n",
      "Epoch 93/100\n",
      "1820/1820 [==============================] - 1s 592us/step - loss: 3.9266e-04\n",
      "Epoch 94/100\n",
      "1820/1820 [==============================] - 1s 592us/step - loss: 3.8989e-04\n",
      "Epoch 95/100\n",
      "1820/1820 [==============================] - 1s 596us/step - loss: 3.8606e-04\n",
      "Epoch 96/100\n",
      "1820/1820 [==============================] - 1s 592us/step - loss: 3.8448e-04\n",
      "Epoch 97/100\n",
      "1820/1820 [==============================] - 1s 591us/step - loss: 3.8242e-04\n",
      "Epoch 98/100\n",
      "1820/1820 [==============================] - 1s 592us/step - loss: 3.8145e-04\n",
      "Epoch 99/100\n",
      "1820/1820 [==============================] - 1s 595us/step - loss: 3.8073e-04\n",
      "Epoch 100/100\n",
      "1820/1820 [==============================] - 1s 599us/step - loss: 3.7982e-04\n",
      "[CV] ... encoded_neuron=8, optimizer=Adam, score=-0.000, total= 1.9min\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:  1.9min remaining:    0.0s\n",
      "[CV] encoded_neuron=8, optimizer=SGD .................................\n",
      "Epoch 1/100\n",
      "1820/1820 [==============================] - 1s 488us/step - loss: 0.0484\n",
      "Epoch 2/100\n",
      "1820/1820 [==============================] - 1s 482us/step - loss: 0.0395\n",
      "Epoch 3/100\n",
      "1820/1820 [==============================] - 1s 469us/step - loss: 0.0300\n",
      "Epoch 4/100\n",
      "1820/1820 [==============================] - 1s 473us/step - loss: 0.0186\n",
      "Epoch 5/100\n",
      "1820/1820 [==============================] - 1s 474us/step - loss: 0.0085\n",
      "Epoch 6/100\n",
      "1820/1820 [==============================] - 1s 494us/step - loss: 0.0042\n",
      "Epoch 7/100\n",
      "1820/1820 [==============================] - 1s 481us/step - loss: 0.0029\n",
      "Epoch 8/100\n",
      "1820/1820 [==============================] - 1s 491us/step - loss: 0.0024\n",
      "Epoch 9/100\n",
      "1820/1820 [==============================] - 1s 488us/step - loss: 0.0022\n",
      "Epoch 10/100\n",
      "1820/1820 [==============================] - 1s 491us/step - loss: 0.0020\n",
      "Epoch 11/100\n",
      "1820/1820 [==============================] - 1s 486us/step - loss: 0.0019\n",
      "Epoch 12/100\n",
      "1820/1820 [==============================] - 1s 502us/step - loss: 0.0019\n",
      "Epoch 13/100\n",
      "1820/1820 [==============================] - 1s 485us/step - loss: 0.0018\n",
      "Epoch 14/100\n",
      "1820/1820 [==============================] - 1s 496us/step - loss: 0.0018\n",
      "Epoch 15/100\n",
      "1820/1820 [==============================] - 1s 483us/step - loss: 0.0018\n",
      "Epoch 16/100\n",
      "1820/1820 [==============================] - 1s 489us/step - loss: 0.0017\n",
      "Epoch 17/100\n",
      "1820/1820 [==============================] - 1s 498us/step - loss: 0.0017\n",
      "Epoch 18/100\n",
      "1820/1820 [==============================] - 1s 506us/step - loss: 0.0017\n",
      "Epoch 19/100\n",
      "1820/1820 [==============================] - 1s 500us/step - loss: 0.0017\n",
      "Epoch 20/100\n",
      "1820/1820 [==============================] - 1s 499us/step - loss: 0.0017\n",
      "Epoch 21/100\n",
      "1820/1820 [==============================] - 1s 507us/step - loss: 0.0017\n",
      "Epoch 22/100\n",
      "1820/1820 [==============================] - 1s 493us/step - loss: 0.0017\n",
      "Epoch 23/100\n",
      "1820/1820 [==============================] - 1s 500us/step - loss: 0.0017\n",
      "Epoch 24/100\n",
      "1820/1820 [==============================] - 1s 515us/step - loss: 0.0017\n",
      "Epoch 25/100\n",
      "1820/1820 [==============================] - 1s 512us/step - loss: 0.0017\n",
      "Epoch 26/100\n",
      "1820/1820 [==============================] - 1s 496us/step - loss: 0.0017\n",
      "Epoch 27/100\n",
      "1820/1820 [==============================] - 1s 487us/step - loss: 0.0017\n",
      "Epoch 28/100\n",
      "1820/1820 [==============================] - 1s 486us/step - loss: 0.0016\n",
      "Epoch 29/100\n",
      "1820/1820 [==============================] - 1s 498us/step - loss: 0.0016\n",
      "Epoch 30/100\n",
      "1820/1820 [==============================] - 1s 504us/step - loss: 0.0016\n",
      "Epoch 31/100\n",
      "1820/1820 [==============================] - 1s 511us/step - loss: 0.0016\n",
      "Epoch 32/100\n",
      "1820/1820 [==============================] - 1s 504us/step - loss: 0.0016\n",
      "Epoch 33/100\n",
      "1820/1820 [==============================] - 1s 489us/step - loss: 0.0016\n",
      "Epoch 34/100\n",
      "1820/1820 [==============================] - 1s 500us/step - loss: 0.0016\n",
      "Epoch 35/100\n",
      "1820/1820 [==============================] - 1s 513us/step - loss: 0.0016\n",
      "Epoch 36/100\n",
      "1820/1820 [==============================] - 1s 506us/step - loss: 0.0016\n",
      "Epoch 37/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 38/100\n",
      "1820/1820 [==============================] - 1s 476us/step - loss: 0.0016\n",
      "Epoch 39/100\n",
      "1820/1820 [==============================] - 1s 482us/step - loss: 0.0016\n",
      "Epoch 40/100\n",
      "1820/1820 [==============================] - 1s 480us/step - loss: 0.0016\n",
      "Epoch 41/100\n",
      "1820/1820 [==============================] - 1s 477us/step - loss: 0.0016\n",
      "Epoch 42/100\n",
      "1820/1820 [==============================] - 1s 505us/step - loss: 0.0016\n",
      "Epoch 43/100\n",
      "1820/1820 [==============================] - 1s 484us/step - loss: 0.0016\n",
      "Epoch 44/100\n",
      "1820/1820 [==============================] - 1s 494us/step - loss: 0.0016\n",
      "Epoch 45/100\n",
      "1820/1820 [==============================] - 1s 498us/step - loss: 0.0016\n",
      "Epoch 46/100\n",
      "1820/1820 [==============================] - 1s 499us/step - loss: 0.0016\n",
      "Epoch 47/100\n",
      "1820/1820 [==============================] - 1s 470us/step - loss: 0.0016\n",
      "Epoch 48/100\n",
      "1820/1820 [==============================] - 1s 476us/step - loss: 0.0016\n",
      "Epoch 49/100\n",
      "1820/1820 [==============================] - 1s 486us/step - loss: 0.0016\n",
      "Epoch 50/100\n",
      "1820/1820 [==============================] - 1s 513us/step - loss: 0.0016\n",
      "Epoch 51/100\n",
      "1820/1820 [==============================] - 1s 498us/step - loss: 0.0016\n",
      "Epoch 52/100\n",
      "1820/1820 [==============================] - 1s 477us/step - loss: 0.0016\n",
      "Epoch 53/100\n",
      "1820/1820 [==============================] - 1s 482us/step - loss: 0.0016\n",
      "Epoch 54/100\n",
      "1820/1820 [==============================] - 1s 483us/step - loss: 0.0016\n",
      "Epoch 55/100\n",
      "1820/1820 [==============================] - 1s 480us/step - loss: 0.0016\n",
      "Epoch 56/100\n",
      "1820/1820 [==============================] - 1s 487us/step - loss: 0.0016\n",
      "Epoch 57/100\n",
      "1820/1820 [==============================] - 1s 489us/step - loss: 0.0016\n",
      "Epoch 58/100\n",
      "1820/1820 [==============================] - 1s 481us/step - loss: 0.0016\n",
      "Epoch 59/100\n",
      "1820/1820 [==============================] - 1s 484us/step - loss: 0.0016\n",
      "Epoch 60/100\n",
      "1820/1820 [==============================] - 1s 514us/step - loss: 0.0016\n",
      "Epoch 61/100\n",
      "1820/1820 [==============================] - 1s 484us/step - loss: 0.0016\n",
      "Epoch 62/100\n",
      "1820/1820 [==============================] - 1s 475us/step - loss: 0.0016\n",
      "Epoch 63/100\n",
      "1820/1820 [==============================] - 1s 486us/step - loss: 0.0016\n",
      "Epoch 64/100\n",
      "1820/1820 [==============================] - 1s 483us/step - loss: 0.0016\n",
      "Epoch 65/100\n",
      "1820/1820 [==============================] - 1s 489us/step - loss: 0.0016\n",
      "Epoch 66/100\n",
      "1820/1820 [==============================] - 1s 477us/step - loss: 0.0016\n",
      "Epoch 67/100\n",
      "1820/1820 [==============================] - 1s 470us/step - loss: 0.0016\n",
      "Epoch 68/100\n",
      "1820/1820 [==============================] - 1s 483us/step - loss: 0.0016\n",
      "Epoch 69/100\n",
      "1820/1820 [==============================] - 1s 484us/step - loss: 0.0016\n",
      "Epoch 70/100\n",
      "1820/1820 [==============================] - 1s 497us/step - loss: 0.0016\n",
      "Epoch 71/100\n",
      "1820/1820 [==============================] - 1s 511us/step - loss: 0.0016\n",
      "Epoch 72/100\n",
      "1820/1820 [==============================] - 1s 498us/step - loss: 0.0016\n",
      "Epoch 73/100\n",
      "1820/1820 [==============================] - 1s 484us/step - loss: 0.0016\n",
      "Epoch 74/100\n",
      "1820/1820 [==============================] - 1s 486us/step - loss: 0.0016\n",
      "Epoch 75/100\n",
      "1820/1820 [==============================] - 1s 483us/step - loss: 0.0016\n",
      "Epoch 76/100\n",
      "1820/1820 [==============================] - 1s 486us/step - loss: 0.0016\n",
      "Epoch 77/100\n",
      "1820/1820 [==============================] - 1s 486us/step - loss: 0.0016\n",
      "Epoch 78/100\n",
      "1820/1820 [==============================] - 1s 511us/step - loss: 0.0016\n",
      "Epoch 79/100\n",
      "1820/1820 [==============================] - 1s 480us/step - loss: 0.0016\n",
      "Epoch 80/100\n",
      "1820/1820 [==============================] - 1s 483us/step - loss: 0.0016\n",
      "Epoch 81/100\n",
      "1820/1820 [==============================] - 1s 500us/step - loss: 0.0016\n",
      "Epoch 82/100\n",
      "1820/1820 [==============================] - 1s 486us/step - loss: 0.0016\n",
      "Epoch 83/100\n",
      "1820/1820 [==============================] - 1s 507us/step - loss: 0.0016\n",
      "Epoch 84/100\n",
      "1820/1820 [==============================] - 1s 500us/step - loss: 0.0016\n",
      "Epoch 85/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 86/100\n",
      "1820/1820 [==============================] - 1s 483us/step - loss: 0.0016\n",
      "Epoch 87/100\n",
      "1820/1820 [==============================] - 1s 480us/step - loss: 0.0016\n",
      "Epoch 88/100\n",
      "1820/1820 [==============================] - 1s 503us/step - loss: 0.0016\n",
      "Epoch 89/100\n",
      "1820/1820 [==============================] - 1s 489us/step - loss: 0.0016\n",
      "Epoch 90/100\n",
      "1820/1820 [==============================] - 1s 483us/step - loss: 0.0016\n",
      "Epoch 91/100\n",
      "1820/1820 [==============================] - 1s 478us/step - loss: 0.0016\n",
      "Epoch 92/100\n",
      "1820/1820 [==============================] - 1s 481us/step - loss: 0.0016\n",
      "Epoch 93/100\n",
      "1820/1820 [==============================] - 1s 490us/step - loss: 0.0016\n",
      "Epoch 94/100\n",
      "1820/1820 [==============================] - 1s 492us/step - loss: 0.0016\n",
      "Epoch 95/100\n",
      "1820/1820 [==============================] - 1s 507us/step - loss: 0.0016\n",
      "Epoch 96/100\n",
      "1820/1820 [==============================] - 1s 511us/step - loss: 0.0016\n",
      "Epoch 97/100\n",
      "1820/1820 [==============================] - 1s 496us/step - loss: 0.0016\n",
      "Epoch 98/100\n",
      "1820/1820 [==============================] - 1s 491us/step - loss: 0.0016\n",
      "Epoch 99/100\n",
      "1820/1820 [==============================] - 1s 492us/step - loss: 0.0016\n",
      "Epoch 100/100\n",
      "1820/1820 [==============================] - 1s 494us/step - loss: 0.0016\n",
      "[CV] .... encoded_neuron=8, optimizer=SGD, score=-0.002, total= 1.5min\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  3.4min remaining:    0.0s\n",
      "[CV] encoded_neuron=16, optimizer=Adam ...............................\n",
      "Epoch 1/100\n",
      "1820/1820 [==============================] - 1s 715us/step - loss: 0.0022\n",
      "Epoch 2/100\n",
      "1820/1820 [==============================] - 1s 713us/step - loss: 8.9359e-04\n",
      "Epoch 3/100\n",
      "1820/1820 [==============================] - 1s 733us/step - loss: 6.6394e-04\n",
      "Epoch 4/100\n",
      "1820/1820 [==============================] - 1s 714us/step - loss: 5.3338e-04\n",
      "Epoch 5/100\n",
      "1820/1820 [==============================] - 1s 703us/step - loss: 4.9672e-04\n",
      "Epoch 6/100\n",
      "1820/1820 [==============================] - 1s 696us/step - loss: 4.4949e-04\n",
      "Epoch 7/100\n",
      "1820/1820 [==============================] - 1s 700us/step - loss: 3.5400e-04\n",
      "Epoch 8/100\n",
      "1820/1820 [==============================] - 1s 722us/step - loss: 3.3385e-04\n",
      "Epoch 9/100\n",
      "1820/1820 [==============================] - 1s 742us/step - loss: 3.2157e-04\n",
      "Epoch 10/100\n",
      "1820/1820 [==============================] - 1s 701us/step - loss: 3.1549e-04\n",
      "Epoch 11/100\n",
      "1820/1820 [==============================] - 1s 698us/step - loss: 3.1063e-04\n",
      "Epoch 12/100\n",
      "1820/1820 [==============================] - 1s 697us/step - loss: 3.0669e-04\n",
      "Epoch 13/100\n",
      "1820/1820 [==============================] - 1s 730us/step - loss: 3.0287e-04\n",
      "Epoch 14/100\n",
      "1820/1820 [==============================] - 1s 714us/step - loss: 2.9786e-04\n",
      "Epoch 15/100\n",
      "1820/1820 [==============================] - 1s 706us/step - loss: 2.9047e-04\n",
      "Epoch 16/100\n",
      "1820/1820 [==============================] - 1s 706us/step - loss: 2.7940e-04\n",
      "Epoch 17/100\n",
      "1820/1820 [==============================] - 1s 742us/step - loss: 2.5315e-04\n",
      "Epoch 18/100\n",
      "1820/1820 [==============================] - 1s 681us/step - loss: 2.3473e-04\n",
      "Epoch 19/100\n",
      "1820/1820 [==============================] - 1s 700us/step - loss: 2.2836e-04\n",
      "Epoch 20/100\n",
      "1820/1820 [==============================] - 1s 685us/step - loss: 2.2297e-04\n",
      "Epoch 21/100\n",
      "1820/1820 [==============================] - 1s 704us/step - loss: 2.1757e-04\n",
      "Epoch 22/100\n",
      "1820/1820 [==============================] - 1s 683us/step - loss: 2.1180e-04\n",
      "Epoch 23/100\n",
      "1820/1820 [==============================] - 1s 687us/step - loss: 2.0631e-04\n",
      "Epoch 24/100\n",
      "1820/1820 [==============================] - 1s 683us/step - loss: 2.0315e-04\n",
      "Epoch 25/100\n",
      "1820/1820 [==============================] - 1s 685us/step - loss: 2.0073e-04\n",
      "Epoch 26/100\n",
      "1820/1820 [==============================] - 1s 680us/step - loss: 1.9787e-04\n",
      "Epoch 27/100\n",
      "1820/1820 [==============================] - 1s 680us/step - loss: 1.9374e-04\n",
      "Epoch 28/100\n",
      "1820/1820 [==============================] - 1s 682us/step - loss: 1.9045e-04\n",
      "Epoch 29/100\n",
      "1820/1820 [==============================] - 1s 682us/step - loss: 1.8778e-04\n",
      "Epoch 30/100\n",
      "1820/1820 [==============================] - 1s 685us/step - loss: 1.8558e-04\n",
      "Epoch 31/100\n",
      "1820/1820 [==============================] - 1s 698us/step - loss: 1.8365e-04\n",
      "Epoch 32/100\n",
      "1820/1820 [==============================] - 1s 693us/step - loss: 1.8097e-04\n",
      "Epoch 33/100\n",
      "1820/1820 [==============================] - 1s 688us/step - loss: 1.7933e-04\n",
      "Epoch 34/100\n",
      "1820/1820 [==============================] - 1s 702us/step - loss: 1.7780e-04\n",
      "Epoch 35/100\n",
      "1820/1820 [==============================] - 1s 690us/step - loss: 1.7623e-04\n",
      "Epoch 36/100\n",
      "1820/1820 [==============================] - 1s 683us/step - loss: 1.7422e-04\n",
      "Epoch 37/100\n",
      "1820/1820 [==============================] - 1s 677us/step - loss: 1.7238e-04\n",
      "Epoch 38/100\n",
      "1820/1820 [==============================] - 1s 691us/step - loss: 1.7108e-04\n",
      "Epoch 39/100\n",
      "1820/1820 [==============================] - 1s 683us/step - loss: 1.6977e-04\n",
      "Epoch 40/100\n",
      "1820/1820 [==============================] - 1s 679us/step - loss: 1.6848e-04\n",
      "Epoch 41/100\n",
      "1820/1820 [==============================] - 1s 682us/step - loss: 1.6747e-04\n",
      "Epoch 42/100\n",
      "1820/1820 [==============================] - 1s 678us/step - loss: 1.6656e-04\n",
      "Epoch 43/100\n",
      "1820/1820 [==============================] - 1s 696us/step - loss: 1.6536e-04\n",
      "Epoch 44/100\n",
      "1820/1820 [==============================] - 1s 684us/step - loss: 1.6476e-04\n",
      "Epoch 45/100\n",
      "1820/1820 [==============================] - 1s 681us/step - loss: 1.6328e-04\n",
      "Epoch 46/100\n",
      "1820/1820 [==============================] - 1s 690us/step - loss: 1.6236e-04\n",
      "Epoch 47/100\n",
      "1820/1820 [==============================] - 1s 710us/step - loss: 1.6108e-04\n",
      "Epoch 48/100\n",
      "1820/1820 [==============================] - 1s 684us/step - loss: 1.6001e-04\n",
      "Epoch 49/100\n",
      "1820/1820 [==============================] - 1s 683us/step - loss: 1.5944e-04\n",
      "Epoch 50/100\n",
      "1820/1820 [==============================] - 1s 685us/step - loss: 1.5849e-04\n",
      "Epoch 51/100\n",
      "1820/1820 [==============================] - 1s 680us/step - loss: 1.5749e-04\n",
      "Epoch 52/100\n",
      "1820/1820 [==============================] - 1s 685us/step - loss: 1.5647e-04\n",
      "Epoch 53/100\n",
      "1820/1820 [==============================] - 1s 680us/step - loss: 1.5580e-04\n",
      "Epoch 54/100\n",
      "1820/1820 [==============================] - 1s 688us/step - loss: 1.5553e-04\n",
      "Epoch 55/100\n",
      "1820/1820 [==============================] - 1s 687us/step - loss: 1.5437e-04\n",
      "Epoch 56/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 1.5403e-04\n",
      "Epoch 57/100\n",
      "1820/1820 [==============================] - 1s 685us/step - loss: 1.5340e-04\n",
      "Epoch 58/100\n",
      "1820/1820 [==============================] - 1s 687us/step - loss: 1.5257e-04\n",
      "Epoch 59/100\n",
      "1820/1820 [==============================] - 1s 706us/step - loss: 1.5217e-04\n",
      "Epoch 60/100\n",
      "1820/1820 [==============================] - 1s 696us/step - loss: 1.5187e-04\n",
      "Epoch 61/100\n",
      "1820/1820 [==============================] - 1s 693us/step - loss: 1.5139e-04\n",
      "Epoch 62/100\n",
      "1820/1820 [==============================] - 1s 688us/step - loss: 1.5098e-04\n",
      "Epoch 63/100\n",
      "1820/1820 [==============================] - 1s 684us/step - loss: 1.5062e-04\n",
      "Epoch 64/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 1.5022e-04\n",
      "Epoch 65/100\n",
      "1820/1820 [==============================] - 1s 693us/step - loss: 1.4964e-04\n",
      "Epoch 66/100\n",
      "1820/1820 [==============================] - 1s 688us/step - loss: 1.4946e-04\n",
      "Epoch 67/100\n",
      "1820/1820 [==============================] - 1s 690us/step - loss: 1.4874e-04\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1820/1820 [==============================] - 1s 690us/step - loss: 1.4827e-04\n",
      "Epoch 69/100\n",
      "1820/1820 [==============================] - 1s 692us/step - loss: 1.4814e-04\n",
      "Epoch 70/100\n",
      "1820/1820 [==============================] - 1s 693us/step - loss: 1.4760e-04\n",
      "Epoch 71/100\n",
      "1820/1820 [==============================] - 1s 684us/step - loss: 1.4754e-04\n",
      "Epoch 72/100\n",
      "1820/1820 [==============================] - 1s 707us/step - loss: 1.4700e-04\n",
      "Epoch 73/100\n",
      "1820/1820 [==============================] - 1s 690us/step - loss: 1.4632e-04\n",
      "Epoch 74/100\n",
      "1820/1820 [==============================] - 1s 706us/step - loss: 1.4624e-04\n",
      "Epoch 75/100\n",
      "1820/1820 [==============================] - 1s 690us/step - loss: 1.4581e-04\n",
      "Epoch 76/100\n",
      "1820/1820 [==============================] - 1s 690us/step - loss: 1.4558e-04\n",
      "Epoch 77/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 1.4497e-04\n",
      "Epoch 78/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 1.4541e-04\n",
      "Epoch 79/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 1.4411e-04\n",
      "Epoch 80/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 1.4378e-04\n",
      "Epoch 81/100\n",
      "1820/1820 [==============================] - 1s 688us/step - loss: 1.4361e-04\n",
      "Epoch 82/100\n",
      "1820/1820 [==============================] - 1s 689us/step - loss: 1.4325e-04\n",
      "Epoch 83/100\n",
      "1820/1820 [==============================] - 1s 691us/step - loss: 1.4292e-04\n",
      "Epoch 84/100\n",
      "1820/1820 [==============================] - 1s 684us/step - loss: 1.4224e-04\n",
      "Epoch 85/100\n",
      "1820/1820 [==============================] - 1s 706us/step - loss: 1.4295e-04\n",
      "Epoch 86/100\n",
      "1820/1820 [==============================] - 1s 705us/step - loss: 1.4159e-04\n",
      "Epoch 87/100\n",
      "1820/1820 [==============================] - 1s 687us/step - loss: 1.4185e-04\n",
      "Epoch 88/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 1.4095e-04\n",
      "Epoch 89/100\n",
      "1820/1820 [==============================] - 1s 687us/step - loss: 1.4109e-04\n",
      "Epoch 90/100\n",
      "1820/1820 [==============================] - 1s 692us/step - loss: 1.4102e-04\n",
      "Epoch 91/100\n",
      "1820/1820 [==============================] - 1s 688us/step - loss: 1.4050e-04\n",
      "Epoch 92/100\n",
      "1820/1820 [==============================] - 1s 688us/step - loss: 1.3989e-04\n",
      "Epoch 93/100\n",
      "1820/1820 [==============================] - 1s 703us/step - loss: 1.4052e-04\n",
      "Epoch 94/100\n",
      "1820/1820 [==============================] - 1s 690us/step - loss: 1.3985e-04\n",
      "Epoch 95/100\n",
      "1820/1820 [==============================] - 1s 681us/step - loss: 1.3902e-04\n",
      "Epoch 96/100\n",
      "1820/1820 [==============================] - 1s 680us/step - loss: 1.3951e-04\n",
      "Epoch 97/100\n",
      "1820/1820 [==============================] - 1s 694us/step - loss: 1.3856e-04\n",
      "Epoch 98/100\n",
      "1820/1820 [==============================] - 1s 694us/step - loss: 1.3856e-04\n",
      "Epoch 99/100\n",
      "1820/1820 [==============================] - 1s 679us/step - loss: 1.3807e-04\n",
      "Epoch 100/100\n",
      "1820/1820 [==============================] - 1s 680us/step - loss: 1.3782e-04\n",
      "[CV] .. encoded_neuron=16, optimizer=Adam, score=-0.000, total= 2.1min\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  5.5min remaining:    0.0s\n",
      "[CV] encoded_neuron=16, optimizer=SGD ................................\n",
      "Epoch 1/100\n",
      "1820/1820 [==============================] - 1s 520us/step - loss: 0.0469\n",
      "Epoch 2/100\n",
      "1820/1820 [==============================] - 1s 520us/step - loss: 0.0306\n",
      "Epoch 3/100\n",
      "1820/1820 [==============================] - 1s 526us/step - loss: 0.0079\n",
      "Epoch 4/100\n",
      "1820/1820 [==============================] - 1s 526us/step - loss: 0.0024\n",
      "Epoch 5/100\n",
      "1820/1820 [==============================] - 1s 521us/step - loss: 0.0020\n",
      "Epoch 6/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0018\n",
      "Epoch 7/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0018\n",
      "Epoch 8/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0017\n",
      "Epoch 9/100\n",
      "1820/1820 [==============================] - 1s 527us/step - loss: 0.0017\n",
      "Epoch 10/100\n",
      "1820/1820 [==============================] - 1s 528us/step - loss: 0.0017\n",
      "Epoch 11/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0017\n",
      "Epoch 12/100\n",
      "1820/1820 [==============================] - 1s 562us/step - loss: 0.0017\n",
      "Epoch 13/100\n",
      "1820/1820 [==============================] - 1s 536us/step - loss: 0.0017\n",
      "Epoch 14/100\n",
      "1820/1820 [==============================] - 1s 545us/step - loss: 0.0017\n",
      "Epoch 15/100\n",
      "1820/1820 [==============================] - 1s 535us/step - loss: 0.0017\n",
      "Epoch 16/100\n",
      "1820/1820 [==============================] - 1s 528us/step - loss: 0.0016\n",
      "Epoch 17/100\n",
      "1820/1820 [==============================] - 1s 538us/step - loss: 0.0016\n",
      "Epoch 18/100\n",
      "1820/1820 [==============================] - 1s 532us/step - loss: 0.0016\n",
      "Epoch 19/100\n",
      "1820/1820 [==============================] - 1s 525us/step - loss: 0.0016\n",
      "Epoch 20/100\n",
      "1820/1820 [==============================] - 1s 529us/step - loss: 0.0016\n",
      "Epoch 21/100\n",
      "1820/1820 [==============================] - 1s 539us/step - loss: 0.0016\n",
      "Epoch 22/100\n",
      "1820/1820 [==============================] - 1s 527us/step - loss: 0.0016\n",
      "Epoch 23/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0016\n",
      "Epoch 24/100\n",
      "1820/1820 [==============================] - 1s 522us/step - loss: 0.0016\n",
      "Epoch 25/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0016\n",
      "Epoch 26/100\n",
      "1820/1820 [==============================] - 1s 528us/step - loss: 0.0016\n",
      "Epoch 27/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 28/100\n",
      "1820/1820 [==============================] - 1s 522us/step - loss: 0.0016\n",
      "Epoch 29/100\n",
      "1820/1820 [==============================] - 1s 558us/step - loss: 0.0016\n",
      "Epoch 30/100\n",
      "1820/1820 [==============================] - 1s 528us/step - loss: 0.0016\n",
      "Epoch 31/100\n",
      "1820/1820 [==============================] - 1s 526us/step - loss: 0.0016\n",
      "Epoch 32/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 33/100\n",
      "1820/1820 [==============================] - 1s 520us/step - loss: 0.0016\n",
      "Epoch 34/100\n",
      "1820/1820 [==============================] - 1s 514us/step - loss: 0.0016\n",
      "Epoch 35/100\n",
      "1820/1820 [==============================] - 1s 534us/step - loss: 0.0016\n",
      "Epoch 36/100\n",
      "1820/1820 [==============================] - 1s 526us/step - loss: 0.0016\n",
      "Epoch 37/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0016\n",
      "Epoch 38/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 39/100\n",
      "1820/1820 [==============================] - 1s 541us/step - loss: 0.0016\n",
      "Epoch 40/100\n",
      "1820/1820 [==============================] - 1s 527us/step - loss: 0.0016\n",
      "Epoch 41/100\n",
      "1820/1820 [==============================] - 1s 528us/step - loss: 0.0016\n",
      "Epoch 42/100\n",
      "1820/1820 [==============================] - 1s 532us/step - loss: 0.0016\n",
      "Epoch 43/100\n",
      "1820/1820 [==============================] - 1s 543us/step - loss: 0.0016\n",
      "Epoch 44/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 45/100\n",
      "1820/1820 [==============================] - 1s 538us/step - loss: 0.0016\n",
      "Epoch 46/100\n",
      "1820/1820 [==============================] - 1s 533us/step - loss: 0.0016\n",
      "Epoch 47/100\n",
      "1820/1820 [==============================] - 1s 522us/step - loss: 0.0016\n",
      "Epoch 48/100\n",
      "1820/1820 [==============================] - 1s 521us/step - loss: 0.0016\n",
      "Epoch 49/100\n",
      "1820/1820 [==============================] - 1s 521us/step - loss: 0.0016\n",
      "Epoch 50/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 51/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0016\n",
      "Epoch 52/100\n",
      "1820/1820 [==============================] - 1s 543us/step - loss: 0.0016\n",
      "Epoch 53/100\n",
      "1820/1820 [==============================] - 1s 526us/step - loss: 0.0016\n",
      "Epoch 54/100\n",
      "1820/1820 [==============================] - 1s 522us/step - loss: 0.0016\n",
      "Epoch 55/100\n",
      "1820/1820 [==============================] - 1s 522us/step - loss: 0.0016\n",
      "Epoch 56/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 57/100\n",
      "1820/1820 [==============================] - 1s 521us/step - loss: 0.0016\n",
      "Epoch 58/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 59/100\n",
      "1820/1820 [==============================] - 1s 515us/step - loss: 0.0016\n",
      "Epoch 60/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 61/100\n",
      "1820/1820 [==============================] - ETA: 0s - loss: 0.001 - 1s 520us/step - loss: 0.0016\n",
      "Epoch 62/100\n",
      "1820/1820 [==============================] - 1s 543us/step - loss: 0.0016\n",
      "Epoch 63/100\n",
      "1820/1820 [==============================] - 1s 525us/step - loss: 0.0016\n",
      "Epoch 64/100\n",
      "1820/1820 [==============================] - 1s 522us/step - loss: 0.0016\n",
      "Epoch 65/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 66/100\n",
      "1820/1820 [==============================] - 1s 538us/step - loss: 0.0016\n",
      "Epoch 67/100\n",
      "1820/1820 [==============================] - 1s 552us/step - loss: 0.0016\n",
      "Epoch 68/100\n",
      "1820/1820 [==============================] - 1s 528us/step - loss: 0.0016\n",
      "Epoch 69/100\n",
      "1820/1820 [==============================] - 1s 528us/step - loss: 0.0016\n",
      "Epoch 70/100\n",
      "1820/1820 [==============================] - 1s 518us/step - loss: 0.0016\n",
      "Epoch 71/100\n",
      "1820/1820 [==============================] - 1s 521us/step - loss: 0.0016\n",
      "Epoch 72/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 73/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 74/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 75/100\n",
      "1820/1820 [==============================] - 1s 522us/step - loss: 0.0016\n",
      "Epoch 76/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0016\n",
      "Epoch 77/100\n",
      "1820/1820 [==============================] - 1s 521us/step - loss: 0.0016\n",
      "Epoch 78/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 79/100\n",
      "1820/1820 [==============================] - 1s 553us/step - loss: 0.0016\n",
      "Epoch 80/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0016\n",
      "Epoch 81/100\n",
      "1820/1820 [==============================] - 1s 513us/step - loss: 0.0016\n",
      "Epoch 82/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 83/100\n",
      "1820/1820 [==============================] - 1s 522us/step - loss: 0.0016\n",
      "Epoch 84/100\n",
      "1820/1820 [==============================] - 1s 534us/step - loss: 0.0016\n",
      "Epoch 85/100\n",
      "1820/1820 [==============================] - 1s 518us/step - loss: 0.0016\n",
      "Epoch 86/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0016\n",
      "Epoch 87/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 88/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 89/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0016\n",
      "Epoch 90/100\n",
      "1820/1820 [==============================] - 1s 518us/step - loss: 0.0016\n",
      "Epoch 91/100\n",
      "1820/1820 [==============================] - 1s 518us/step - loss: 0.0016\n",
      "Epoch 92/100\n",
      "1820/1820 [==============================] - 1s 515us/step - loss: 0.0016\n",
      "Epoch 93/100\n",
      "1820/1820 [==============================] - 1s 523us/step - loss: 0.0016\n",
      "Epoch 94/100\n",
      "1820/1820 [==============================] - 1s 515us/step - loss: 0.0016\n",
      "Epoch 95/100\n",
      "1820/1820 [==============================] - 1s 526us/step - loss: 0.0016\n",
      "Epoch 96/100\n",
      "1820/1820 [==============================] - 1s 540us/step - loss: 0.0016\n",
      "Epoch 97/100\n",
      "1820/1820 [==============================] - 1s 516us/step - loss: 0.0016\n",
      "Epoch 98/100\n",
      "1820/1820 [==============================] - 1s 519us/step - loss: 0.0016\n",
      "Epoch 99/100\n",
      "1820/1820 [==============================] - 1s 524us/step - loss: 0.0016\n",
      "Epoch 100/100\n",
      "1820/1820 [==============================] - 1s 522us/step - loss: 0.0016\n",
      "[CV] ... encoded_neuron=16, optimizer=SGD, score=-0.002, total= 1.6min\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  7.1min remaining:    0.0s\n",
      "[CV] encoded_neuron=32, optimizer=Adam ...............................\n",
      "Epoch 1/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 0.0013\n",
      "Epoch 2/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.0261e-04\n",
      "Epoch 3/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.1204e-04\n",
      "Epoch 4/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 1.6378e-04\n",
      "Epoch 5/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 1.4770e-04\n",
      "Epoch 6/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 1.3229e-04\n",
      "Epoch 7/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 1.1008e-04\n",
      "Epoch 8/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 9.9261e-05\n",
      "Epoch 9/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 9.1555e-05\n",
      "Epoch 10/100\n",
      "1820/1820 [==============================] - 2s 985us/step - loss: 8.2834e-05\n",
      "Epoch 11/100\n",
      "1820/1820 [==============================] - 2s 987us/step - loss: 7.0882e-05\n",
      "Epoch 12/100\n",
      "1820/1820 [==============================] - 2s 986us/step - loss: 6.1875e-05\n",
      "Epoch 13/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 5.6635e-05\n",
      "Epoch 14/100\n",
      "1820/1820 [==============================] - 2s 998us/step - loss: 5.2565e-05\n",
      "Epoch 15/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 4.9627e-05\n",
      "Epoch 16/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 4.7151e-05\n",
      "Epoch 17/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 4.5427e-05\n",
      "Epoch 18/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 4.2982e-05\n",
      "Epoch 19/100\n",
      "1820/1820 [==============================] - 2s 990us/step - loss: 4.1040e-05\n",
      "Epoch 20/100\n",
      "1820/1820 [==============================] - 2s 988us/step - loss: 4.0331e-05\n",
      "Epoch 21/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.8178e-05\n",
      "Epoch 22/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.7381e-05\n",
      "Epoch 23/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.6028e-05\n",
      "Epoch 24/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.5605e-05\n",
      "Epoch 25/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.4599e-05\n",
      "Epoch 26/100\n",
      "1820/1820 [==============================] - 2s 984us/step - loss: 3.3935e-05\n",
      "Epoch 27/100\n",
      "1820/1820 [==============================] - 2s 1000us/step - loss: 3.3342e-05\n",
      "Epoch 28/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.2848e-05\n",
      "Epoch 29/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.2520e-05\n",
      "Epoch 30/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.2423e-05\n",
      "Epoch 31/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.1336e-05\n",
      "Epoch 32/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.1093e-05\n",
      "Epoch 33/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.0935e-05\n",
      "Epoch 34/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.0355e-05\n",
      "Epoch 35/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 3.0063e-05\n",
      "Epoch 36/100\n",
      "1820/1820 [==============================] - 2s 983us/step - loss: 2.9924e-05\n",
      "Epoch 37/100\n",
      "1820/1820 [==============================] - 2s 989us/step - loss: 2.9440e-05\n",
      "Epoch 38/100\n",
      "1820/1820 [==============================] - 2s 992us/step - loss: 3.0406e-05\n",
      "Epoch 39/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.8399e-05\n",
      "Epoch 40/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.8483e-05\n",
      "Epoch 41/100\n",
      "1820/1820 [==============================] - 2s 995us/step - loss: 2.7738e-05\n",
      "Epoch 42/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.7919e-05\n",
      "Epoch 43/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.7502e-05\n",
      "Epoch 44/100\n",
      "1820/1820 [==============================] - 2s 989us/step - loss: 2.7223e-05\n",
      "Epoch 45/100\n",
      "1820/1820 [==============================] - 2s 995us/step - loss: 2.6936e-05\n",
      "Epoch 46/100\n",
      "1820/1820 [==============================] - 2s 985us/step - loss: 2.6668e-05\n",
      "Epoch 47/100\n",
      "1820/1820 [==============================] - 2s 997us/step - loss: 2.6948e-05\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.5826e-05\n",
      "Epoch 49/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.5823e-05\n",
      "Epoch 50/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.5614e-05\n",
      "Epoch 51/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.5475e-05\n",
      "Epoch 52/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.5248e-05\n",
      "Epoch 53/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.4890e-05\n",
      "Epoch 54/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.5160e-05\n",
      "Epoch 55/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.4473e-05\n",
      "Epoch 56/100\n",
      "1820/1820 [==============================] - 2s 974us/step - loss: 2.4611e-05\n",
      "Epoch 57/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.4399e-05\n",
      "Epoch 58/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.3973e-05\n",
      "Epoch 59/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.4160e-05\n",
      "Epoch 60/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.3850e-05\n",
      "Epoch 61/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.4482e-05\n",
      "Epoch 62/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.3840e-05\n",
      "Epoch 63/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.3681e-05\n",
      "Epoch 64/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.3578e-05\n",
      "Epoch 65/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.3371e-05\n",
      "Epoch 66/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.3480e-05\n",
      "Epoch 67/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.3128e-05\n",
      "Epoch 68/100\n",
      "1820/1820 [==============================] - 2s 995us/step - loss: 2.2947e-05\n",
      "Epoch 69/100\n",
      "1820/1820 [==============================] - 2s 988us/step - loss: 2.2675e-05\n",
      "Epoch 70/100\n",
      "1820/1820 [==============================] - 2s 970us/step - loss: 2.3579e-05\n",
      "Epoch 71/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.4943e-05\n",
      "Epoch 72/100\n",
      "1820/1820 [==============================] - 2s 984us/step - loss: 2.2410e-05\n",
      "Epoch 73/100\n",
      "1820/1820 [==============================] - 2s 988us/step - loss: 2.2678e-05\n",
      "Epoch 74/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.2703e-05\n",
      "Epoch 75/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.2248e-05\n",
      "Epoch 76/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.2214e-05\n",
      "Epoch 77/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.2287e-05\n",
      "Epoch 78/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.2335e-05\n",
      "Epoch 79/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.2347e-05\n",
      "Epoch 80/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.1786e-05\n",
      "Epoch 81/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.1837e-05\n",
      "Epoch 82/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.1782e-05\n",
      "Epoch 83/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.1663e-05\n",
      "Epoch 84/100\n",
      "1820/1820 [==============================] - 2s 974us/step - loss: 2.1493e-05\n",
      "Epoch 85/100\n",
      "1820/1820 [==============================] - 2s 984us/step - loss: 2.1464e-05\n",
      "Epoch 86/100\n",
      "1820/1820 [==============================] - 2s 980us/step - loss: 2.1461e-05\n",
      "Epoch 87/100\n",
      "1820/1820 [==============================] - 2s 974us/step - loss: 2.1429e-05\n",
      "Epoch 88/100\n",
      "1820/1820 [==============================] - 2s 995us/step - loss: 2.1253e-05\n",
      "Epoch 89/100\n",
      "1820/1820 [==============================] - 2s 995us/step - loss: 2.1223e-05\n",
      "Epoch 90/100\n",
      "1820/1820 [==============================] - 2s 980us/step - loss: 2.1189e-05\n",
      "Epoch 91/100\n",
      "1820/1820 [==============================] - 2s 991us/step - loss: 2.1114e-05\n",
      "Epoch 92/100\n",
      "1820/1820 [==============================] - 2s 986us/step - loss: 2.1336e-05\n",
      "Epoch 93/100\n",
      "1820/1820 [==============================] - 2s 996us/step - loss: 2.0869e-05\n",
      "Epoch 94/100\n",
      "1820/1820 [==============================] - 2s 973us/step - loss: 2.0899e-05\n",
      "Epoch 95/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.0714e-05\n",
      "Epoch 96/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.0705e-05\n",
      "Epoch 97/100\n",
      "1820/1820 [==============================] - 2s 989us/step - loss: 2.0712e-05\n",
      "Epoch 98/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.0644e-05\n",
      "Epoch 99/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.0677e-05\n",
      "Epoch 100/100\n",
      "1820/1820 [==============================] - 2s 1ms/step - loss: 2.0477e-05\n",
      "[CV] .. encoded_neuron=32, optimizer=Adam, score=-0.000, total= 3.1min\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed: 10.2min remaining:    0.0s\n",
      "[CV] encoded_neuron=32, optimizer=SGD ................................\n",
      "Epoch 1/100\n",
      "1820/1820 [==============================] - 2s 920us/step - loss: 0.0467\n",
      "Epoch 2/100\n",
      "1820/1820 [==============================] - 2s 934us/step - loss: 0.0308\n",
      "Epoch 3/100\n",
      "1820/1820 [==============================] - 2s 961us/step - loss: 0.0089\n",
      "Epoch 4/100\n",
      "1820/1820 [==============================] - 2s 833us/step - loss: 0.0027\n",
      "Epoch 5/100\n",
      "1820/1820 [==============================] - 1s 644us/step - loss: 0.0020\n",
      "Epoch 6/100\n",
      "1820/1820 [==============================] - 1s 726us/step - loss: 0.0019\n",
      "Epoch 7/100\n",
      "1820/1820 [==============================] - 1s 658us/step - loss: 0.0018\n",
      "Epoch 8/100\n",
      "1820/1820 [==============================] - 1s 704us/step - loss: 0.0017\n",
      "Epoch 9/100\n",
      "1820/1820 [==============================] - 1s 657us/step - loss: 0.0017\n",
      "Epoch 10/100\n",
      "1820/1820 [==============================] - 1s 671us/step - loss: 0.0017\n",
      "Epoch 11/100\n",
      "1820/1820 [==============================] - 1s 761us/step - loss: 0.0017\n",
      "Epoch 12/100\n",
      "1820/1820 [==============================] - 1s 714us/step - loss: 0.0017\n",
      "Epoch 13/100\n",
      "1820/1820 [==============================] - 1s 726us/step - loss: 0.0017\n",
      "Epoch 14/100\n",
      "1820/1820 [==============================] - 1s 718us/step - loss: 0.0017\n",
      "Epoch 15/100\n",
      "1820/1820 [==============================] - 1s 697us/step - loss: 0.0016\n",
      "Epoch 16/100\n",
      "1820/1820 [==============================] - 1s 701us/step - loss: 0.0016\n",
      "Epoch 17/100\n",
      "1820/1820 [==============================] - 1s 696us/step - loss: 0.0016\n",
      "Epoch 18/100\n",
      "1820/1820 [==============================] - 1s 704us/step - loss: 0.0016\n",
      "Epoch 19/100\n",
      "1820/1820 [==============================] - 1s 676us/step - loss: 0.0016\n",
      "Epoch 20/100\n",
      "1820/1820 [==============================] - 1s 715us/step - loss: 0.0016\n",
      "Epoch 21/100\n",
      "1820/1820 [==============================] - 1s 718us/step - loss: 0.0016\n",
      "Epoch 22/100\n",
      "1820/1820 [==============================] - 1s 706us/step - loss: 0.0016\n",
      "Epoch 23/100\n",
      "1820/1820 [==============================] - 1s 746us/step - loss: 0.0016\n",
      "Epoch 24/100\n",
      "1820/1820 [==============================] - 1s 710us/step - loss: 0.0016\n",
      "Epoch 25/100\n",
      "1820/1820 [==============================] - 1s 694us/step - loss: 0.0016\n",
      "Epoch 26/100\n",
      "1820/1820 [==============================] - 1s 690us/step - loss: 0.0016\n",
      "Epoch 27/100\n",
      "1820/1820 [==============================] - 1s 696us/step - loss: 0.0016\n",
      "Epoch 28/100\n",
      "1820/1820 [==============================] - 1s 701us/step - loss: 0.0016\n",
      "Epoch 29/100\n",
      "1820/1820 [==============================] - 1s 692us/step - loss: 0.0016\n",
      "Epoch 30/100\n",
      "1820/1820 [==============================] - 1s 693us/step - loss: 0.0016\n",
      "Epoch 31/100\n",
      "1820/1820 [==============================] - 1s 706us/step - loss: 0.0016\n",
      "Epoch 32/100\n",
      "1820/1820 [==============================] - 1s 707us/step - loss: 0.0016\n",
      "Epoch 33/100\n",
      "1820/1820 [==============================] - 1s 675us/step - loss: 0.0016\n",
      "Epoch 34/100\n",
      "1820/1820 [==============================] - 1s 672us/step - loss: 0.0016\n",
      "Epoch 35/100\n",
      "1820/1820 [==============================] - 1s 790us/step - loss: 0.0016\n",
      "Epoch 36/100\n",
      "1820/1820 [==============================] - 2s 898us/step - loss: 0.0016\n",
      "Epoch 37/100\n",
      "1820/1820 [==============================] - 1s 751us/step - loss: 0.0016\n",
      "Epoch 38/100\n",
      "1820/1820 [==============================] - 1s 737us/step - loss: 0.0016\n",
      "Epoch 39/100\n",
      "1820/1820 [==============================] - 1s 693us/step - loss: 0.0016\n",
      "Epoch 40/100\n",
      "1820/1820 [==============================] - 1s 676us/step - loss: 0.0016\n",
      "Epoch 41/100\n",
      "1820/1820 [==============================] - 1s 707us/step - loss: 0.0016\n",
      "Epoch 42/100\n",
      "1820/1820 [==============================] - 1s 680us/step - loss: 0.0016\n",
      "Epoch 43/100\n",
      "1820/1820 [==============================] - 1s 702us/step - loss: 0.0016\n",
      "Epoch 44/100\n",
      "1820/1820 [==============================] - 1s 701us/step - loss: 0.0016\n",
      "Epoch 45/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 0.0016\n",
      "Epoch 46/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 0.0016\n",
      "Epoch 47/100\n",
      "1820/1820 [==============================] - 1s 676us/step - loss: 0.0016\n",
      "Epoch 48/100\n",
      "1820/1820 [==============================] - 1s 695us/step - loss: 0.0016\n",
      "Epoch 49/100\n",
      "1820/1820 [==============================] - 1s 677us/step - loss: 0.0016\n",
      "Epoch 50/100\n",
      "1820/1820 [==============================] - 1s 670us/step - loss: 0.0016\n",
      "Epoch 51/100\n",
      "1820/1820 [==============================] - 1s 687us/step - loss: 0.0016\n",
      "Epoch 52/100\n",
      "1820/1820 [==============================] - 1s 673us/step - loss: 0.0016\n",
      "Epoch 53/100\n",
      "1820/1820 [==============================] - 1s 666us/step - loss: 0.0016\n",
      "Epoch 54/100\n",
      "1820/1820 [==============================] - 1s 674us/step - loss: 0.0016\n",
      "Epoch 55/100\n",
      "1820/1820 [==============================] - 1s 646us/step - loss: 0.0016\n",
      "Epoch 56/100\n",
      "1820/1820 [==============================] - 1s 683us/step - loss: 0.0016\n",
      "Epoch 57/100\n",
      "1820/1820 [==============================] - 1s 677us/step - loss: 0.0016\n",
      "Epoch 58/100\n",
      "1820/1820 [==============================] - 1s 678us/step - loss: 0.0016\n",
      "Epoch 59/100\n",
      "1820/1820 [==============================] - 1s 667us/step - loss: 0.0016\n",
      "Epoch 60/100\n",
      "1820/1820 [==============================] - 1s 682us/step - loss: 0.0016\n",
      "Epoch 61/100\n",
      "1820/1820 [==============================] - 1s 736us/step - loss: 0.0016\n",
      "Epoch 62/100\n",
      "1820/1820 [==============================] - 1s 681us/step - loss: 0.0016\n",
      "Epoch 63/100\n",
      "1820/1820 [==============================] - 1s 689us/step - loss: 0.0016\n",
      "Epoch 64/100\n",
      "1820/1820 [==============================] - 1s 691us/step - loss: 0.0016\n",
      "Epoch 65/100\n",
      "1820/1820 [==============================] - 1s 720us/step - loss: 0.0016\n",
      "Epoch 66/100\n",
      "1820/1820 [==============================] - 1s 680us/step - loss: 0.0016\n",
      "Epoch 67/100\n",
      "1820/1820 [==============================] - 1s 697us/step - loss: 0.0016\n",
      "Epoch 68/100\n",
      "1820/1820 [==============================] - 1s 686us/step - loss: 0.0016\n",
      "Epoch 69/100\n",
      "1820/1820 [==============================] - 1s 693us/step - loss: 0.0016\n",
      "Epoch 70/100\n",
      "1820/1820 [==============================] - 1s 741us/step - loss: 0.0016\n",
      "Epoch 71/100\n",
      "1820/1820 [==============================] - 1s 726us/step - loss: 0.0016\n",
      "Epoch 72/100\n",
      "1820/1820 [==============================] - 1s 687us/step - loss: 0.0016\n",
      "Epoch 73/100\n",
      "1820/1820 [==============================] - 1s 740us/step - loss: 0.0016\n",
      "Epoch 74/100\n",
      "1820/1820 [==============================] - 1s 692us/step - loss: 0.0016\n",
      "Epoch 75/100\n",
      "1820/1820 [==============================] - 1s 768us/step - loss: 0.0016\n",
      "Epoch 76/100\n",
      "1820/1820 [==============================] - 2s 837us/step - loss: 0.0016\n",
      "Epoch 77/100\n",
      "1820/1820 [==============================] - 1s 734us/step - loss: 0.0016\n",
      "Epoch 78/100\n",
      "1820/1820 [==============================] - 1s 813us/step - loss: 0.0016\n",
      "Epoch 79/100\n",
      "1820/1820 [==============================] - 1s 790us/step - loss: 0.0016\n",
      "Epoch 80/100\n",
      "1820/1820 [==============================] - 1s 780us/step - loss: 0.0016\n",
      "Epoch 81/100\n",
      "1820/1820 [==============================] - 1s 735us/step - loss: 0.0016\n",
      "Epoch 82/100\n",
      "1820/1820 [==============================] - 1s 726us/step - loss: 0.0016\n",
      "Epoch 83/100\n",
      "1820/1820 [==============================] - 1s 730us/step - loss: 0.0016\n",
      "Epoch 84/100\n",
      "1820/1820 [==============================] - 1s 713us/step - loss: 0.0016\n",
      "Epoch 85/100\n",
      "1820/1820 [==============================] - 1s 765us/step - loss: 0.0016\n",
      "Epoch 86/100\n",
      "1820/1820 [==============================] - 1s 707us/step - loss: 0.0016\n",
      "Epoch 87/100\n",
      "1820/1820 [==============================] - 1s 694us/step - loss: 0.0016\n",
      "Epoch 88/100\n",
      "1820/1820 [==============================] - 1s 728us/step - loss: 0.0016\n",
      "Epoch 89/100\n",
      "1820/1820 [==============================] - 1s 682us/step - loss: 0.0016\n",
      "Epoch 90/100\n",
      "1820/1820 [==============================] - 1s 694us/step - loss: 0.0016\n",
      "Epoch 91/100\n",
      "1820/1820 [==============================] - 1s 696us/step - loss: 0.0016\n",
      "Epoch 92/100\n",
      "1820/1820 [==============================] - 1s 694us/step - loss: 0.0016\n",
      "Epoch 93/100\n",
      "1820/1820 [==============================] - 1s 698us/step - loss: 0.0016\n",
      "Epoch 94/100\n",
      "1820/1820 [==============================] - 1s 693us/step - loss: 0.0016\n",
      "Epoch 95/100\n",
      "1820/1820 [==============================] - 1s 697us/step - loss: 0.0016\n",
      "Epoch 96/100\n",
      "1820/1820 [==============================] - 1s 658us/step - loss: 0.0016\n",
      "Epoch 97/100\n",
      "1820/1820 [==============================] - 1s 691us/step - loss: 0.0016\n",
      "Epoch 98/100\n",
      "1820/1820 [==============================] - 1s 689us/step - loss: 0.0016\n",
      "Epoch 99/100\n",
      "1820/1820 [==============================] - 1s 674us/step - loss: 0.0016\n",
      "Epoch 100/100\n",
      "1820/1820 [==============================] - 1s 687us/step - loss: 0.0016\n",
      "[CV] ... encoded_neuron=32, optimizer=SGD, score=-0.002, total= 2.2min\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 12.4min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed: 12.4min finished\n",
      "Epoch 1/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 0.0010\n",
      "Epoch 2/100\n",
      "2275/2275 [==============================] - 2s 990us/step - loss: 2.7668e-04\n",
      "Epoch 3/100\n",
      "2275/2275 [==============================] - 2s 997us/step - loss: 1.8927e-04\n",
      "Epoch 4/100\n",
      "2275/2275 [==============================] - 2s 999us/step - loss: 1.3275e-04\n",
      "Epoch 5/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 9.8859e-05\n",
      "Epoch 6/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 8.1311e-05\n",
      "Epoch 7/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 6.9198e-05\n",
      "Epoch 8/100\n",
      "2275/2275 [==============================] - 2s 995us/step - loss: 5.5886e-05\n",
      "Epoch 9/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 4.7359e-05\n",
      "Epoch 10/100\n",
      "2275/2275 [==============================] - 2s 985us/step - loss: 4.1850e-05\n",
      "Epoch 11/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 3.8251e-05\n",
      "Epoch 12/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 3.4788e-05\n",
      "Epoch 13/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 3.2556e-05\n",
      "Epoch 14/100\n",
      "2275/2275 [==============================] - 2s 995us/step - loss: 3.0898e-05\n",
      "Epoch 15/100\n",
      "2275/2275 [==============================] - 2s 989us/step - loss: 2.9982e-05\n",
      "Epoch 16/100\n",
      "2275/2275 [==============================] - 2s 985us/step - loss: 2.8620e-05\n",
      "Epoch 17/100\n",
      "2275/2275 [==============================] - 2s 988us/step - loss: 2.7619e-05\n",
      "Epoch 18/100\n",
      "2275/2275 [==============================] - 2s 986us/step - loss: 2.6032e-05\n",
      "Epoch 19/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 2.5822e-05\n",
      "Epoch 20/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 2.4505e-05\n",
      "Epoch 21/100\n",
      "2275/2275 [==============================] - 2s 996us/step - loss: 2.3949e-05\n",
      "Epoch 22/100\n",
      "2275/2275 [==============================] - 2s 990us/step - loss: 2.3124e-05\n",
      "Epoch 23/100\n",
      "2275/2275 [==============================] - 2s 986us/step - loss: 2.2893e-05\n",
      "Epoch 24/100\n",
      "2275/2275 [==============================] - 2s 989us/step - loss: 2.2051e-05\n",
      "Epoch 25/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 2.1640e-05\n",
      "Epoch 26/100\n",
      "2275/2275 [==============================] - 2s 988us/step - loss: 2.1050e-05\n",
      "Epoch 27/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 2.1141e-05\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2275/2275 [==============================] - 2s 1ms/step - loss: 2.0495e-05\n",
      "Epoch 29/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 2.0180e-05\n",
      "Epoch 30/100\n",
      "2275/2275 [==============================] - 2s 996us/step - loss: 2.4107e-05\n",
      "Epoch 31/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.9819e-05\n",
      "Epoch 32/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.9229e-05\n",
      "Epoch 33/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.9020e-05\n",
      "Epoch 34/100\n",
      "2275/2275 [==============================] - 2s 996us/step - loss: 1.8844e-05\n",
      "Epoch 35/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.8856e-05\n",
      "Epoch 36/100\n",
      "2275/2275 [==============================] - 2s 993us/step - loss: 1.8246e-05\n",
      "Epoch 37/100\n",
      "2275/2275 [==============================] - 2s 995us/step - loss: 1.8477e-05\n",
      "Epoch 38/100\n",
      "2275/2275 [==============================] - 2s 992us/step - loss: 1.7898e-05\n",
      "Epoch 39/100\n",
      "2275/2275 [==============================] - 2s 990us/step - loss: 1.7855e-05\n",
      "Epoch 40/100\n",
      "2275/2275 [==============================] - 2s 996us/step - loss: 1.7267e-05\n",
      "Epoch 41/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.7137e-05\n",
      "Epoch 42/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.6685e-05\n",
      "Epoch 43/100\n",
      "2275/2275 [==============================] - 3s 1ms/step - loss: 1.6619e-05\n",
      "Epoch 44/100\n",
      "2275/2275 [==============================] - 3s 1ms/step - loss: 1.6218e-05\n",
      "Epoch 45/100\n",
      "2275/2275 [==============================] - 3s 1ms/step - loss: 1.6065e-05\n",
      "Epoch 46/100\n",
      "2275/2275 [==============================] - 3s 1ms/step - loss: 1.5762e-05\n",
      "Epoch 47/100\n",
      "2275/2275 [==============================] - 3s 1ms/step - loss: 1.5523e-05\n",
      "Epoch 48/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.5225e-05\n",
      "Epoch 49/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.5130e-05\n",
      "Epoch 50/100\n",
      "2275/2275 [==============================] - 2s 991us/step - loss: 1.5031e-05\n",
      "Epoch 51/100\n",
      "2275/2275 [==============================] - 2s 994us/step - loss: 1.4594e-05\n",
      "Epoch 52/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.4686e-05\n",
      "Epoch 53/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.4401e-05\n",
      "Epoch 54/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.4100e-05\n",
      "Epoch 55/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.3883e-05\n",
      "Epoch 56/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.3776e-05\n",
      "Epoch 57/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.3655e-05\n",
      "Epoch 58/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.3546e-05\n",
      "Epoch 59/100\n",
      "2275/2275 [==============================] - 2s 994us/step - loss: 1.3305e-05\n",
      "Epoch 60/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.2976e-05\n",
      "Epoch 61/100\n",
      "2275/2275 [==============================] - 2s 1000us/step - loss: 1.2857e-05\n",
      "Epoch 62/100\n",
      "2275/2275 [==============================] - 2s 996us/step - loss: 1.2759e-05\n",
      "Epoch 63/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.2451e-05\n",
      "Epoch 64/100\n",
      "2275/2275 [==============================] - 2s 995us/step - loss: 1.2509e-05\n",
      "Epoch 65/100\n",
      "2275/2275 [==============================] - 2s 973us/step - loss: 1.2677e-05\n",
      "Epoch 66/100\n",
      "2275/2275 [==============================] - 2s 973us/step - loss: 1.2218e-05\n",
      "Epoch 67/100\n",
      "2275/2275 [==============================] - 2s 979us/step - loss: 1.1883e-05\n",
      "Epoch 68/100\n",
      "2275/2275 [==============================] - 2s 986us/step - loss: 1.1881e-05\n",
      "Epoch 69/100\n",
      "2275/2275 [==============================] - 2s 976us/step - loss: 1.1872e-05\n",
      "Epoch 70/100\n",
      "2275/2275 [==============================] - 2s 980us/step - loss: 1.1724e-05\n",
      "Epoch 71/100\n",
      "2275/2275 [==============================] - 2s 978us/step - loss: 1.1509e-05\n",
      "Epoch 72/100\n",
      "2275/2275 [==============================] - 2s 982us/step - loss: 1.2520e-05\n",
      "Epoch 73/100\n",
      "2275/2275 [==============================] - 2s 989us/step - loss: 1.1732e-05\n",
      "Epoch 74/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.1452e-05\n",
      "Epoch 75/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.1798e-05\n",
      "Epoch 76/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.1278e-05\n",
      "Epoch 77/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.1233e-05\n",
      "Epoch 78/100\n",
      "2275/2275 [==============================] - 2s 977us/step - loss: 1.1191e-05\n",
      "Epoch 79/100\n",
      "2275/2275 [==============================] - 2s 979us/step - loss: 1.1126e-05\n",
      "Epoch 80/100\n",
      "2275/2275 [==============================] - 2s 982us/step - loss: 1.1517e-05\n",
      "Epoch 81/100\n",
      "2275/2275 [==============================] - 2s 981us/step - loss: 1.1002e-05\n",
      "Epoch 82/100\n",
      "2275/2275 [==============================] - 2s 1000us/step - loss: 1.0819e-05\n",
      "Epoch 83/100\n",
      "2275/2275 [==============================] - 2s 985us/step - loss: 1.3020e-05\n",
      "Epoch 84/100\n",
      "2275/2275 [==============================] - 2s 982us/step - loss: 1.0871e-05\n",
      "Epoch 85/100\n",
      "2275/2275 [==============================] - 2s 988us/step - loss: 1.0762e-05\n",
      "Epoch 86/100\n",
      "2275/2275 [==============================] - 2s 998us/step - loss: 1.0705e-05\n",
      "Epoch 87/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.0617e-05\n",
      "Epoch 88/100\n",
      "2275/2275 [==============================] - 2s 985us/step - loss: 1.0641e-05\n",
      "Epoch 89/100\n",
      "2275/2275 [==============================] - 2s 995us/step - loss: 1.0398e-05\n",
      "Epoch 90/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.0274e-05\n",
      "Epoch 91/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.0210e-05\n",
      "Epoch 92/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.0488e-05\n",
      "Epoch 93/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.0041e-05\n",
      "Epoch 94/100\n",
      "2275/2275 [==============================] - 2s 975us/step - loss: 9.9524e-06\n",
      "Epoch 95/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 9.7177e-06\n",
      "Epoch 96/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 1.0024e-05\n",
      "Epoch 97/100\n",
      "2275/2275 [==============================] - 2s 985us/step - loss: 9.6784e-06\n",
      "Epoch 98/100\n",
      "2275/2275 [==============================] - 2s 982us/step - loss: 9.6072e-06\n",
      "Epoch 99/100\n",
      "2275/2275 [==============================] - 2s 1ms/step - loss: 9.6060e-06\n",
      "Epoch 100/100\n",
      "2275/2275 [==============================] - 2s 995us/step - loss: 9.5632e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=1, test_size=0.2, train_size=None),\n",
       "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x0000017D12954F40>,\n",
       "             param_grid={'encoded_neuron': [8, 16, 32],\n",
       "                         'optimizer': ['Adam', 'SGD']},\n",
       "             scoring='neg_mean_squared_error', verbose=100)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'optimizer': ['Adam', 'SGD'],\n",
    "          'encoded_neuron': [8, 16, 32]}\n",
    "\n",
    "autoencoder = KerasRegressor(build_fn=create_model)\n",
    "\n",
    "autoencoder_grid = GridSearchCV(autoencoder, param_grid=params, cv=cv, verbose=100, scoring='neg_mean_squared_error') \n",
    "\n",
    "autoencoder_grid.fit(X_train_normal, X_train_normal, shuffle=True, batch_size=100, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoded_neuron': 32, 'optimizer': 'Adam'}\n",
      "-2.1862270360757218e-05\n"
     ]
    }
   ],
   "source": [
    "# Gridsearch Parameter Tuning result\n",
    "print(autoencoder_grid.best_params_)\n",
    "print(autoencoder_grid.best_score_)\n",
    "autoencoder_grid.best_estimator_.model.save('oneclass_ae.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hybrid (semi-supervised & supervised): encoder + classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder = Sequential()\n",
    "encoder.add(autoencoder_grid.best_estimator_.model.layers[0])\n",
    "encoder.add(autoencoder_grid.best_estimator_.model.layers[1])\n",
    "encoder.add(autoencoder_grid.best_estimator_.model.layers[2])\n",
    "\n",
    "train_all_rep = encoder.predict(X_train_all)\n",
    "test_all_rep = encoder.predict(X_test_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      0.93      0.96        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       1.00      0.96      0.98     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "accuracy_score 0.9998771110564938\n",
      "f1_score [0.99993845 0.96335079]\n",
      "recall_score [1.         0.92929293]\n",
      "precision_score [0.99987691 1.        ]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEXCAYAAACqIS9uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxUVf8H8M8IAiooaEquZPkAFu65BJho9KjsiwsuoJKipplaJgqahblgpbklpamP+4IoaqkkuWC49bjgmhsgiKAgICDbzPn94c95JIVxlMsA9/N+vXi9nDtz7/meK6/PHM7cOVchhBAgIiLZqKHrAoiIqGIx+ImIZIbBT0QkMwx+IiKZYfATEckMg5+ISGYY/NWQUqnE6tWr4eXlBXd3dzg5OWHBggUoLCx8pWOOHTsWvXv3xvr167XePy4uDhMmTHjp9svbw4cP4efnV+rz7u7uyM7OfuV2yjpvJ06cgIuLy0sf29fXF/v27SvzNbdv38Ynn3wCAEhNTYWPj89LtwcAVlZWcHV1hbu7u/onKCjolY75Is6fP4+ZM2dK3o5c6Ou6ACp/s2bNQlZWFtauXQsTExPk5eXh888/R1BQEBYsWPBSx0xNTUVMTAzOnj0LPT09rfdv06YNFi9e/FJtSyErKwtxcXGlPr9r165yaedVz9urunPnDm7dugUAMDc3x+bNm1/5mGvXrkX9+vVf+TjauH79OlJTUyu0zeqMI/5qJikpCbt378acOXNgYmICAKhduza++uorODo6Ang82v3888/h4uICV1dXhIaGori4GMDjgF6yZAl8fHzQq1cvbNy4ETk5ORg5ciSKi4vh5eWFxMREWFlZISMjQ93uk8e5ubmYMGEC3N3d4enpieDgYKhUqhKjW23bf542bdrg+++/R79+/eDk5IRff/0VEyZMQJ8+feDn54e8vDwAwPbt29G/f394eHigZ8+e6uNNmzYN+fn5cHd3h1KphI2NDT799FP07t0bcXFx6v4sXboUPj4+UCqVuHfvHuzt7XH8+PFn6jl9+jQGDBgAV1dXeHl54ciRI889b6W5d+8e/P394enpCU9PTyxatEj93LJly+Dk5ARXV1dMmDAB9+7de2b/FStWoH///nB1dYWjoyOioqKgVCoRHByMxMREfPTRR0hKSkKHDh0AAEVFRQgJCVEfNygoCDk5OQCAXr16YcmSJRg8eDB69uxZopayPO8cAMCOHTswePBgeHp6wtfXFwCwbds2eHl5wcPDA8OHD8eNGzfUx+jXrx+8vLzg5eWF/fv3IyUlBYsXL8bp06cxbdq0F6qFNBBUrezbt094e3uX+ZovvvhChISECJVKJQoKCoS/v78ICwsTQghhaWkp1q1bJ4QQIi4uTtjY2Ij8/Hxx+/Zt0b59e/UxLC0tRXp6+jOPIyIihL+/vxBCiOLiYhEUFCTi4+PF8ePHhbOz80u3/0+WlpZi7dq1QgghwsLCRIcOHcTdu3eFUqkUnp6eIjIyUuTk5IgBAwaIjIwMIYQQZ86cUffhef2JiIh4pj/FxcViyJAhIiwsTAwfPlz8+OOPz9SSkZEh3nvvPXH27FkhhBB///236NKli0hMTHymnac9fU6WLl0qZsyYIYQQIjc3V0ycOFFkZ2eL7du3i4EDB4rc3FwhhBCLFy9Wn9+hQ4eK3377TSQlJQlfX1/x6NEjIYQQe/bsES4uLs+08XQtP/zwgxg/frwoLCwUSqVSBAYGqtvv2bOnmDdvnhBCiLt374o2bdqIxMRE9XlxcXERbm5u6p/79++XeQ7Cw8NF586dxcOHD4UQQpw4cUIMHjxY5OXlCSGEOHr0qOjTp48QQgg/Pz+xZ88eIYQQly9fFrNmzRJCCBEeHi4CAgKeex5Je5zqqWZq1KgBlUpV5muOHDmCTZs2QaFQwMDAAD4+Pli7di0CAgIAAB988AEA4J133kFhYaF69PwiOnXqhIULF8LX1xe2trYYNmwYLCwscPfu3Vdq39DQ8Jm2evfuDQBo0aIFLC0tYW5uDgBo1qwZsrKyUKdOHaxYsQKHDx9GfHw8rly5UmZf3n333We26enp4dtvv4WrqyveeecdjB49+pnXnD9/Hi1atEC7du0AAP/617/QsWNHnDx5El27dn2h89a9e3cEBAQgJSUFtra2+Oyzz2BiYoIjR47Ay8sLtWvXBgD4+flhxYoVJT6vadq0KUJDQ7F7924kJCTg3LlzyM3NLbO9I0eOYNKkSahZsyaAx58XjBs3Tv38k/8Dc3NzNGjQAFlZWWjevDmA50/1HD58uNRzoFAoYGVlBWNjYwDAoUOHkJCQUOLzhuzsbGRmZqJv3774+uuvER0dDVtbW0yePPmFzh9ph1M91Uzbtm1x8+ZN9Z/tT6SmpiIgIAD5+flQqVRQKBTq51QqlXqqBYA6ZJ+8RmhYzunpEGrevDmioqIQEBCAnJwcjBgxAtHR0SVeX17tPwmtf/77ibt378LDwwPJycno1KkTJk6cWGY/noTrPyUnJ8PQ0BCJiYnIysp65nmlUlmiP09qfrpPmrRt2xYHDx7EwIEDkZycjP79++PChQsazxUAXLx4EQMHDkROTg7s7OwwcuRIje0977hFRUXqx0+/0SoUCo2/A5rOwdPnVqVSwd3dHbt27cKuXbsQERGB8PBw1KtXDz4+PoiMjISdnR1iYmLg5uaGgoICjf0h7TD4qxlzc3O4urpi+vTp6vDPycnBrFmzYGpqCiMjI9jb22P9+vUQQqCwsBBbt26Fra2tVu3Ur19f/eHonj171Ns3btyIadOmwd7eHlOmTIG9vT0uXbpUYt/yaP9FXLhwAfXr18fHH38Me3t7/PHHHwAeh5S+vj6USqXGQMvOzsaUKVMwb948uLi4PPcKlvbt2+PmzZs4f/48AODatWs4deoUunTp8sK1fvvtt1i+fDkcHR0RFBSEVq1a4dq1a+jevTvCw8PVf6msW7cOnTt3hoGBgXrfU6dOwcbGBiNGjECXLl1w8OBBKJVKAI//Ynk60J/o3r07Nm3ahKKiIqhUKmzYsAF2dnYvXO+rnAN7e3vs3bsXaWlpAIBNmzZh2LBhAAAfHx9cvnwZXl5eCAkJQXZ2Nu7duwc9PT2t3kipbJzqqYa+/PJLLF++HD4+PtDT00NhYSEcHR3Vl/UFBwdj9uzZcHV1RVFREbp3744xY8Zo1UZwcDC+/vpr1K1bF7a2tmjYsCEAwMPDAydPnoSTkxNq1aqFxo0bw9fXF1euXCmx76u2/yLs7Oywfft29OnTBwqFAl26dEH9+vWRkJAACwsLtG3bFs7OztiwYUOZ/XRwcIC9vT26dOmCfv36YcOGDRgyZIj6NfXr18cPP/yAkJAQ5OfnQ6FQYO7cuWjZsiWSkpJeqNZhw4YhMDAQLi4uMDAwgJWVFZydnaGvr4+UlBT0798fKpUKFhYW+Pbbb0vs6+LiggMHDqBv375QqVTo2bMnsrKykJOTg1atWsHQ0BD9+vXDwoUL1fuMHTsW8+fPh4eHB4qLi9G2bVvMmDFDyzP8P2WdgzNnzpR4rb29PUaNGgV/f38oFAoYGxtj6dKlUCgU+PzzzzFnzhwsWrQICoUC48ePR7NmzaBUKrFs2TKMHz8eS5cufek66TGF0DTkISKiaoVTPUREMsPgJyKSGQY/EZHMMPiJiGSGwU9EJDNV4nLOovs3dV0C0XPVatJd1yUQlaq4MPm52zniJyKSGQY/EZHMMPiJiGSGwU9EJDMMfiIimWHwExHJDIOfiEhmGPxERDLD4CcikhkGPxGRzDD4iYhkhsFPRCQzDH4iIplh8BMRyQyDn4hIZhj8REQyw+AnIpIZBj8Rkcww+ImIZIbBT0QkMwx+IiKZYfATEckMg5+ISGYY/EREMsPgJyKSGQY/EZHMMPiJiGSGwU9EJDMMfiIimWHwExHJDIOfiEhmGPxERDLD4CcikhkGPxGRzDD4iYhkhsFPRCQzDH4iIplh8BMRyQyDn4hIZhj8REQyw+AnIpIZBj8Rkcww+ImIZIbBT0QkMwx+IiKZYfATEckMg5+ISGYY/EREMsPgJyKSGX1dF0DaW7DkZ+z/4yjqmZgAAN5o0QzfhUzD5h17EL57H/ILCvG2VSuETJsIAwMD3LiVgFmhi5GXlw+FApg01h92XTsBAE6fjcP3y1Yhv7AQJnXqYHbQZDRv2hgpqfcwc+5CpD/IhEqpwojB3nB3+lCX3aZqzKnvB5g9OxCGhoaIi7uMUQGf4eHDHF2XVW0phBBC10VoUnT/pq5LqFSGBEzC55+MQoc2b6u3RR06hsU/rcX6Fd/BxLgOJgfPgU1rS4z0HYDh47+AW58P4OXSG5f/vo4R46ci5tetuJ+RAe9h4/Dzojl426oV1m3diZjjpxH2/WyM/2IWunZqB9+Bnrif8QDOAz/Crg1heL1RQx32vPKp1aS7rkuo8l57rT7On/0D7zt44Pr1W5g7ZzqMjY3xyYTpui6tyisuTH7udo74q5jCwkJcvnYDqzdsx9fJKbBo3hRTJwRg976DGObjhXp1H/8VMHPKeBQVFwMAVEoVsv9/9JSb9wgGBgYAgKg/YmDf7V28bdUKADDA3Un9l8DieTPxZEyQkpoGPT09GBkaVmhfSR4+/LAHTp8+h+vXbwEAVoT9B/89HcXgl5AkwW9tbQ2FQgEA+OcfFAqFApcvX5aiWVlIu5+Brh3b4ZMAP7RqaYHVG8PxSeBXKCgsgk1rS4yeHIy0++no1M4Gkz/+CAAQ9Nk4fDQhEOu2RCD9QRYWfBUIfX09xN9ORu1aRvh85lzEJyahsXkjfDEhAABQo8bjj3+Gj/8CZ85fhN9AL5jWq6uzflP11bxZE9xOuqN+nJSUgnr16sLExJjTPRLhVE8VJ4RAt397o6CgEB3avoMl82fC0MAA02d/hwZmppg01h/9RozHZ+M+goNdV5y7cBnjp87C1l+WYsXqjTh07AT+s3wBLJo3xfptuxCx5wDC1y4r0UbGg0yMmhiEoQPc4en8bx31tHLiVM+rC5z6CZo1a4Lxn0wDAOjp6aHgUSLqmrZCXt4jHVdXtZU21SPpVT0ZGRlYs2YNli1bhqVLl2Lx4sX44osvpGyy2rt6/RYi9x0ssU0I4HXzhnDsYQvjOnVQs2ZNuPTuhXMXr+DazXjk5xfAwa4rAKCdTWu81dICcZeuoOFr9dGhzduwaN4UAODl0htXr99EfkEBDvxxFLm5eQCA+mam6PX+e7h89XrFdpZkIfF2Mpo0MVc/btr0dWRkPGDoS0jS4J84cSIuX76MyMhIPHr0CPv371dPIdDLqVFDgXmLViDpzl0AwJaIvbBs1RK+AzywP/oo8gsKIIRA9JFY2FhbokWzJsjJzcWZuEsAgMSkO7h5KxHW/3oLju/b4kzcJfWxfj98DK1aWsDI0BBbIvZiw/ZIAMDDnFz8cTQWXTq1002nqVqLijqMrl06olWrlgCA0QG+iNx9QMdVVW+STvX06dMH+/btw/z589GnTx+0aNECw4YNQ2RkpFbH4VRPSbv3R2PVuq1QqlQwb/gaQqZNRKOGDRC2djP2HTwMlVKF1lat8OUXn8C4Th2c/Oscvlu+CoWFRdDTq4Gx/kPwwfu2AB5fDbRi9UYUFxejbl1jzJr6Kd56owVSUu/h69DFuHvvPgCgn2sfDOnvrstuV0qc6ikfffv0wuzZ02BgUBM3byRguP+nePAgU9dlVXmlTfVIGvwDBw7Eli1bsHXrVgghMHDgQLi5uTH4qdpg8FNlppPLObt164YJEyZg6tSp8Pf3x8WLF2FkZCRlk0REpIHkV/UkJiaiRYsWuHjxIk6dOgUnJyc0atRIq2NwxE+VFUf8VJnpZKqnsLAQMTExyM7OLrHdw8NDq+Mw+KmyYvBTZaaTqZ5Ro0ZBCIGmTZuW2K5t8BMRUfmRNPgfPHig9Qe5REQkLUkvqu/WrRv+/PNPqFQqKZshIiItSDrib9KkCfz9/Uus28O1eoiIdEvS4N+6dSuio6PRpEkTKZshIiItSDrV07BhQ5iamkrZBBERaUnSEb+pqSlcXFzQsWNH1KxZU7197ty5UjZLRERlkDT4HRwc4ODgIGUTRESkJUmDf8+ePVi1apWUTRARkZYknePPz89HSkqKlE0QEZGWJB3xZ2RkoFevXmjQoAEMDQ3Vl3MePHhQ885ERCQJSYN/5cqVUh6eiIheguRf4Nq0aROOHz+O4uJidOvWDUOHDpWySSIi0kDS4A8NDUVCQgK8vb0hhMCOHTtw+/ZtBAUFSdksERGVQdLgP3bsGHbu3Km+z66DgwNcXV2lbJKIiDSQ9KoepVKJ4uLiEo/19PSkbJKIiDSQdMTv6uoKPz8/ODs7AwD27t2r/jcREemGJMF/584dAICbmxvq1auH48ePQwgBV1dX9OzZU4omiYjoBUly68VevXpBoVDgn4e+f/8+ioqKtF6WmbdepMqKt16kykzrWy9mZmaWecCyVt2Mjo4u8Tg3Nxfz589HTEwMQkJCyjwuERFJq9Tg79at23NH7QC0uplKbGwsgoODYWdnh8jISBgbG798tURE9MpKDf4rV6680oHz8vIwb9489Sjfzs7ulY5HRETlQ+PlnCqVCqtWrUJgYCBycnIQFhYGpVJZ5j6xsbHq6/V3797N0CciqkQ0XtUTGhqKjIwMxMXFQQiBo0eP4t69ewgODi51nxEjRkBfXx8xMTE4duyYejsXaSMi0j2NwR8bG4uIiAh4eXnBxMQEv/zyC9zd3cvch8FORFR5aQx+fX199ZILAGBgYAB9/bJ3a9q06atXRkREktAY/JaWltiwYQOUSiVu3ryJNWvWwNrauiJqIyIiCWj8cDcoKAgXL15Eeno6Bg0ahNzcXEyfPr0iaiMiIglI8s3d8sZv7lJlxW/uUmVW2jd3NY7409PTMXnyZHTt2hX29vaYPn06srOzy71AIiKqGBqDPzg4GM2bN8f27duxfv161KtXDzNnzqyI2oiISAIaP9xNTk7Gjz/+qH48depU3kyFiKgK0zjib9SoEW7fvq1+fPfuXTRs2FDSooiISDqljvjHjBkDAMjIyICHhwdsbW1Ro0YNnDhxAlZWVhVWIBERla9Sg793797P3e7g4CBVLUREVAFKDX5PT8/nbhdCICEhQbKCiIhIWho/3N28eTNCQ0Px6NEj9bb69euXWHyNiIiqDo3B/9NPP2H16tX48ccfMXHiRPzxxx+4e/duRdRGREQS0HhVj6mpKdq1a4fWrVsjPT0dY8eOxalTpyqiNiIikoDG4NfX10dWVhYsLCxw/vx5ANB4IxYiIqq8NAb/gAEDMHr0aDg4OGDLli3w8vLCm2++WRG1ERGRBF5okba8vDzUrl0bqampiIuLQ/fu3WFoaFgR9QHgIm1UeXGRNqrMXnqRNgCoXbs2AMDc3ByOjo4YPnx4uRVGREQV64WC/5+uXLlS3nUQEVEFeangVygU5V0HERFVkJcKfiIiqrpK/QLX7Nmzn7tdCIGioiLJCnoefoBGRFR+Sg1+U1PTUncaPXq0JMUQEZH0qsQ9d/UNmuq6BCKiKueVLuckIqLqg8FPRCQzDH4iIpnRGPwqlQorV67E1KlTkZOTg7CwMC7SRkRUhWkM/tDQUPz999/qlTmPHj2KuXPnSl4YERFJQ2Pwx8bGYt68eTA0NISxsTF++eUX3n2LiKgKe6H1+GvU+N/LDAwMoK+v8cZdRERUSWlMcEtLS2zYsAFKpRI3b97EmjVrYG1tXRG1ERGRBDSO+IOCgnDx4kWkp6dj0KBByM3NxfTp0yuiNiIikgC/uUtEVE2V9s1djVM9pS3WFhwc/GoVERGRTmic6jE1NVX/1KlTBydPnqyIuoiISCJaT/Xk5ORg7NixWLdunVQ1PYNTPURE2iu3RdqMjY2Rlpb2ygUREZFuaJzjDwkJUd9qUQiBixcv4s0335S8MCIikobG4DczMyvx2M3NDW5ubpIVRERE0tIY/ImJiQgNDa2IWoiIqAJonOO/cuUKqsCl/kRE9II0jvgbNmwIZ2dntGvXDnXq1FFv53X8RERVU6nBX1hYCAMDA3To0AEdOnSoyJqIiEhCpV7H7+npiYiIiIqu57l4HT8Rkfa0vo6f8/pERNVTqVM9BQUFuHTpUqlvAO+8845kRRERkXRKneqxsbGBubn5c4NfoVDg4MGDkhf3BKd6iIi0p/XqnK1atcLOnTslK4iIiHRD67V6iIioais1+N99992KrIOIiCoI78BFRFRNlduyzEREVLUx+ImIZIbBT0QkMwx+IiKZYfATEckMg5+ISGYY/EREMsPgJyKSGQY/EZHMMPiJiGSGwU9EJDMMfiIimWHwExHJDIOfiEhmGPxERDLD4CcikhkGPxGRzDD4iYhkhsFPRCQzDH6ZGDq0H06fOqD+uXY1Fo9y49Go0Wu6Lo1katzHI3DxwhGcPnUA69ctg5mZKYyMjPDzT9/h7JmDOHc2Gj//9B2MjIx0XWq1w5uty5C+vj4ORe/A2v9sxc8r1+u6HJIhhx62WLN6Mey6uyI5OQVDhnjDzbU3rl69jubNm8L/o4lQKBT4z9oluH79FmZ99a2uS66SSrvZun4F10GVwBdTxiHt3n2GPulMx45tcDD6KJKTUwAAERG/4qcVC7By5XrEJyRBCAEhBM6evYC337bScbXVD6d6ZKZBAzNMmhiAzz6fpetSSMZOnjyDng52aNHi8V/zw4cNhKGhIeIuXMG1azcBAC1aNMWET0YiPHyPLkutliQZ8VtbW0OhUPyvEX196OnpoaCgAMbGxjh16pQUzdILGDVyKCJ3H8CtW4m6LoVkLObYSYTM/h7bt62CSqXCmjVbkJ7+AIWFRQCAjh3aYPu2VVj+4xrs/fV3HVdb/Ug6x//ll1+iY8eOcHNzg0KhwP79+3H06FHMnj1bq+Nwjr/8/HU6CpMmzcCRo8d1XQrJmLFxHZibN8SNG/EAgCZNXseZv36HeWMbDBjghqWL52DCxGBs3rxTt4VWcaXN8Us61XP+/Hm4u7urR/+9e/fGhQsXpGySymBqWg+t3noDf8ae1nUpJHNNmryOg1HbYWJiDACYFjgBm7fshIvzh1j0fQj6Og1m6EtI0g93a9WqhfDwcPTt2xcqlQq7du1CvXr1pGySytDqrTeQkpKK4uJiXZdCMvf33zcQumAp/jy2BzVq1MCxYycx4dNg/HX6ABQKBcLC/ncVz59/nsKET4N0WG31I+lUT3JyMkJCQnDixAkoFArY2dkhODgY5ubmWh2HUz1ERNorbaqH1/ETEVVTOrmOv1evXiWu7nni4MGDUjZLRERlkDT4161bp/53cXExoqKiUFhYKGWTRESkQYVP9Xh5eWHHjh1a7cOpHiIi7elkqufpL2oJIXDt2jUUFBRI2SQREWkgafAvXrxY/W+FQgEzMzPMmzdPyiaJiEgDXtVDRFRN6WSq5+zZswgLC0NeXh6EEFCpVLhz5w6io6OlbJaIiMog6ZIN06dPh6OjI5RKJYYMGQJzc3M4OjpK2SQREWkg6YjfwMAA3t7eSE5ORt26dREaGgpXV1cpmyQiIg0kHfEbGhoiMzMTLVu2xLlz56CnpwelUillk0REpIGkwT9ixAhMmjQJPXv2xK5du+Ds7AwbGxspmyQiIg0kvarn0KFD6NGjBxQKBfLy8hAfHw9ra2vUqKHd+w2v6iEi0p5O1uNfsGCBeq2e2rVr4+2339Y69ImIqHxJOuIfM2YMzMzM0K5dOxgZGam3e3h4aHUcjviJiLRXodfxp6amwtzcHGZmZgCAc+fOlXhe2+AnIqLyI8mI39PTExEREQCAX375Bf7+/q90PI74iYi0V6Fz/E+/l+zevVuKJoiI6CVJEvxP33ylCiwFREQkK5JfYvO8O3AREZHuSDLHb2Njo76h+pMPeoHHo3+FQqH1rRc5x09EpL0Kvapn//79UhyWiIjKAdfjJyKqpnTyzV0iIqp8GPxERDLD4CcikhkGPxGRzDD4iYhkhsFPRCQzDH4iIplh8BMRyQyDn4hIZhj8REQyw+AnIpIZBj8Rkcww+ImIZIbBT0QkMwx+IiKZYfATEckMg5+ISGYY/EREMsPgJyKSGQY/EZHMMPiJiGSGwU9EJDMMfiIimWHwExHJDIOfiEhmGPxERDLD4CcikhmFEELouggiIqo4HPETEckMg5+ISGYY/EREMsPgJyKSGQY/EZHMMPiJiGSGwU9EJDMMfiIimWHwExHJDIO/CklKSoKVlRWOHTtWYnuvXr2QlJRUITVYWVlVSDtUtSUlJcHGxgbu7u4lflJSUsq1Hf4+vhx9XRdA2qlZsyZmzJiByMhIGBsb67ocolI1atQIu3bt0nUZ9BwM/iqmUaNGsLW1xfz58xESElLiuRUrViAyMhJ6enqws7PDlClTkJKSgpEjR8LMzAxGRkZwdXXFoUOHkJmZibS0NPj4+CA5ORnHjx+HqakpVq5cCUNDQyxcuBCxsbHIyspCo0aNsHDhQrz22ms66jVVF4GBgcjMzERCQgKmTJmCgoICrF69Gvn5+SgsLMScOXPQsWNH+Pr6Yvz48ejatSuSkpLg5+eH6OhoJCUlYcqUKcjLy0O7du103Z0qi1M9VVBgYCBiYmJKTPkcOXIE0dHRCA8PR0REBBISErB582YAwK1bt7BgwQKsXr0aABAXF4fly5dj1apVmDt3Lt5//33s3r0bAHD06FEkJCTg5s2b2Lx5M/bv34/GjRsjMjKy4jtKVVpaWlqJaZ6VK1cCAExNTfHbb7/BwcEBmzdvVg9YRo4ciZ9++qnMY4aEhMDLywu7du1Cx44dK6Ib1RJH/FWQsbExQkJC1FM+AHD8+HE4OzujVq1aAABvb2/s3LkTPXr0QIMGDdCsWTP1/h07doSxsbF6qui9994DADRt2hTZ2dmwsLDA1KlTsW3bNty6dQtnz55FixYtKriXVNU9b6onMDAQbdu2BQDUqFEDy5YtQ3R0NG7duoWTJ0+iRo2yx6InT57Ed999BwBwc3NDcHCwNMVXcxzxV1H29vbqKR8AUKlUz7ymuLgYAGBkZFRie82aNUs81tcv+f5/4cIFfPTRR1CpVPWPJVcAAAYRSURBVOjduzccHR3B1bupvDz5fczNzUW/fv2QlJSEzp07w9fXt8TrnvzOPfk9/ud2hUKh8Y2Cno9nrQp7MuWTlpaGbt26Ye/evcjPz0dxcTHCw8PRrVu3lzruqVOn0KVLFwwaNAhvvPEGDh06BKVSWc7Vk9zFx8dDoVBgzJgx6Nq1K6KiotS/Z2ZmZrh+/ToA4Pfff1fvY2trq/4r98CBAygoKKj4wqsBBn8V9mTKp6ioCA4ODnBwcIC3tzecnZ3RpEkTDB069KWO6+TkhCtXrsDV1RV+fn6wsbGpsMtFST6sra3RunVr9O3bF87OzjAzM8OdO3cAACNHjsTGjRvh6emJ/Px89T4zZ87E/v374ebmhsOHD6NOnTq6Kr9K4x24iIhkhiN+IiKZYfATEckMg5+ISGYY/EREMsPgJyKSGQY/VUpJSUlo3bp1ia/8u7m5Yfv27a987NGjR2PHjh0AAHd3d2RnZ5f62ocPH8LPz0/rNvbt2/fMF5KAx/3q0KGD1sezsrJCRkaGVvsEBgZi1apVWrdF1R+XbKBKy8jIqMRX/lNTU+Hi4gIbGxtYW1uXSxuaVo/MyspCXFxcubRFVFkw+KnKMDc3h4WFBeLj43Hp0iVs374djx49grGxMdatW4dt27Zh06ZNUKlUMDU1xYwZM/DWW28hNTUVgYGBSEtLQ5MmTZCenq4+ppWVFWJjY1G/fn2EhYUhIiIC+vr6sLCwwLx58zBt2jTk5+fD3d0dO3bsQHx8PL755htkZmZCqVTC19cX/fr1AwD88MMP2L17N0xNTWFhYaF1/27duoWvv/4aubm5uHfvHqytrbFo0SIYGhoCABYtWoS4uDioVCpMnDgRPXv2BIBS+01UKkFUCd2+fVu0b9++xLb//ve/onPnzuLOnTsiPDxcdO7cWTx8+FAIIcSJEyfE4MGDRV5enhBCiKNHj4o+ffoIIYT4+OOPxcKFC4UQQsTHx4v27duL8PBwIYQQlpaWIj09Xfz+++/i3//+t8jMzBRCCDFnzhyxfPnyEnUUFRUJJycnceHCBSGEENnZ2aJv377izJkzIioqSjg5OYmHDx+KoqIiERAQIIYOHfpC/Xpi3rx5YufOnUIIIQoLC4WLi4vYt2+fus6wsDAhhBBXr14VXbp0Eenp6WX2e+rUqWLlypXanXiSBY74qdJ6MtIGAKVSCTMzMyxYsACNGzcG8Hi0/mSF0UOHDiEhIQE+Pj7q/bOzs5GZmYk///wTU6dOBQBYWFiga9euz7QVGxuLPn36oF69egCAadOmAUCJpSri4+ORmJiI6dOnl6jx0qVLuHHjBj788EN1Pd7e3li3bp1W/Z0yZQqOHTuGn3/+GfHx8UhLS0NeXp76+UGDBgEALC0t8dZbb+HMmTP466+/Su03UWkY/FRp/XOO/59q166t/rdKpYK7uzumTJmifpyWloZ69epBoVCUWF30n6uRAoCenh4UCoX6cXZ29jMf+iqVSpiYmJSo6f79+zAxMUFoaGiJNvT09LTo6WOTJ0+GUqlE37594eDggJSUlBLHfHolSpVKBX19/TL7TVQaXtVD1YK9vT327t2LtLQ0AMCmTZswbNgwAED37t2xZcsWAMCdO3dw4sSJZ/a3tbVFVFQUcnJyAABLlizBmjVroK+vD6VSCSEEWrZsWeLNKCUlBS4uLrhw4QLef/997Nu3D9nZ2VCpVC91y8GYmBiMGzcOTk5OAIBz586VWBU1IiICAHDx4kUkJiaiXbt2ZfabqDQc8VO1YG9vj1GjRsHf3x8KhQLGxsZYunQpFAoFvvzyS0ybNg19+/bF66+//twrgnr06IHr16+rp1NatWqFkJAQ1KpVC23btoWzszM2bNiA5cuX45tvvsHKlStRXFyMTz/9FJ06dQIAXL16Fd7e3qhbty6sra3x4MGD59aal5f3zCWdmzdvxqRJkzBu3DjUrl0bxsbG6Ny5MxITE9WvuX37Njw8PKBQKPD999/D1NS0zH4TlYarcxIRyQyneoiIZIbBT0QkMwx+IiKZYfATEckMg5+ISGYY/EREMsPgJyKSGQY/EZHM/B/dTpiW7rHFCAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# classifier\n",
    "clf = LogisticRegression().fit(train_all_rep, Y_train_all)\n",
    "y_pred = clf.predict(test_all_rep)\n",
    "evaluation_matrix(Y_test_all, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semi-supervised: error threshold-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>true_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176561</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246293</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211214</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36088</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87505</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21526</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117827</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73527</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267816</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128297</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227452 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        reconstruction_error  true_class\n",
       "176561              0.000003         0.0\n",
       "246293              0.000006         0.0\n",
       "211214              0.000005         0.0\n",
       "36088               0.000002         0.0\n",
       "87505               0.000006         0.0\n",
       "...                      ...         ...\n",
       "21526               0.000002         0.0\n",
       "117827              0.000002         0.0\n",
       "73527               0.000003         0.0\n",
       "267816              0.000002         0.0\n",
       "128297              0.000002         0.0\n",
       "\n",
       "[227452 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get reconstruction error of train normal data\n",
    "pred = autoencoder_grid.best_estimator_.model.predict(X_train_normal)\n",
    "mse = np.mean(np.power(X_train_normal - pred, 2), axis=1)\n",
    "\n",
    "error_train = pd.DataFrame({'reconstruction_error': mse, 'true_class': Y_train_normal})\n",
    "error_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.005889626284892677"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get maximum error as threshold\n",
    "threshold = max(error_train['reconstruction_error'].values)\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reconstruction_error</th>\n",
       "      <th>true_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56957</th>\n",
       "      <td>0.035148</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56958</th>\n",
       "      <td>0.039324</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56959</th>\n",
       "      <td>0.040336</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56960</th>\n",
       "      <td>0.035216</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56961</th>\n",
       "      <td>0.035033</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56962 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       reconstruction_error  true_class\n",
       "0                  0.000003           0\n",
       "1                  0.000002           0\n",
       "2                  0.000003           0\n",
       "3                  0.000002           0\n",
       "4                  0.000008           0\n",
       "...                     ...         ...\n",
       "56957              0.035148           1\n",
       "56958              0.039324           1\n",
       "56959              0.040336           1\n",
       "56960              0.035216           1\n",
       "56961              0.035033           1\n",
       "\n",
       "[56962 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get reconstruction error of train data\n",
    "pred = autoencoder_grid.best_estimator_.model.predict(X_test_all)\n",
    "mse = np.mean(np.power(X_test_all - pred, 2), axis=1)\n",
    "\n",
    "error_test = pd.DataFrame({'reconstruction_error': mse, 'true_class': Y_test_all})\n",
    "error_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x17d1362ba60>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_test.iloc[56500:,0].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00        99\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       1.00      1.00      1.00     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "accuracy_score 1.0\n",
      "f1_score [1. 1.]\n",
      "recall_score [1. 1.]\n",
      "precision_score [1. 1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prediction\n",
    "y_pred = [1 if e > threshold else 0 for e in error_test.reconstruction_error.values]\n",
    "evaluation_matrix(error_test.true_class, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
